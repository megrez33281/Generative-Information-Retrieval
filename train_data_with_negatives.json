[
    {
        "query": "Sets the output of the streaming query to be processed using the provided\n        function. This is supported only the in the micro-batch execution modes (that is, when the\n        trigger is not continuous). In every micro-batch, the provided function will be called in\n        every micro-batch with (i) the output rows as a DataFrame and (ii) the batch identifier.\n        The batchId can be used deduplicate and transactionally write the output\n        (that is, the provided Dataset) to external systems. The output DataFrame is guaranteed\n        to exactly same for the same batchId (assuming all operations are deterministic in the\n        query).\n\n        .. note:: Evolving.\n\n        >>> def func(batch_df, batch_id):\n        ...     batch_df.collect()\n        ...\n        >>> writer = sdf.writeStream.foreach(func)",
        "positive_code": "def foreachBatch(self, func):\n        \n\n        from pyspark.java_gateway import ensure_callback_server_started\n        gw = self._spark._sc._gateway\n        java_import(gw.jvm, \"org.apache.spark.sql.execution.streaming.sources.*\")\n\n        wrapped_func = ForeachBatchFunction(self._spark, func)\n        gw.jvm.PythonForeachBatchHelper.callForeachBatch(self._jwrite, wrapped_func)\n        ensure_callback_server_started(gw)\n        return self",
        "hard_negative_ids": [
            360,
            42,
            142,
            414,
            29,
            291,
            136,
            466,
            217,
            25,
            197,
            429,
            245,
            243,
            112,
            73,
            337,
            376,
            275,
            232,
            453,
            236,
            47,
            34,
            252,
            424,
            23,
            109,
            166,
            235,
            425,
            64,
            33,
            9,
            499,
            116,
            119,
            470,
            76,
            264,
            227,
            349,
            368,
            297,
            255,
            317,
            171,
            97,
            254,
            343
        ]
    },
    {
        "query": "Retrieve variant calls for all samples, merging batched samples into single VCF.",
        "positive_code": "def _organize_variants(samples, batch_id):\n    \n    caller_names = [x[\"variantcaller\"] for x in samples[0][\"variants\"]]\n    calls = collections.defaultdict(list)\n    for data in samples:\n        for vrn in data[\"variants\"]:\n            calls[vrn[\"variantcaller\"]].append(vrn[\"vrn_file\"])\n    data = samples[0]\n    vrn_files = []\n    for caller in caller_names:\n        fnames = calls[caller]\n        if len(fnames) == 1:\n            vrn_files.append(fnames[0])\n        else:\n            vrn_files.append(population.get_multisample_vcf(fnames, batch_id, caller, data))\n    return caller_names, vrn_files",
        "hard_negative_ids": [
            448,
            218,
            16,
            85,
            116,
            142,
            76,
            207,
            295,
            88,
            47,
            201,
            25,
            237,
            23,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190,
            443,
            145,
            103,
            4,
            344,
            122,
            387,
            246,
            411,
            477,
            15,
            215
        ]
    },
    {
        "query": "Resolve all chained / nested aliases. This will recursively point\n    nested aliases to their resolved data type (first non-alias in the chain).\n\n    Note: This differs from unwrap_alias which simply identifies/returns\n    the resolved data type.\n\n    Args:\n        data_type (DataType): The target DataType/Alias to resolve.\n    Return:\n        DataType: The resolved type.",
        "positive_code": "def resolve_aliases(data_type):\n    \n    if not is_alias(data_type):\n        return data_type\n\n    resolved = resolve_aliases(data_type.data_type)\n    data_type.data_type = resolved\n\n    return resolved",
        "hard_negative_ids": [
            321,
            414,
            134,
            421,
            489,
            49,
            85,
            429,
            232,
            360,
            269,
            324,
            73,
            146,
            393,
            466,
            159,
            76,
            285,
            47,
            223,
            291,
            189,
            109,
            287,
            147,
            41,
            207,
            23,
            490,
            488,
            77,
            498,
            69,
            275,
            279,
            197,
            457,
            500,
            195,
            131,
            33,
            361,
            280,
            424,
            219,
            357,
            440,
            88,
            295
        ]
    },
    {
        "query": "Show stack frames for a task",
        "positive_code": "def do_where(self, taskid: int) -> None:\n        \n        task = task_by_id(taskid, self._loop)\n        if task:\n            self._sout.write(_format_stack(task))\n            self._sout.write()\n        else:\n            self._sout.write( % taskid)",
        "hard_negative_ids": [
            216,
            392,
            414,
            106,
            228,
            304,
            47,
            391,
            317,
            453,
            178,
            425,
            15,
            360,
            171,
            470,
            256,
            382,
            222,
            462,
            76,
            349,
            472,
            272,
            466,
            180,
            23,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190
        ]
    },
    {
        "query": "Try to import the aeneas package and return ``True`` if that fails.",
        "positive_code": "def check_import():\n    \n    try:\n        import aeneas\n        print_success(u\"aeneas         OK\")\n        return False\n    except ImportError:\n        print_error(u\"aeneas         ERROR\")\n        print_info(u\"  Unable to load the aeneas Python package\")\n        print_info(u\"  This error is probably caused by:\")\n        print_info(u\"    A. you did not download/git-clone the aeneas package properly; or\")\n        print_info(u\"    B. you did not install the required Python packages:\")\n        print_info(u\"      1. BeautifulSoup4\")\n        print_info(u\"      2. lxml\")\n        print_info(u\"      3. numpy\")\n    except Exception as e:\n        print_error(e)\n    return True",
        "hard_negative_ids": [
            36,
            360,
            295,
            252,
            414,
            131,
            73,
            193,
            197,
            466,
            291,
            275,
            119,
            136,
            158,
            44,
            11,
            485,
            76,
            239,
            153,
            264,
            429,
            185,
            7,
            433,
            26,
            234,
            171,
            345,
            269,
            23,
            24,
            231,
            367,
            201,
            326,
            370,
            118,
            25,
            376,
            109,
            281,
            368,
            324,
            189,
            277,
            208,
            93,
            424
        ]
    },
    {
        "query": "Create a node for SystemRestoreItem/OriginalFileName\n    \n    :return: A IndicatorItem represented as an Element node",
        "positive_code": "def make_systemrestoreitem_originalfilename(original_filename, condition=, negate=False, preserve_case=False):\n    \n    document = \n    search = \n    content_type = \n    content = original_filename\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node",
        "hard_negative_ids": [
            305,
            174,
            433,
            325,
            311,
            126,
            215,
            461,
            348,
            18,
            391,
            170,
            360,
            379,
            459,
            106,
            304,
            366,
            317,
            272,
            464,
            31,
            453,
            178,
            39,
            425,
            227,
            382,
            207,
            15,
            189,
            500,
            171,
            457,
            462,
            222,
            429,
            470,
            427,
            266,
            265,
            256,
            159,
            361,
            472,
            327,
            414,
            440,
            388,
            162
        ]
    },
    {
        "query": "Ensure the given policy exists on an S3 bucket, granting access for the given origin access\n    identity to do the things specified in the policy.\n\n    name\n        The name of the state definition\n\n    Bucket\n        The S3 bucket which CloudFront needs access to. Note that this policy\n        is exclusive - it will be the only policy definition on the bucket (and\n        objects inside the bucket if you specify such permissions in the\n        policy). Note that this likely SHOULD reflect the bucket mentioned in\n        the Resource section of the Policy, but this is not enforced...\n\n    OAI\n        The value of `Name` passed to the state definition for the origin\n        access identity which will be accessing the bucket.\n\n    Policy\n        The full policy document which should be set on the S3 bucket. If a\n        ``Principal`` clause is not provided in the policy, one will be\n        automatically added, and pointed at the correct value as dereferenced\n        from the OAI provided above. If one IS provided, then this is not\n        done, and you are responsible for providing the correct values.\n\n    region (string)\n        Region to connect to.\n\n    key (string)\n        Secret key to use.\n\n    keyid (string)\n        Access key to use.\n\n    profile (dict or string)\n        Dict, or pillar key pointing to a dict, containing AWS region/key/keyid.\n\n    Example:\n\n    .. code-block:: yaml\n\n        my_oai_s3_policy:\n          boto_cloudfront.oai_bucket_policy_present:\n          - Bucket: the_bucket_for_my_distribution\n          - OAI: the_OAI_I_just_created_and_attached_to_my_distribution\n          - Policy:\n              Version: 2012-10-17\n              Statement:\n              - Effect: Allow\n                Action: s3:GetObject\n                Resource: arn:aws:s3:::the_bucket_for_my_distribution/*",
        "positive_code": "def oai_bucket_policy_present(name, Bucket, OAI, Policy,\n                              region=None, key=None, keyid=None, profile=None):\n    \n    ret = {: name, : True, : , : {}}\n    oais = __salt__[](\n            Comment=OAI, region=region, key=key, keyid=keyid, profile=profile)\n    if len(oais) > 1:\n        msg = .format(OAI)\n        log.error(msg)\n        ret[] = msg\n        ret[] = False\n        return ret\n    if not oais:\n        msg = .format(OAI)\n        log.error(msg)\n        ret[] = msg\n        ret[] = False\n        return ret\n    canonical_user = oais[0].get()\n    oai_id = oais[0].get()\n    if isinstance(Policy, six.string_types):\n        Policy = json.loads(Policy)\n    for stanza in range(len(Policy.get(, []))):\n        if  not in Policy[][stanza]:\n            Policy[][stanza][] = {\"CanonicalUser\": canonical_user}\n    bucket = __salt__[](Bucket=Bucket, region=region, key=key,\n            keyid=keyid, profile=profile)\n    if not bucket or  not in bucket:\n        msg = .format(Bucket)\n        log.error(msg)\n        ret[] = msg\n        ret[] = False\n        return ret\n    curr_policy = bucket[].get(, {}).get(, {})  \n    return ret",
        "hard_negative_ids": [
            360,
            124,
            189,
            73,
            171,
            69,
            466,
            414,
            349,
            232,
            136,
            295,
            382,
            178,
            291,
            269,
            210,
            47,
            67,
            413,
            429,
            329,
            11,
            425,
            196,
            179,
            40,
            130,
            15,
            387,
            462,
            182,
            158,
            345,
            23,
            260,
            391,
            342,
            192,
            470,
            185,
            197,
            222,
            386,
            332,
            499,
            99,
            146,
            109,
            217
        ]
    },
    {
        "query": "Setter method for ipv6_phy_intf_cmds, mapped from YANG variable /interface/fortygigabitethernet/ipv6/ipv6_phy_intf_cmds (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ipv6_phy_intf_cmds is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ipv6_phy_intf_cmds() directly.",
        "positive_code": "def _set_ipv6_phy_intf_cmds(self, v, load=False):\n    \n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ipv6_phy_intf_cmds.ipv6_phy_intf_cmds, is_container=, presence=False, yang_name=\"ipv6-phy-intf-cmds\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u: {u: u, u: None, u: u}}, namespace=, defining_module=, yang_type=, is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          : ,\n          : \"container\",\n          : ,\n        })\n\n    self.__ipv6_phy_intf_cmds = t\n    if hasattr(self, ):\n      self._set()",
        "hard_negative_ids": [
            373,
            324,
            323,
            498,
            189,
            409,
            171,
            69,
            315,
            414,
            391,
            275,
            454,
            429,
            41,
            178,
            425,
            227,
            360,
            291,
            405,
            466,
            462,
            402,
            44,
            70,
            207,
            228,
            139,
            500,
            99,
            457,
            449,
            317,
            130,
            47,
            304,
            192,
            117,
            73,
            361,
            363,
            5,
            188,
            106,
            265,
            23,
            197,
            181,
            382
        ]
    },
    {
        "query": "Log formatter used in our syslog\n\n    :param request: a request object\n    :returns: logging.Formatter",
        "positive_code": "def log_formatter(request=None):\n    \n\n    if request:\n        format_str = (\n                      \n                      )\n    else:\n        format_str = \n\n    try:\n        hostname = socket.gethostname()\n    except socket.gaierror:\n        hostname = \n\n    try:\n        ip = socket.gethostbyname(hostname)\n    except socket.gaierror:\n        ip = \n\n    formatter = logging.Formatter(\n            format_str.format(ip=ip, name=options.name, env=options.env),\n            datefmt=)\n    logging.Formatter.converter = time.gmtime\n\n    return formatter",
        "hard_negative_ids": [
            139,
            491,
            79,
            81,
            113,
            129,
            131,
            402,
            488,
            422,
            344,
            222,
            425,
            415,
            470,
            130,
            427,
            10,
            391,
            204,
            369,
            106,
            285,
            304,
            297,
            50,
            300,
            178,
            317,
            453,
            446,
            281,
            376,
            105,
            197,
            307,
            15,
            360,
            140,
            266,
            296,
            171,
            124,
            275,
            264,
            340,
            13,
            361,
            73,
            439
        ]
    },
    {
        "query": "Resolve given variable",
        "positive_code": "def resolve(self, _):\n        \n        if self.default_value == DUMMY_VALUE:\n            if self.name in os.environ:\n                return os.environ[self.name]\n            else:\n                raise VelException(f\"Undefined environment variable: {self.name}\")\n        else:\n            return os.environ.get(self.name, self.default_value)",
        "hard_negative_ids": [
            373,
            324,
            73,
            179,
            99,
            17,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453
        ]
    },
    {
        "query": "Given an instance of TemporalMemory, print out the relevant parameters",
        "positive_code": "def printTemporalMemory(tm, outFile):\n  \n  table = PrettyTable([\"Parameter name\", \"Value\", ])\n\n  table.add_row([\"columnDimensions\", tm.getColumnDimensions()])\n  table.add_row([\"cellsPerColumn\", tm.getCellsPerColumn()])\n  table.add_row([\"activationThreshold\", tm.getActivationThreshold()])\n  table.add_row([\"minThreshold\", tm.getMinThreshold()])\n  table.add_row([\"maxNewSynapseCount\", tm.getMaxNewSynapseCount()])\n  table.add_row([\"permanenceIncrement\", tm.getPermanenceIncrement()])\n  table.add_row([\"permanenceDecrement\", tm.getPermanenceDecrement()])\n  table.add_row([\"initialPermanence\", tm.getInitialPermanence()])\n  table.add_row([\"connectedPermanence\", tm.getConnectedPermanence()])\n  table.add_row([\"predictedSegmentDecrement\", tm.getPredictedSegmentDecrement()])\n\n  print >>outFile, table.get_string().encode(\"utf-8\")",
        "hard_negative_ids": [
            269,
            73,
            135,
            435,
            360,
            414,
            219,
            23,
            466,
            171,
            197,
            333,
            163,
            429,
            189,
            131,
            439,
            349,
            395,
            157,
            76,
            291,
            470,
            232,
            239,
            472,
            234,
            467,
            136,
            427,
            233,
            99,
            376,
            44,
            318,
            266,
            490,
            182,
            173,
            47,
            25,
            343,
            272,
            289,
            34,
            426,
            101,
            109,
            474,
            473
        ]
    },
    {
        "query": "confirm_key - takes `name`, `confirm_name` and `trafaret`.\n\n    Checks if data['name'] equals data['confirm_name'] and both\n    are valid against `trafaret`.",
        "positive_code": "def confirm_key(name, confirm_name, trafaret):\n    \n    def check_(value):\n        first, second = None, None\n        if name in value:\n            first = value[name]\n        else:\n            yield name, t.DataError(), (name,)\n        if confirm_name in value:\n            second = value[confirm_name]\n        else:\n            yield confirm_name, t.DataError(), (confirm_name,)\n        if not (first and second):\n            return\n        yield name, t.catch_error(trafaret, first), (name,)\n        yield confirm_name, t.catch_error(trafaret, second), (confirm_name,)\n        if first != second:\n            yield confirm_name, t.DataError(.format(name)), (confirm_name,)\n    return check_",
        "hard_negative_ids": [
            498,
            421,
            424,
            201,
            324,
            223,
            429,
            176,
            328,
            283,
            185,
            33,
            195,
            440,
            357,
            494,
            85,
            154,
            203,
            499,
            393,
            65,
            412,
            157,
            492,
            66,
            150,
            484,
            78,
            454,
            256,
            425,
            252,
            466,
            366,
            184,
            318,
            163,
            76,
            47,
            222,
            141,
            22,
            386,
            91,
            321,
            25,
            391,
            131,
            353
        ]
    },
    {
        "query": "Dehydrator for `datetime` values.\n\n    :param value:\n    :type value: datetime\n    :return:",
        "positive_code": "def dehydrate_datetime(value):\n    \n\n    def seconds_and_nanoseconds(dt):\n        if isinstance(dt, datetime):\n            dt = DateTime.from_native(dt)\n        zone_epoch = DateTime(1970, 1, 1, tzinfo=dt.tzinfo)\n        t = dt.to_clock_time() - zone_epoch.to_clock_time()\n        return t.seconds, t.nanoseconds\n\n    tz = value.tzinfo\n    if tz is None:\n        \n        value = utc.localize(value)\n        seconds, nanoseconds = seconds_and_nanoseconds(value)\n        return Structure(b\"d\", seconds, nanoseconds)\n    elif hasattr(tz, \"zone\") and tz.zone:\n        \n        seconds, nanoseconds = seconds_and_nanoseconds(value)\n        return Structure(b\"f\", seconds, nanoseconds, tz.zone)\n    else:\n        \n        seconds, nanoseconds = seconds_and_nanoseconds(value)\n        return Structure(b\"F\", seconds, nanoseconds, tz.utcoffset(value).seconds)",
        "hard_negative_ids": [
            460,
            332,
            56,
            232,
            267,
            481,
            280,
            166,
            441,
            15,
            81,
            199,
            142,
            366,
            362,
            91,
            11,
            424,
            349,
            382,
            19,
            242,
            204,
            222,
            344,
            182,
            333,
            300,
            375,
            103,
            253,
            279,
            133,
            105,
            115,
            411,
            20,
            226,
            90,
            311,
            195,
            384,
            272,
            273,
            113,
            353,
            117,
            448,
            192,
            303
        ]
    },
    {
        "query": "Go through a stream and print out anything not in observed set",
        "positive_code": "def _traverse_unobserved(stream,negative_filter,of):\n  \n  observed = set()\n  for line in stream:\n    name = PacBioReadName(_nameprog.match(line).group(1))\n    if name.get_molecule() not in negative_filter: of.write(line)\n    observed.add(name.get_molecule())\n  return negative_filter|observed",
        "hard_negative_ids": [
            269,
            407,
            171,
            135,
            435,
            128,
            258,
            432,
            76,
            131,
            163,
            239,
            106,
            304,
            472,
            23,
            490,
            391,
            289,
            178,
            439,
            25,
            184,
            317,
            360,
            453,
            425,
            234,
            90,
            97,
            349,
            467,
            462,
            272,
            15,
            11,
            173,
            345,
            376,
            157,
            222,
            24,
            182,
            382,
            61,
            46,
            109,
            470,
            477,
            47
        ]
    },
    {
        "query": "Inject string $b16_scheme into self.content.",
        "positive_code": "def inject_scheme(self, b16_scheme):\n        \n        \n        \n        content_lines = self.content.splitlines()\n        b16_scheme_lines = b16_scheme.splitlines()\n        start_line = None\n        for num, line in enumerate(content_lines):\n            if not start_line:\n                match = TEMP_NEEDLE.match(line)\n                if match:\n                    start_line = num + 1\n            else:\n                match = TEMP_END_NEEDLE.match(line)\n                if match:\n                    end_line = num\n\n        \n        new_content_lines = (content_lines[0:start_line]\n                             + b16_scheme_lines\n                             + content_lines[end_line:])\n        self.content = .join(new_content_lines)",
        "hard_negative_ids": [
            210,
            273,
            413,
            40,
            62,
            342,
            275,
            73,
            498,
            55,
            406,
            423,
            150,
            398,
            351,
            478,
            251,
            487,
            362,
            3,
            196,
            56,
            224,
            313,
            328,
            176,
            168,
            408,
            108,
            170,
            447,
            389,
            338,
            276,
            112,
            361,
            247,
            432,
            45,
            22,
            455,
            320,
            122,
            476,
            411,
            460,
            372,
            482,
            459,
            114
        ]
    },
    {
        "query": "Yield client urns.",
        "positive_code": "def GetInput(self):\n    \n    client_list = GetAllClients(token=self.token)\n    logging.debug(\"Got %d clients\", len(client_list))\n    for client_group in collection.Batch(client_list, self.client_chunksize):\n      for fd in aff4.FACTORY.MultiOpen(\n          client_group,\n          mode=\"r\",\n          aff4_type=aff4_grr.VFSGRRClient,\n          token=self.token):\n        if isinstance(fd, aff4_grr.VFSGRRClient):\n          \n          oldest_time = (time.time() - self.max_age) * 1e6\n        if fd.Get(aff4_grr.VFSGRRClient.SchemaCls.PING) >= oldest_time:\n          yield fd",
        "hard_negative_ids": [
            423,
            441,
            29,
            301,
            144,
            191,
            103,
            246,
            477,
            24,
            291,
            113,
            288,
            195,
            311,
            384,
            427,
            120,
            298,
            319,
            28,
            27,
            26,
            25,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461
        ]
    },
    {
        "query": "Prompts the user to provide a credential for an encrypted volume.\n\n    Args:\n      scan_context (SourceScannerContext): the source scanner context.\n      locked_scan_node (SourceScanNode): the locked scan node.\n      output_writer (StdoutWriter): the output writer.",
        "positive_code": "def _PromptUserForEncryptedVolumeCredential(\n      self, scan_context, locked_scan_node, output_writer):\n    \n    credentials = credentials_manager.CredentialsManager.GetCredentials(\n        locked_scan_node.path_spec)\n\n    \n    if locked_scan_node.type_indicator == (\n        definitions.TYPE_INDICATOR_APFS_CONTAINER):\n      line = \n    elif locked_scan_node.type_indicator == definitions.TYPE_INDICATOR_BDE:\n      line = \n    elif locked_scan_node.type_indicator == definitions.TYPE_INDICATOR_FVDE:\n      line = \n    else:\n      line = \n\n    output_writer.WriteLine(line)\n\n    credentials_list = list(credentials.CREDENTIALS)\n    credentials_list.append()\n\n    \n    output_writer.WriteLine()\n    output_writer.WriteLine()\n    for index, name in enumerate(credentials_list):\n      output_writer.WriteLine(.format(index + 1, name))\n    output_writer.WriteLine()\n\n    result = False\n    while not result:\n      output_writer.WriteString(\n          )\n      \n      input_line = sys.stdin.readline()\n      input_line = input_line.strip()\n\n      if input_line in credentials_list:\n        credential_identifier = input_line\n      else:\n        try:\n          credential_identifier = int(input_line, 10)\n          credential_identifier = credentials_list[credential_identifier - 1]\n        except (IndexError, ValueError):\n          output_writer.WriteLine(\n              .format(input_line))\n          continue\n\n      if credential_identifier == :\n        break\n\n      getpass_string = \n      if sys.platform.startswith() and sys.version_info[0] < 3:\n        \n        \n        getpass_string = self._EncodeString(getpass_string)\n\n      credential_data = getpass.getpass(getpass_string)\n      output_writer.WriteLine()\n\n      result = self._source_scanner.Unlock(\n          scan_context, locked_scan_node.path_spec, credential_identifier,\n          credential_data)\n\n      if not result:\n        output_writer.WriteLine()\n        output_writer.WriteLine()",
        "hard_negative_ids": [
            360,
            269,
            423,
            414,
            136,
            244,
            453,
            305,
            425,
            73,
            174,
            376,
            466,
            287,
            126,
            187,
            129,
            215,
            488,
            55,
            330,
            41,
            117,
            197,
            18,
            291,
            189,
            131,
            311,
            5,
            219,
            147,
            379,
            103,
            227,
            171,
            390,
            112,
            9,
            106,
            385,
            366,
            304,
            324,
            415,
            316,
            272,
            329,
            252,
            34
        ]
    },
    {
        "query": "Program entry point.\n\n    Load the entire Unicode table into memory, excluding those that:\n\n        - are not named (func unicodedata.name returns empty string),\n        - are combining characters.\n\n    Using ``locale``, for each unicode character string compare libc's\n    wcwidth with local wcwidth.wcwidth() function; when they differ,\n    report a detailed AssertionError to stdout.",
        "positive_code": "def main(using_locale=(, ,)):\n    \n    all_ucs = (ucs for ucs in\n               [unichr(val) for val in range(sys.maxunicode)]\n               if is_named(ucs) and isnt_combining(ucs))\n\n    libc_name = ctypes.util.find_library()\n    if not libc_name:\n        raise ImportError(\"Canwcwidthwcswidth', None) is not None\n\n    locale.setlocale(locale.LC_ALL, using_locale)\n\n    for ucs in all_ucs:\n        try:\n            _is_equal_wcwidth(libc, ucs)\n        except AssertionError as err:\n            print(err)",
        "hard_negative_ids": [
            268,
            481,
            360,
            291,
            42,
            210,
            413,
            478,
            40,
            137,
            342,
            246,
            287,
            217,
            166,
            73,
            450,
            1,
            453,
            337,
            466,
            429,
            264,
            329,
            112,
            181,
            391,
            173,
            188,
            29,
            103,
            425,
            499,
            178,
            414,
            386,
            498,
            142,
            76,
            141,
            119,
            235,
            136,
            109,
            44,
            275,
            297,
            366,
            176,
            90
        ]
    },
    {
        "query": "This function imports all sub-modules of the supplied module and returns a dictionary\n    with module names as keys and the sub-module objects as values. If the supplied parameter\n    is not a module object, a RuntimeError is raised.\n\n    :param module: Module object from which to import sub-modules.\n    :return: Dict with name-module pairs.",
        "positive_code": "def get_submodules(module):\n    \n    if not inspect.ismodule(module):\n        raise RuntimeError(\n            \n            )\n\n    submodules = get_members(module, inspect.ismodule)\n\n    module_path = list(getattr(module, , [None]))[0]\n\n    if module_path is not None:\n        for item in listdir(module_path):\n            module_name = extract_module_name(osp.join(module_path, item))\n\n            if module_name is not None:\n                try:\n                    submodules[module_name] = importlib.import_module(\n                        .format(module_name), package=module.__name__)\n                except ImportError:\n                    \n                    \n                    pass\n\n    return submodules",
        "hard_negative_ids": [
            234,
            215,
            193,
            367,
            79,
            466,
            382,
            178,
            311,
            142,
            360,
            470,
            76,
            81,
            391,
            349,
            414,
            69,
            444,
            15,
            321,
            131,
            42,
            332,
            429,
            11,
            197,
            308,
            498,
            291,
            113,
            235,
            171,
            73,
            304,
            146,
            188,
            388,
            264,
            26,
            345,
            106,
            47,
            445,
            25,
            90,
            91,
            269,
            2,
            176
        ]
    },
    {
        "query": "Build the String instance\n\n        :param list pre: The prerequisites list (optional, default=None)\n        :param bool shortest: Whether or not the shortest reference-chain (most minimal) version of the field should be generated.",
        "positive_code": "def build(self, pre=None, shortest=False):\n        \n        if pre is None:\n            pre = []\n\n        if self.value is not None and rand.maybe():\n            return utils.val(self.value, pre, shortest=shortest)\n\n        length = super(String, self).build(pre, shortest=shortest)\n        res = rand.data(length, self.charset)\n        return res",
        "hard_negative_ids": [
            466,
            73,
            360,
            81,
            210,
            291,
            168,
            424,
            413,
            429,
            460,
            192,
            77,
            306,
            489,
            40,
            269,
            197,
            386,
            232,
            136,
            435,
            342,
            23,
            344,
            8,
            165,
            462,
            182,
            414,
            405,
            84,
            204,
            219,
            278,
            105,
            76,
            470,
            260,
            349,
            333,
            300,
            179,
            2,
            25,
            61,
            331,
            109,
            44,
            47
        ]
    },
    {
        "query": "Assesses production capacity.\n\n    Assesses the capacity of the model to produce the precursors for the\n    reaction and absorb the production of the reaction while the reaction is\n    operating at, or above, the specified cutoff.\n\n    Parameters\n    ----------\n    model : cobra.Model\n        The cobra model to assess production capacity for\n\n    reaction : reaction identifier or cobra.Reaction\n        The reaction to assess\n\n    flux_coefficient_cutoff :  float\n        The minimum flux that reaction must carry to be considered active.\n\n    solver : basestring\n        Solver name. If None, the default solver will be used.\n\n    Returns\n    -------\n    bool or dict\n        True if the model can produce the precursors and absorb the products\n        for the reaction operating at, or above, flux_coefficient_cutoff.\n        Otherwise, a dictionary of {'precursor': Status, 'product': Status}.\n        Where Status is the results from assess_precursors and\n        assess_products, respectively.",
        "positive_code": "def assess(model, reaction, flux_coefficient_cutoff=0.001, solver=None):\n    \n    reaction = model.reactions.get_by_any(reaction)[0]\n    with model as m:\n        m.objective = reaction\n        if _optimize_or_value(m, solver=solver) >= flux_coefficient_cutoff:\n            return True\n        else:\n            results = dict()\n            results[] = assess_component(\n                model, reaction, , flux_coefficient_cutoff)\n            results[] = assess_component(\n                model, reaction, , flux_coefficient_cutoff)\n            return results",
        "hard_negative_ids": [
            360,
            349,
            232,
            489,
            161,
            414,
            89,
            136,
            466,
            333,
            376,
            295,
            73,
            382,
            429,
            197,
            470,
            198,
            291,
            386,
            199,
            318,
            76,
            12,
            178,
            23,
            306,
            168,
            25,
            2,
            487,
            97,
            424,
            391,
            201,
            462,
            308,
            109,
            273,
            131,
            56,
            345,
            105,
            255,
            152,
            179,
            467,
            171,
            24,
            84
        ]
    },
    {
        "query": "this method returns the url to set the archive layout",
        "positive_code": "def set_archive_layout_url(self, archive_id):\n        \n        url = self.api_url +  + self.api_key +  + archive_id + \n        return url",
        "hard_negative_ids": [
            323,
            88,
            414,
            402,
            327,
            360,
            41,
            389,
            429,
            90,
            189,
            70,
            44,
            73,
            466,
            139,
            25,
            197,
            38,
            322,
            161,
            291,
            187,
            47,
            357,
            339,
            364,
            136,
            249,
            109,
            9,
            116,
            275,
            23,
            463,
            369,
            171,
            11,
            97,
            269,
            434,
            230,
            131,
            368,
            376,
            295,
            87,
            264,
            138,
            289
        ]
    },
    {
        "query": "Returns whether the value has a mixture representation.\n\n    Returns:\n        If `val` has a `_has_mixture_` method and its result is not\n        NotImplemented, that result is returned. Otherwise, if the value\n        has a `_mixture_` method return True if that has a non-default value.\n        Returns False if neither function exists.",
        "positive_code": "def has_mixture(val: Any) -> bool:\n    \n    getter = getattr(val, , None)\n    result = NotImplemented if getter is None else getter()\n    if result is not NotImplemented:\n        return result\n\n    \n    return mixture(val, None) is not None",
        "hard_negative_ids": [
            360,
            250,
            424,
            211,
            323,
            56,
            222,
            349,
            151,
            452,
            168,
            268,
            199,
            382,
            223,
            42,
            41,
            44,
            306,
            142,
            481,
            15,
            267,
            332,
            178,
            304,
            201,
            375,
            391,
            166,
            197,
            76,
            441,
            106,
            70,
            38,
            226,
            91,
            405,
            84,
            2,
            402,
            235,
            329,
            139,
            11,
            363,
            466,
            366,
            362
        ]
    },
    {
        "query": "adds a new repository file for apt",
        "positive_code": "def apt_add_repository_from_apt_string(apt_string, apt_file):\n    \n\n    apt_file_path =  % apt_file\n\n    if not file_contains(apt_file_path, apt_string.lower(), use_sudo=True):\n        file_append(apt_file_path, apt_string.lower(), use_sudo=True)\n\n        with hide(, ):\n            sudo(\"DEBIAN_FRONTEND=noninteractive apt-get update\")",
        "hard_negative_ids": [
            82,
            284,
            171,
            363,
            453,
            189,
            106,
            304,
            391,
            215,
            58,
            317,
            289,
            178,
            467,
            425,
            15,
            360,
            272,
            144,
            376,
            169,
            23,
            1,
            470,
            256,
            275,
            382,
            44,
            222,
            277,
            462,
            76,
            127,
            264,
            99,
            349,
            414,
            472,
            466,
            180,
            135,
            489,
            321,
            35,
            234,
            223,
            377,
            142,
            29
        ]
    },
    {
        "query": "Link the contacts with contactgroups\n\n        :param contacts: realms object to link with\n        :type contacts: alignak.objects.contact.Contacts\n        :return: None",
        "positive_code": "def linkify_contactgroups_contacts(self, contacts):\n        \n        for contactgroup in self:\n            mbrs = contactgroup.get_contacts()\n\n            \n            new_mbrs = []\n            for mbr in mbrs:\n                mbr = mbr.strip()  \n                    continue\n                member = contacts.find_by_name(mbr)\n                \n                if member is not None:\n                    new_mbrs.append(member.uuid)\n                else:\n                    contactgroup.add_unknown_members(mbr)\n\n            \n            new_mbrs = list(set(new_mbrs))\n\n            \n            contactgroup.replace_members(new_mbrs)",
        "hard_negative_ids": [
            92,
            21,
            79,
            81,
            414,
            297,
            232,
            425,
            113,
            360,
            269,
            470,
            466,
            291,
            204,
            73,
            344,
            383,
            279,
            197,
            300,
            170,
            193,
            280,
            63,
            264,
            76,
            96,
            133,
            115,
            128,
            20,
            404,
            434,
            74,
            275,
            59,
            136,
            171,
            411,
            353,
            474,
            273,
            439,
            468,
            397,
            226,
            23,
            117,
            131
        ]
    },
    {
        "query": "Compute the SAG algorithm to solve the regularized discrete measures\n        optimal transport max problem\n\n    The function solves the following optimization problem:\n\n    .. math::\n        \\gamma = arg\\min_\\gamma <\\gamma,M>_F + reg\\cdot\\Omega(\\gamma)\n\n        s.t. \\gamma 1 = a\n\n             \\gamma^T 1 = b\n\n             \\gamma \\geq 0\n\n    Where :\n\n    - M is the (ns,nt) metric cost matrix\n    - :math:`\\Omega` is the entropic regularization term with :math:`\\Omega(\\gamma)=\\sum_{i,j} \\gamma_{i,j}\\log(\\gamma_{i,j})`\n    - a and b are source and target weights (sum to 1)\n\n    The algorithm used for solving the problem is the SAG algorithm\n    as proposed in [18]_ [alg.1]\n\n\n    Parameters\n    ----------\n\n    a : np.ndarray(ns,),\n        source measure\n    b : np.ndarray(nt,),\n        target measure\n    M : np.ndarray(ns, nt),\n        cost matrix\n    reg : float number,\n        Regularization term > 0\n    numItermax : int number\n        number of iteration\n    lr : float number\n        learning rate\n\n    Returns\n    -------\n\n    v : np.ndarray(nt,)\n        dual variable\n\n    Examples\n    --------\n\n    >>> n_source = 7\n    >>> n_target = 4\n    >>> reg = 1\n    >>> numItermax = 300000\n    >>> a = ot.utils.unif(n_source)\n    >>> b = ot.utils.unif(n_target)\n    >>> rng = np.random.RandomState(0)\n    >>> X_source = rng.randn(n_source, 2)\n    >>> Y_target = rng.randn(n_target, 2)\n    >>> M = ot.dist(X_source, Y_target)\n    >>> method = \"ASGD\"\n    >>> asgd_pi = stochastic.solve_semi_dual_entropic(a, b, M, reg,\n                                                      method, numItermax)\n    >>> print(asgd_pi)\n\n    References\n    ----------\n\n    [Genevay et al., 2016] :\n                    Stochastic Optimization for Large-scale Optimal Transport,\n                     Advances in Neural Information Processing Systems (2016),\n                      arXiv preprint arxiv:1605.08527.",
        "positive_code": "def sag_entropic_transport(a, b, M, reg, numItermax=10000, lr=None):\n    \n\n    if lr is None:\n        lr = 1. / max(a / reg)\n    n_source = np.shape(M)[0]\n    n_target = np.shape(M)[1]\n    cur_beta = np.zeros(n_target)\n    stored_gradient = np.zeros((n_source, n_target))\n    sum_stored_gradient = np.zeros(n_target)\n    for _ in range(numItermax):\n        i = np.random.randint(n_source)\n        cur_coord_grad = a[i] * coordinate_grad_semi_dual(b, M, reg,\n                                                          cur_beta, i)\n        sum_stored_gradient += (cur_coord_grad - stored_gradient[i])\n        stored_gradient[i] = cur_coord_grad\n        cur_beta += lr * (1. / n_source) * sum_stored_gradient\n    return cur_beta",
        "hard_negative_ids": [
            160,
            391,
            149,
            252,
            381,
            142,
            106,
            12,
            48,
            23,
            58,
            177,
            122,
            245,
            88,
            462,
            53,
            466,
            60,
            414,
            429,
            317,
            256,
            197,
            238,
            240,
            77,
            56,
            360,
            41,
            134,
            490,
            79,
            442,
            135,
            280,
            206,
            324,
            293,
            109,
            15,
            182,
            269,
            171,
            373,
            101,
            263,
            318,
            179,
            239
        ]
    },
    {
        "query": "Count how many levels are in a dict:\n        scalar, list etc = 0\n        {} = 0\n        {'a':1} = 1\n        {'a' : {'b' : 1}} = 2\n        etc...",
        "positive_code": "def count_levels(value):\n    \n    if not isinstance(value, dict) or len(value) == 0:\n        return 0\n    elif len(value) == 0:\n        return 0 \n    else:\n        nextval = list(value.values())[0]\n        return 1 + count_levels(nextval)",
        "hard_negative_ids": [
            106,
            391,
            288,
            60,
            149,
            48,
            178,
            15,
            77,
            2,
            32,
            58,
            383,
            304,
            360,
            361,
            240,
            43,
            14,
            317,
            26,
            453,
            294,
            256,
            382,
            239,
            338,
            252,
            183,
            466,
            425,
            171,
            12,
            424,
            489,
            462,
            105,
            182,
            349,
            162,
            242,
            19,
            386,
            136,
            499,
            347,
            198,
            260,
            265,
            127
        ]
    },
    {
        "query": "Show the log from the device",
        "positive_code": "def cmd_logcat(self, *args):\n        \n        self.check_requirements()\n        serial = self.serials[0:]\n        if not serial:\n            return\n        filters = self.buildozer.config.getrawdefault(\n            \"app\", \"android.logcat_filters\", \"\", section_sep=\":\", split_char=\" \")\n        filters = \" \".join(filters)\n        self.buildozer.environ[] = serial[0]\n        self.buildozer.cmd(.format(adb=self.adb_cmd,\n                                                           filters=filters),\n                           cwd=self.buildozer.global_platform_dir,\n                           show_output=True)\n        self.buildozer.environ.pop(, None)",
        "hard_negative_ids": [
            197,
            73,
            360,
            414,
            291,
            228,
            466,
            50,
            47,
            136,
            193,
            446,
            376,
            7,
            281,
            26,
            429,
            44,
            307,
            367,
            131,
            140,
            266,
            11,
            124,
            296,
            264,
            23,
            340,
            275,
            25,
            69,
            153,
            13,
            361,
            67,
            185,
            439,
            254,
            147,
            231,
            34,
            391,
            208,
            375,
            343,
            252,
            109,
            186,
            469
        ]
    },
    {
        "query": "Start the Blockade REST API",
        "positive_code": "def cmd_daemon(opts):\n    \n    if opts.data_dir is None:\n        raise BlockadeError(\"You must supply a data directory for the daemon\")\n    rest.start(data_dir=opts.data_dir, port=opts.port, debug=opts.debug,\n        host_exec=get_host_exec())",
        "hard_negative_ids": [
            407,
            493,
            174,
            429,
            278,
            80,
            82,
            207,
            268,
            485,
            369,
            360,
            175,
            324,
            197,
            414,
            291,
            283,
            466,
            385,
            136,
            73,
            238,
            490,
            44,
            23,
            349,
            25,
            149,
            109,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464,
            463
        ]
    },
    {
        "query": "Convert latitude to degrees.",
        "positive_code": "def lat_to_deg(lat):\n    \n    if isinstance(lat, str) and ( in lat):\n        \n        lat_deg = dmsStrToDeg(lat)\n    else:\n        lat_deg = float(lat)\n    return lat_deg",
        "hard_negative_ids": [
            75,
            171,
            269,
            131,
            368,
            376,
            295,
            414,
            264,
            189,
            73,
            275,
            360,
            47,
            76,
            266,
            157,
            329,
            466,
            99,
            109,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464,
            463,
            462,
            461
        ]
    },
    {
        "query": "Prompts user to input a date in the past.",
        "positive_code": "def pastdate(self, prompt, default=None):\n        \n        prompt = prompt if prompt is not None else \"Enter a past date\"\n        if default is not None:\n            prompt += \" [\" + default.strftime() + \"]\"\n        prompt += \n        return self.input(curry(filter_pastdate, default=default), prompt)",
        "hard_negative_ids": [
            460,
            57,
            425,
            360,
            496,
            187,
            55,
            131,
            429,
            414,
            383,
            171,
            103,
            466,
            106,
            73,
            415,
            185,
            304,
            391,
            291,
            197,
            317,
            178,
            453,
            228,
            136,
            15,
            76,
            173,
            23,
            269,
            44,
            368,
            376,
            470,
            293,
            295,
            264,
            189,
            256,
            275,
            382,
            25,
            109,
            47,
            222,
            462,
            349,
            157
        ]
    },
    {
        "query": "This browse node's children in the browse node tree.\n\n    :return:\n    A list of this browse node's children in the browse node tree.",
        "positive_code": "def children(self):\n        \n        children = []\n        child_nodes = getattr(self.element, )\n        for child in getattr(child_nodes, , []):\n                children.append(AmazonBrowseNode(child))\n        return children",
        "hard_negative_ids": [
            500,
            305,
            377,
            311,
            174,
            126,
            366,
            18,
            215,
            446,
            388,
            197,
            379,
            272,
            90,
            466,
            360,
            414,
            77,
            31,
            386,
            477,
            15,
            144,
            429,
            20,
            349,
            470,
            47,
            189,
            291,
            464,
            178,
            106,
            304,
            73,
            275,
            44,
            462,
            76,
            391,
            136,
            23,
            78,
            407,
            317,
            395,
            232,
            453,
            201
        ]
    },
    {
        "query": "Array column number",
        "positive_code": "def columnCount(self, qindex=QModelIndex()):\r\n        \r\n        if self.total_cols <= self.cols_loaded:\r\n            return self.total_cols\r\n        else:\r\n            return self.cols_loaded",
        "hard_negative_ids": [
            142,
            88,
            252,
            424,
            44,
            12,
            100,
            299,
            81,
            256,
            105,
            192,
            293,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456
        ]
    },
    {
        "query": "Returns the best-fit parameters, choosing the best of multiple starting guesses\n\n        :param nseeds: (optional)\n            Number of starting guesses, uniformly distributed throughout\n            allowed ranges.  Default=50.\n\n        :return:\n            list of best-fit parameters: ``[mA,mB,age,feh,[distance,A_V]]``.\n            Note that distance and A_V values will be meaningless unless\n            magnitudes are present in ``self.properties``.",
        "positive_code": "def maxlike(self,nseeds=50):\n        \n        mA_0,age0,feh0 = self.ic.random_points(nseeds)\n        mB_0,foo1,foo2 = self.ic.random_points(nseeds)\n        mC_0,foo3,foo4 = self.ic.random_points(nseeds)\n        m_all = np.sort(np.array([mA_0, mB_0, mC_0]), axis=0)\n        mA_0, mB_0, mC_0 = (m_all[0,:], m_all[1,:], m_all[2,:])\n\n        d0 = 10**(rand.uniform(0,np.log10(self.max_distance),size=nseeds))\n        AV0 = rand.uniform(0,self.maxAV,size=nseeds)\n\n        \n\n        costs = np.zeros(nseeds)\n\n        if self.fit_for_distance:\n            pfits = np.zeros((nseeds,7))\n        else:\n            pfits = np.zeros((nseeds,5))\n            \n        def fn(p): \n            return -1*self.lnpost(p)\n        \n        for i,mA,mB,mC,age,feh,d,AV in zip(range(nseeds),\n                                    mA_0,mB_0,mC_0,age0,feh0,d0,AV0):\n                if self.fit_for_distance:\n                    pfit = scipy.optimize.fmin(fn,[mA,mB,mC,age,feh,d,AV],disp=False)\n                else:\n                    pfit = scipy.optimize.fmin(fn,[mA,mB,mC,age,feh],disp=False)\n                pfits[i,:] = pfit\n                costs[i] = self.lnpost(pfit)\n\n        return pfits[np.argmax(costs),:]",
        "hard_negative_ids": [
            424,
            435,
            142,
            391,
            429,
            360,
            332,
            466,
            168,
            232,
            430,
            349,
            152,
            460,
            291,
            426,
            344,
            199,
            81,
            197,
            306,
            470,
            395,
            84,
            23,
            252,
            136,
            318,
            185,
            76,
            405,
            25,
            414,
            12,
            56,
            267,
            77,
            490,
            105,
            204,
            496,
            233,
            350,
            382,
            53,
            182,
            15,
            109,
            300,
            333
        ]
    },
    {
        "query": "Return the value of the android prefixed attribute in a specific tag.\n\n        This function will always try to get the attribute with a android: prefix first,\n        and will try to return the attribute without the prefix, if the attribute could not be found.\n        This is useful for some broken AndroidManifest.xml, where no android namespace is set,\n        but could also indicate malicious activity (i.e. wrongly repackaged files).\n        A warning is printed if the attribute is found without a namespace prefix.\n\n        If you require to get the exact result you need to query the tag directly:\n\n        example::\n            >>> from lxml.etree import Element\n            >>> tag = Element('bar', nsmap={'android': 'http://schemas.android.com/apk/res/android'})\n            >>> tag.set('{http://schemas.android.com/apk/res/android}foobar', 'barfoo')\n            >>> tag.set('name', 'baz')\n            # Assume that `a` is some APK object\n            >>> a.get_value_from_tag(tag, 'name')\n            'baz'\n            >>> tag.get('name')\n            'baz'\n            >>> tag.get('foobar')\n            None\n            >>> a.get_value_from_tag(tag, 'foobar')\n            'barfoo'\n\n        :param lxml.etree.Element tag: specify the tag element\n        :param str attribute: specify the attribute name\n        :returns: the attribute's value, or None if the attribute is not present",
        "positive_code": "def get_value_from_tag(self, tag, attribute):\n        \n\n        \n        \n        value = tag.get(self._ns(attribute))\n        if value is None:\n            value = tag.get(attribute)\n\n            if value:\n                \n                log.warning(\"Failed to get the attribute  on tag  with namespace. \"\n                            \"But found the same attribute without namespace!\".format(attribute, tag.tag))\n        return value",
        "hard_negative_ids": [
            91,
            360,
            311,
            379,
            429,
            475,
            349,
            500,
            291,
            189,
            433,
            73,
            461,
            466,
            414,
            382,
            275,
            197,
            391,
            498,
            149,
            159,
            265,
            226,
            341,
            222,
            348,
            69,
            295,
            136,
            435,
            23,
            11,
            264,
            207,
            386,
            441,
            182,
            81,
            90,
            462,
            171,
            204,
            201,
            56,
            470,
            232,
            317,
            109,
            178
        ]
    },
    {
        "query": "Forces the contraction coefficient of uncontracted shells to 1.0",
        "positive_code": "def _fix_uncontracted(basis):\n    \n\n    for el in basis[].values():\n        if  not in el:\n            continue\n\n        for sh in el[]:\n            if len(sh[]) == 1 and len(sh[][0]) == 1:\n                sh[][0][0] = \n\n            \n\n    return basis",
        "hard_negative_ids": [
            466,
            414,
            197,
            360,
            349,
            429,
            73,
            232,
            157,
            291,
            44,
            275,
            395,
            470,
            171,
            136,
            188,
            14,
            318,
            269,
            131,
            386,
            240,
            23,
            109,
            368,
            376,
            25,
            295,
            264,
            189,
            47,
            361,
            272,
            162,
            329,
            177,
            60,
            88,
            155,
            245,
            347,
            401,
            256,
            77,
            174,
            346,
            486,
            298,
            202
        ]
    },
    {
        "query": "Convert labels according to crop box",
        "positive_code": "def _update_labels(self, label, crop_box, height, width):\n        \n        xmin = float(crop_box[0]) / width\n        ymin = float(crop_box[1]) / height\n        w = float(crop_box[2]) / width\n        h = float(crop_box[3]) / height\n        out = label.copy()\n        out[:, (1, 3)] -= xmin\n        out[:, (2, 4)] -= ymin\n        out[:, (1, 3)] /= w\n        out[:, (2, 4)] /= h\n        out[:, 1:5] = np.maximum(0, out[:, 1:5])\n        out[:, 1:5] = np.minimum(1, out[:, 1:5])\n        coverage = self._calculate_areas(out[:, 1:]) * w * h / self._calculate_areas(label[:, 1:])\n        valid = np.logical_and(out[:, 3] > out[:, 1], out[:, 4] > out[:, 2])\n        valid = np.logical_and(valid, coverage > self.min_eject_coverage)\n        valid = np.where(valid)[0]\n        if valid.size < 1:\n            return None\n        out = out[valid, :]\n        return out",
        "hard_negative_ids": [
            184,
            271,
            451,
            369,
            171,
            12,
            269,
            131,
            100,
            368,
            376,
            295,
            414,
            264,
            189,
            73,
            275,
            360,
            47,
            76,
            266,
            157,
            329,
            466,
            99,
            109,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464
        ]
    },
    {
        "query": "Make a solid to subtract from an interfacing solid to bore a pilot-hole.",
        "positive_code": "def make_pilothole_cutter(self):\n        \n        \n        \n        \n            .circle(pilothole_radius) \\\n            .extrude(self.length)",
        "hard_negative_ids": [
            360,
            171,
            391,
            189,
            73,
            106,
            131,
            136,
            304,
            414,
            453,
            178,
            76,
            317,
            425,
            269,
            15,
            193,
            256,
            466,
            7,
            26,
            462,
            368,
            376,
            67,
            470,
            349,
            295,
            264,
            472,
            69,
            367,
            382,
            275,
            11,
            427,
            99,
            153,
            47,
            185,
            157,
            222,
            147,
            231,
            266,
            208,
            109,
            329,
            343
        ]
    },
    {
        "query": "Ensures each value is ascii-only",
        "positive_code": "def force_ascii_values(data):\n    \n    return {\n        k: v.encode().decode(, )\n        for k, v in data.items()\n    }",
        "hard_negative_ids": [
            262,
            287,
            56,
            332,
            267,
            481,
            349,
            166,
            69,
            441,
            91,
            382,
            366,
            362,
            11,
            424,
            242,
            19,
            496,
            199,
            182,
            232,
            222,
            280,
            15,
            142,
            99,
            375,
            253,
            103,
            272,
            448,
            423,
            180,
            192,
            195,
            311,
            384,
            224,
            345,
            76,
            95,
            66,
            105,
            268,
            365,
            435,
            1,
            245,
            121
        ]
    },
    {
        "query": "Start a timer or restart an active one.\n\n        The timeout is given in milliseconds. If a timer with the\n        same name already exists, it is restarted with the specified timeout.\n        Note that the timeout is intended as the minimum time until the timer's\n        expiration, but may vary due to the state of the event queue and the\n        load of the system.",
        "positive_code": "def start_timer(self, timer_id, timeout):\n        \n        self._logger.debug(.format(timer_id, self.id))\n        self._driver._start_timer(timer_id, timeout, self)",
        "hard_negative_ids": [
            360,
            73,
            202,
            473,
            25,
            414,
            349,
            385,
            466,
            197,
            478,
            348,
            327,
            178,
            264,
            257,
            179,
            37,
            291,
            314,
            391,
            13,
            201,
            433,
            232,
            372,
            429,
            237,
            50,
            434,
            97,
            170,
            217,
            329,
            295,
            318,
            99,
            44,
            490,
            128,
            410,
            304,
            69,
            171,
            470,
            89,
            325,
            136,
            498,
            324
        ]
    },
    {
        "query": "wage dataset\n\n    Parameters\n    ----------\n    return_X_y : bool,\n        if True, returns a model-ready tuple of data (X, y)\n        otherwise, returns a Pandas DataFrame\n\n    Returns\n    -------\n    model-ready tuple of data (X, y)\n        OR\n    Pandas DataFrame\n\n    Notes\n    -----\n    X contains the year, age and education of each sampled person.\n    The education category has been transformed to integers.\n\n    y contains the wage.\n\n    Source:\n    https://github.com/JWarmenhoven/ISLR-python/blob/master/Notebooks/Data/Wage.csv",
        "positive_code": "def wage(return_X_y=True):\n    \n    \n    \n    wage = pd.read_csv(PATH + , index_col=0)\n    if return_X_y:\n        X = wage[[, , ]].values\n        X[:,-1] = np.unique(X[:,-1], return_inverse=True)[1]\n        y = wage[].values\n        return _clean_X_y(X, y)\n    return wage",
        "hard_negative_ids": [
            240,
            3,
            263,
            33,
            333,
            245,
            207,
            429,
            391,
            265,
            495,
            466,
            267,
            500,
            296,
            198,
            421,
            464,
            472,
            321,
            23,
            349,
            89,
            290,
            287,
            424,
            360,
            152,
            462,
            489,
            276,
            239,
            318,
            181,
            197,
            350,
            343,
            361,
            496,
            414,
            288,
            291,
            223,
            160,
            25,
            457,
            162,
            256,
            76,
            156
        ]
    },
    {
        "query": "Decode any parameter to a byte sequence.\n\n    :param data: byte sequence representing an LLRP parameter.\n    :returns dict, bytes: where dict is {'Type': <decoded type>, 'Data':\n        <decoded data>} and bytes is the remaining bytes trailing the bytes we\n        could decode.",
        "positive_code": "def decode_param(data):\n    \n    logger.debug(, data)\n    header_len = struct.calcsize()\n    partype, parlen = struct.unpack(, data[:header_len])\n\n    pardata = data[header_len:parlen]\n    logger.debug(, pardata)\n\n    ret = {\n        : partype,\n    }\n\n    if partype == 1023:\n        vsfmt = \n        vendor, subtype = struct.unpack(vsfmt, pardata[:struct.calcsize(vsfmt)])\n        ret[] = vendor\n        ret[] = subtype\n        ret[] = pardata[struct.calcsize(vsfmt):]\n    else:\n        ret[] = pardata,\n\n    return ret, data[parlen:]",
        "hard_negative_ids": [
            342,
            113,
            360,
            429,
            421,
            165,
            300,
            159,
            178,
            487,
            73,
            81,
            154,
            163,
            393,
            256,
            2,
            237,
            189,
            197,
            204,
            466,
            404,
            223,
            345,
            232,
            414,
            252,
            485,
            324,
            498,
            269,
            424,
            435,
            17,
            475,
            33,
            195,
            283,
            357,
            85,
            440,
            291,
            171,
            265,
            450,
            382,
            76,
            492,
            180
        ]
    },
    {
        "query": "This function finds URLs inside of valid HTML bytes.",
        "positive_code": "def _html_find_urls(bytes, mimetype, base_url=None):\n    \n\n    def _recursive_tag_values(tag, values=[]):\n        \n\n        if hasattr(tag, ):\n            for child in tag.children:\n                if hasattr(child, ):\n                    for key in child.attrs:\n                        if isinstance(child.attrs[key], list):\n                            for value in child.attrs[key]:\n                                values.append(value)\n                        elif isinstance(child.attrs[key], str):\n                            values.append(child.attrs[key])\n\n                    values = _recursive_tag_values(child, values)\n\n        return values\n\n    \n    ascii_bytes = b.join(re.compile(b).findall(bytes))\n    ascii_bytes = ascii_bytes.replace(b, b)\n\n    \n    urls = []\n\n    \n    soups = []\n    soups.append(BeautifulSoup(ascii_bytes, ))\n    try:\n        soups.append(BeautifulSoup(urllib.parse.unquote(str(ascii_bytes)), ))\n    except:\n        pass\n\n    \n    for soup in soups:\n\n        \n        \n        script_urls = []\n        script_tags = soup.find_all()\n        for script_tag in script_tags:\n            for tag_content in script_tag.contents:\n                if  in tag_content.lower():\n                    \n                    \n                    \n                    code_begin = tag_content.rfind()\n                    code_end = tag_content.find()\n                    code = tag_content[code_begin+1:code_end]\n                    \n        \n        else:\n            urls = _recursive_tag_values(soup)\n            urls += css_urls\n            urls += meta_urls\n            urls += script_urls\n\n        \n        \n        \n        \n        for s in soup.stripped_strings:\n            if is_valid(s):\n                urls.append(s)\n\n        \n        \n        \n        \n        urls = [u.strip() for u in urls]\n\n        \n\n    return urls",
        "hard_negative_ids": [
            42,
            117,
            342,
            429,
            235,
            47,
            71,
            189,
            142,
            222,
            389,
            349,
            90,
            197,
            395,
            470,
            232,
            466,
            38,
            322,
            161,
            187,
            300,
            357,
            339,
            122,
            274,
            364,
            60,
            86,
            249,
            210,
            402,
            9,
            318,
            163,
            204,
            463,
            369,
            414,
            192,
            479,
            157,
            275,
            230,
            353,
            443,
            272,
            138,
            228
        ]
    },
    {
        "query": "SQL Editor",
        "positive_code": "def sqllab(self):\n        \n        d = {\n            : config.get(),\n            : self.common_bootsrap_payload(),\n        }\n        return self.render_template(\n            ,\n            entry=,\n            bootstrap_data=json.dumps(d, default=utils.json_iso_dttm_ser),\n        )",
        "hard_negative_ids": [
            216,
            257,
            481,
            16,
            17,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453,
            452
        ]
    },
    {
        "query": "Returns a lifetime plot, see examples: https://lifelines.readthedocs.io/en/latest/Survival%20Analysis%20intro.html#Censoring\n\n    Parameters\n    -----------\n    durations: (n,) numpy array or pd.Series\n      duration subject was observed for.\n    event_observed: (n,) numpy array or pd.Series\n      array of booleans: True if event observed, else False.\n    entry: (n,) numpy array or pd.Series\n      offsetting the births away from t=0. This could be from left-truncation, or delayed entry into study.\n    left_truncated: boolean\n      if entry is provided, and the data is left-truncated, this will display additional information in the plot to reflect this.\n    sort_by_duration: boolean\n      sort by the duration vector\n    event_observed_color: str\n      default: \"#A60628\"\n    event_censored_color: str\n      default: \"#348ABD\"\n\n    Returns\n    -------\n    ax\n\n    Examples\n    ---------\n    >>> from lifelines.datasets import load_waltons\n    >>> from lifelines.plotting import plot_lifetimes\n    >>> T, E = load_waltons()[\"T\"], load_waltons()[\"E\"]\n    >>> ax = plot_lifetimes(T.loc[:50], event_observed=E.loc[:50])",
        "positive_code": "def plot_lifetimes(\n    durations,\n    event_observed=None,\n    entry=None,\n    left_truncated=False,\n    sort_by_duration=True,\n    event_observed_color=\"\n    event_censored_color=\"\n    **kwargs\n):\n    \n    set_kwargs_ax(kwargs)\n    ax = kwargs.pop(\"ax\")\n\n    N = durations.shape[0]\n    if N > 80:\n        warnings.warn(\"For less visual clutter, you may want to subsample to less than 80 individuals.\")\n\n    if event_observed is None:\n        event_observed = np.ones(N, dtype=bool)\n\n    if entry is None:\n        entry = np.zeros(N)\n\n    assert durations.shape[0] == N\n    assert event_observed.shape[0] == N\n\n    if sort_by_duration:\n        \n        ix = np.argsort(entry + durations, 0)\n        durations = durations[ix]\n        event_observed = event_observed[ix]\n        entry = entry[ix]\n\n    for i in range(N):\n        c = event_observed_color if event_observed[i] else event_censored_color\n        ax.hlines(i, entry[i], entry[i] + durations[i], color=c, lw=1.5)\n        if left_truncated:\n            ax.hlines(i, 0, entry[i], color=c, lw=1.0, linestyle=\"--\")\n        m = \"\" if not event_observed[i] else \"o\"\n        ax.scatter(entry[i] + durations[i], i, color=c, marker=m, s=10)\n\n    ax.set_ylim(-0.5, N)\n    return ax",
        "hard_negative_ids": [
            33,
            462,
            239,
            466,
            100,
            391,
            280,
            69,
            44,
            431,
            23,
            246,
            291,
            68,
            424,
            429,
            88,
            275,
            76,
            73,
            137,
            269,
            168,
            197,
            237,
            306,
            328,
            414,
            99,
            159,
            382,
            314,
            84,
            265,
            53,
            271,
            256,
            255,
            464,
            350,
            345,
            229,
            257,
            12,
            101,
            189,
            349,
            131,
            360,
            149
        ]
    },
    {
        "query": "Set fields to be key-value represented.\n\n        :rtype: Column\n\n        :Example:\n\n        >>> new_ds = df.key_value('f1 f2', kv=':', item=',')",
        "positive_code": "def key_value(self, **kwargs):\n        \n        field_name = self.name\n        new_df = copy_df(self)\n        new_df._perform_operation(op.FieldKVConfigOperation({field_name: KVConfig(**kwargs)}))\n        return new_df",
        "hard_negative_ids": [
            44,
            142,
            239,
            56,
            462,
            11,
            196,
            23,
            222,
            424,
            382,
            85,
            411,
            232,
            45,
            48,
            127,
            78,
            236,
            69,
            192,
            476,
            182,
            15,
            332,
            387,
            267,
            183,
            442,
            31,
            481,
            329,
            166,
            113,
            349,
            441,
            245,
            8,
            97,
            25,
            366,
            362,
            490,
            91,
            159,
            386,
            379,
            109,
            19,
            242
        ]
    },
    {
        "query": "Wrap a list of tuples in xml ready to pass into a SOAP request.\n\n        Args:\n            args (list):  a list of (name, value) tuples specifying the\n                name of each argument and its value, eg\n                ``[('InstanceID', 0), ('Speed', 1)]``. The value\n                can be a string or something with a string representation. The\n                arguments are escaped and wrapped in <name> and <value> tags.\n\n        Example:\n\n            >>> from soco import SoCo\n            >>> device = SoCo('192.168.1.101')\n            >>> s = Service(device)\n            >>> print(s.wrap_arguments([('InstanceID', 0), ('Speed', 1)]))\n            <InstanceID>0</InstanceID><Speed>1</Speed>'",
        "positive_code": "def wrap_arguments(args=None):\n        \n        if args is None:\n            args = []\n\n        tags = []\n        for name, value in args:\n            tag = \"<{name}>{value}</{name}>\".format(\n                name=name, value=escape(\"%s\" % value, {: \"&quot;\"}))\n            \n            \n            tags.append(tag)\n\n        xml = \"\".join(tags)\n        return xml",
        "hard_negative_ids": [
            159,
            429,
            287,
            269,
            210,
            475,
            349,
            182,
            466,
            386,
            197,
            291,
            56,
            470,
            149,
            391,
            366,
            413,
            131,
            232,
            360,
            69,
            424,
            382,
            76,
            162,
            171,
            332,
            40,
            77,
            179,
            462,
            267,
            485,
            147,
            342,
            11,
            500,
            324,
            15,
            73,
            379,
            498,
            222,
            23,
            25,
            91,
            219,
            245,
            252
        ]
    },
    {
        "query": "Executes given functions with given models.\n\n        Args:\n            models: models to execute\n            func: function name to execute\n\n        Returns:",
        "positive_code": "def creating_schema_and_index(self, models, func):\n        \n        waiting_models = []\n        self.base_thread.do_with_submit(func, models, waiting_models, threads=self.threads)\n        if waiting_models:\n            print(\"WAITING MODELS ARE CHECKING...\")\n            self.creating_schema_and_index(waiting_models, func)",
        "hard_negative_ids": [
            42,
            152,
            112,
            235,
            89,
            378,
            217,
            269,
            333,
            489,
            73,
            193,
            337,
            297,
            198,
            450,
            29,
            287,
            498,
            488,
            119,
            41,
            453,
            142,
            273,
            324,
            219,
            147,
            179,
            159,
            467,
            176,
            311,
            425,
            385,
            99,
            131,
            316,
            171,
            264,
            487,
            218,
            414,
            65,
            66,
            150,
            275,
            412,
            76,
            368
        ]
    },
    {
        "query": "args and kwargs intentionally not *args and **kwargs",
        "positive_code": "def hydrate_callable_with_edge_node_map(\n            self,\n            edge_node_map,\n            callable_function,\n            parameter_lambda\n        ):\n        \n\n        def extract_kwargs_dict(*args, **kwargs):\n            return kwargs\n\n        def extract_args_list(*args, **kwargs):\n            return list(args)\n\n        args = parameter_lambda(extract_args_list)\n        kwargs = parameter_lambda(extract_kwargs_dict)\n\n        arg_list = [edge_node_map[node_id] for node_id in list(args)]\n\n        kwarg_map = {}\n\n        for kwarg in kwargs:\n            kwarg_map[kwarg] = edge_node_map[kwargs[kwarg]]\n\n        return callable_function(*arg_list, **kwarg_map)",
        "hard_negative_ids": [
            287,
            488,
            269,
            41,
            112,
            316,
            219,
            478,
            16,
            324,
            212,
            385,
            123,
            5,
            396,
            179,
            139,
            85,
            295,
            147,
            226,
            191,
            412,
            7,
            420,
            45,
            82,
            297,
            285,
            222,
            33,
            159,
            451,
            487,
            67,
            207,
            188,
            369,
            227,
            296,
            192,
            184,
            405,
            30,
            46,
            264,
            345,
            427,
            24,
            92
        ]
    },
    {
        "query": "Parses a shell item.\n\n    Args:\n      parser_mediator (ParserMediator): mediates interactions between parsers\n          and other components, such as storage and dfvfs.\n      shell_item (pyfwsi.item): shell item.",
        "positive_code": "def _ParseShellItem(self, parser_mediator, shell_item):\n    \n    path_segment = self._ParseShellItemPathSegment(shell_item)\n    self._path_segments.append(path_segment)\n\n    event_data = shell_item_events.ShellItemFileEntryEventData()\n    event_data.origin = self._origin\n    event_data.shell_item_path = self.CopyToPath()\n\n    if isinstance(shell_item, pyfwsi.file_entry):\n      event_data.name = shell_item.name\n\n      for extension_block in shell_item.extension_blocks:\n        if isinstance(extension_block, pyfwsi.file_entry_extension):\n          long_name = extension_block.long_name\n          localized_name = extension_block.localized_name\n          file_reference = extension_block.file_reference\n          if file_reference:\n            file_reference = .format(\n                file_reference & 0xffffffffffff, file_reference >> 48)\n\n          event_data.file_reference = file_reference\n          event_data.localized_name = localized_name\n          event_data.long_name = long_name\n\n          fat_date_time = extension_block.get_creation_time_as_integer()\n          if fat_date_time != 0:\n            date_time = dfdatetime_fat_date_time.FATDateTime(\n                fat_date_time=fat_date_time)\n            event = time_events.DateTimeValuesEvent(\n                date_time, definitions.TIME_DESCRIPTION_CREATION)\n            parser_mediator.ProduceEventWithEventData(event, event_data)\n\n          fat_date_time = extension_block.get_access_time_as_integer()\n          if fat_date_time != 0:\n            date_time = dfdatetime_fat_date_time.FATDateTime(\n                fat_date_time=fat_date_time)\n            event = time_events.DateTimeValuesEvent(\n                date_time, definitions.TIME_DESCRIPTION_LAST_ACCESS)\n            parser_mediator.ProduceEventWithEventData(event, event_data)\n\n      fat_date_time = shell_item.get_modification_time_as_integer()\n      if fat_date_time != 0:\n        date_time = dfdatetime_fat_date_time.FATDateTime(\n            fat_date_time=fat_date_time)\n        event = time_events.DateTimeValuesEvent(\n            date_time, definitions.TIME_DESCRIPTION_MODIFICATION)\n        parser_mediator.ProduceEventWithEventData(event, event_data)",
        "hard_negative_ids": [
            485,
            250,
            85,
            145,
            285,
            494,
            78,
            222,
            49,
            31,
            236,
            219,
            287,
            488,
            269,
            41,
            329,
            188,
            23,
            147,
            106,
            304,
            112,
            169,
            391,
            324,
            192,
            359,
            385,
            352,
            316,
            275,
            453,
            179,
            178,
            159,
            487,
            317,
            425,
            360,
            349,
            30,
            203,
            297,
            171,
            462,
            15,
            198,
            470,
            24
        ]
    },
    {
        "query": "Determine the revision number for a given revision specifier.",
        "positive_code": "def _get_rev_num(self, rev=None):\n\t\t\n\t\t\n\t\tcmd = [, ]\n\t\t\n\t\tcmd.extend([, ])\n\t\tif rev:\n\t\t\tcmd.extend([, rev])\n\t\tres = self._invoke(*cmd)\n\t\treturn res.strip()",
        "hard_negative_ids": [
            142,
            73,
            360,
            252,
            106,
            304,
            466,
            391,
            414,
            197,
            291,
            317,
            453,
            178,
            425,
            15,
            99,
            136,
            23,
            171,
            105,
            429,
            44,
            470,
            256,
            382,
            25,
            293,
            222,
            462,
            76,
            349,
            472,
            109,
            272,
            180,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            29,
            247,
            205,
            305,
            61,
            500
        ]
    },
    {
        "query": "Solve the Sudoku.\n\n        :param verbose: If the steps used for solving the Sudoku\n                        should be printed. Default is `False`\n        :type verbose: bool\n        :param allow_brute_force: If Dancing Links Brute Force method\n                                  should be used if necessary. Default is `True`\n        :type allow_brute_force: bool",
        "positive_code": "def solve(self, verbose=False, allow_brute_force=True):\n        \n        while not self.is_solved:\n            \n            self._update()\n\n            \n            singles_found = False or self._fill_naked_singles() or self._fill_hidden_singles()\n\n            \n            \n            \n            if not singles_found:\n                if allow_brute_force:\n                    solution = None\n                    try:\n                        dlxs = DancingLinksSolver(copy.deepcopy(self._matrix))\n                        solutions = dlxs.solve()\n                        solution = next(solutions)\n                        more_solutions = next(solutions)\n                    except StopIteration as e:\n                        if solution is not None:\n                            self._matrix = solution\n                        else:\n                            raise SudokuHasNoSolutionError(\"Dancing Links solver could not find any solution.\")\n                    except Exception as e:\n                        raise SudokuHasNoSolutionError(\"Brute Force method failed.\")\n                    else:\n                        \n                        \n                        raise SudokuHasMultipleSolutionsError(\"This Sudoku has multiple solutions!\")\n                    self.solution_steps.append(\"BRUTE FORCE - Dancing Links\")\n                    break\n                else:\n                    print(self)\n                    raise SudokuTooDifficultError(\"This Sudoku requires more advanced methods!\")\n        if verbose:\n            print(\"Sudoku solved in {0} iterations!\\n{1}\".format(len(self.solution_steps), self))\n            for step in self.solution_steps:\n                print(step)",
        "hard_negative_ids": [
            232,
            168,
            260,
            424,
            306,
            81,
            291,
            164,
            84,
            192,
            376,
            23,
            323,
            92,
            405,
            414,
            197,
            76,
            466,
            344,
            462,
            285,
            204,
            44,
            182,
            41,
            21,
            360,
            38,
            345,
            12,
            331,
            402,
            429,
            136,
            386,
            490,
            279,
            70,
            300,
            181,
            109,
            139,
            73,
            280,
            133,
            179,
            382,
            97,
            113
        ]
    },
    {
        "query": "Updates a node name or generate a new if no node\n        name is available.\n\n        :param base_name: new node base name",
        "positive_code": "def update_allocated_node_name(self, base_name):\n        \n\n        if base_name is None:\n            return None\n        base_name = re.sub(r\"[ ]\", \"\", base_name)\n        if base_name in self._allocated_node_names:\n            base_name = re.sub(r\"[0-9]+$\", \"{0}\", base_name)\n\n        if  in base_name or  in base_name:\n            \n            for number in range(1, 1000000):\n                try:\n                    name = base_name.format(number, id=number, name=\"Node\")\n                except KeyError as e:\n                    raise aiohttp.web.HTTPConflict(text=\"{\" + e.args[0] + \"} is not a valid replacement string in the node name\")\n                except (ValueError, IndexError) as e:\n                    raise aiohttp.web.HTTPConflict(text=\"{} is not a valid replacement string in the node name\".format(base_name))\n                if name not in self._allocated_node_names:\n                    self._allocated_node_names.add(name)\n                    return name\n        else:\n            if base_name not in self._allocated_node_names:\n                self._allocated_node_names.add(base_name)\n                return base_name\n            \n            for number in range(1, 1000000):\n                name = base_name + str(number)\n                if name not in self._allocated_node_names:\n                    self._allocated_node_names.add(name)\n                    return name\n        raise aiohttp.web.HTTPConflict(text=\"A node name could not be allocated (node limit reached?)\")",
        "hard_negative_ids": [
            82,
            379,
            305,
            174,
            215,
            366,
            498,
            126,
            18,
            311,
            40,
            391,
            176,
            272,
            81,
            412,
            66,
            304,
            98,
            425,
            70,
            106,
            201,
            65,
            31,
            424,
            150,
            203,
            58,
            76,
            204,
            454,
            277,
            453,
            178,
            344,
            191,
            91,
            171,
            464,
            317,
            386,
            179,
            360,
            15,
            197,
            300,
            321,
            324,
            266
        ]
    },
    {
        "query": "returns the current cpu archictecture",
        "positive_code": "def arch():\n    \n    with settings(hide(, , , ),\n                  warn_only=True, capture=True):\n        result = sudo().strip()\n    return result",
        "hard_negative_ids": [
            466,
            285,
            360,
            197,
            414,
            291,
            136,
            73,
            293,
            429,
            44,
            23,
            25,
            109,
            176,
            150,
            380,
            328,
            460,
            485,
            498,
            487,
            478,
            435,
            481,
            94,
            441,
            390,
            21,
            134,
            386,
            5,
            250,
            193,
            454,
            226,
            112,
            86,
            128,
            210,
            42,
            3,
            56,
            433,
            141,
            425,
            55,
            304,
            118,
            424
        ]
    },
    {
        "query": "Get a metadata fingerprint for a file",
        "positive_code": "def file_fingerprint(fullpath):\n    \n    stat = os.stat(fullpath)\n    return .join([str(value) for value in [stat.st_ino, stat.st_mtime, stat.st_size] if value])",
        "hard_negative_ids": [
            171,
            106,
            304,
            363,
            500,
            391,
            421,
            317,
            453,
            15,
            382,
            178,
            425,
            360,
            498,
            326,
            467,
            470,
            256,
            23,
            180,
            144,
            376,
            169,
            222,
            462,
            82,
            1,
            280,
            389,
            114,
            6,
            76,
            315,
            349,
            275,
            295,
            44,
            402,
            272,
            452,
            463,
            113,
            277,
            373,
            472,
            371,
            442,
            285,
            72
        ]
    },
    {
        "query": "Maximizing the log likelihood using weights according to empirical bayes",
        "positive_code": "def maximum_likelihood(Ms, Mu, Mus, Mss, fit_offset=False, fit_offset2=False):\n    \n    n_obs, n_var = Ms.shape\n    offset, offset_ss = np.zeros(n_var, dtype=\"float32\"), np.zeros(n_var, dtype=\"float32\")\n    gamma = np.ones(n_var, dtype=\"float32\")\n\n    def sse(A, data, b):\n        sigma = (A.dot(data) - b).std(1)\n        return np.log(sigma).sum()  \n\n    if fit_offset and fit_offset2:\n        for i in range(n_var):\n            data = np.vstack((Mu[:, i], Ms[:, i], Mus[:, i], Mss[:, i]))\n            offset[i], offset_ss[i], gamma[i] = \\\n                minimize(lambda m: sse(np.array([[1, -m[2], 0, 0], [1, m[2], 2, -2 * m[2]]]),\n                                       data, b=np.array(m[0], m[1])), x0=(1e-4, 1e-4, 1), method=\"L-BFGS-B\").x\n    elif fit_offset:\n        for i in range(n_var):\n            data = np.vstack((Mu[:, i], Ms[:, i], Mus[:, i], Mss[:, i]))\n            offset[i], gamma[i] = \\\n                minimize(lambda m: sse(np.array([[1, -m[1], 0, 0], [1, m[1], 2, -2 * m[1]]]),\n                                       data, b=np.array(m[0], 0)), x0=(1e-4, 1), method=\"L-BFGS-B\").x\n    elif fit_offset2:\n        for i in range(n_var):\n            data = np.vstack((Mu[:, i], Ms[:, i], Mus[:, i], Mss[:, i]))\n            offset_ss[i], gamma[i] = \\\n                minimize(lambda m: sse(np.array([[1, -m[1], 0, 0], [1, m[1], 2, -2 * m[1]]]),\n                                       data, b=np.array(0, m[0])), x0=(1e-4, 1), method=\"L-BFGS-B\").x\n    else:\n        for i in range(n_var):\n            data = np.vstack((Mu[:, i], Ms[:, i], Mus[:, i], Mss[:, i]))\n            gamma[i] = \\\n                minimize(lambda m: sse(np.array([[1, -m, 0, 0], [1, m, 2, -2 * m]]), data, b=0),\n                         x0=gamma[i], method=\"L-BFGS-B\").x\n    return offset, offset_ss, gamma",
        "hard_negative_ids": [
            166,
            360,
            73,
            264,
            197,
            291,
            414,
            376,
            228,
            50,
            275,
            466,
            266,
            446,
            281,
            307,
            23,
            140,
            171,
            136,
            269,
            124,
            296,
            99,
            340,
            131,
            13,
            361,
            429,
            368,
            44,
            295,
            439,
            189,
            254,
            34,
            25,
            109,
            47,
            391,
            375,
            252,
            76,
            186,
            157,
            329,
            469,
            258,
            478,
            477
        ]
    },
    {
        "query": "Finds the seconds to the next section from the datetime of a record.",
        "positive_code": "def _seconds_to_section_split(record, sections):\n    \n\n    next_section = sections[\n        bisect_right(sections, _find_weektime(record.datetime))] * 60\n    return next_section - _find_weektime(record.datetime, time_type=)",
        "hard_negative_ids": [
            460,
            467,
            360,
            130,
            466,
            197,
            414,
            354,
            73,
            97,
            384,
            429,
            291,
            470,
            171,
            131,
            349,
            106,
            136,
            304,
            179,
            391,
            434,
            189,
            44,
            23,
            395,
            193,
            453,
            178,
            7,
            232,
            329,
            375,
            26,
            317,
            425,
            415,
            367,
            157,
            25,
            11,
            269,
            15,
            122,
            274,
            76,
            69,
            60,
            153
        ]
    },
    {
        "query": "Computes the cumulative distribution function for the copula, :math:`C(u, v)`\n\n        Args:\n            X: `np.ndarray`\n\n        Returns:\n            np.array: cumulative distribution",
        "positive_code": "def cumulative_distribution(self, X):\n        \n        self.check_fit()\n\n        U, V = self.split_matrix(X)\n\n        num = np.multiply(\n            np.exp(np.multiply(-self.theta, U)) - 1,\n            np.exp(np.multiply(-self.theta, V)) - 1\n        )\n        den = np.exp(-self.theta) - 1\n\n        return -1.0 / self.theta * np.log(1 + num / den)",
        "hard_negative_ids": [
            263,
            88,
            292,
            256,
            42,
            100,
            296,
            152,
            269,
            496,
            240,
            210,
            287,
            159,
            411,
            488,
            177,
            78,
            235,
            41,
            490,
            128,
            12,
            219,
            377,
            1,
            3,
            147,
            360,
            101,
            472,
            23,
            414,
            81,
            112,
            73,
            500,
            197,
            142,
            25,
            291,
            267,
            385,
            190,
            192,
            206,
            391,
            324,
            466,
            339
        ]
    },
    {
        "query": "Create custom Domain Settings\n\n        Domain settings are referenced by an OSPFProfile\n\n        :param str name: name of custom domain settings\n        :param str abr_type: cisco|shortcut|standard\n        :param int auto_cost_bandwidth: Mbits/s\n        :param bool deprecated_algorithm: RFC 1518 compatibility\n        :param int initial_delay: in milliseconds\n        :param int initial_hold_type: in milliseconds\n        :param int max_hold_time: in milliseconds\n        :param int shutdown_max_metric_lsa: in seconds\n        :param int startup_max_metric_lsa: in seconds\n        :raises CreateElementFailed: create failed with reason\n        :return: instance with meta\n        :rtype: OSPFDomainSetting",
        "positive_code": "def create(cls, name, abr_type=, auto_cost_bandwidth=100,\n               deprecated_algorithm=False, initial_delay=200,\n               initial_hold_time=1000, max_hold_time=10000,\n               shutdown_max_metric_lsa=0, startup_max_metric_lsa=0):\n        \n        json = {: name,\n                : abr_type,\n                : auto_cost_bandwidth,\n                : deprecated_algorithm,\n                : initial_delay,\n                : initial_hold_time,\n                : max_hold_time,\n                : shutdown_max_metric_lsa,\n                : startup_max_metric_lsa}\n\n        return ElementCreator(cls, json)",
        "hard_negative_ids": [
            65,
            81,
            386,
            16,
            325,
            170,
            269,
            204,
            291,
            300,
            375,
            344,
            498,
            459,
            473,
            209,
            429,
            179,
            107,
            466,
            252,
            329,
            201,
            176,
            499,
            323,
            159,
            366,
            361,
            73,
            412,
            219,
            39,
            368,
            391,
            147,
            462,
            152,
            450,
            500,
            331,
            360,
            23,
            275,
            66,
            489,
            59,
            40,
            333,
            211
        ]
    },
    {
        "query": "Returns a list of paths to search for config files in reverse order of\n        precedence.  In other words: the last path element will override the\n        settings from the first one.",
        "positive_code": "def _effective_path(self):\n        \n        \n        \n        path = ([ % (self.group_name, self.app_name)] +\n                self.get_xdg_dirs() +\n                [expanduser( % (self.group_name, self.app_name)),\n                 self.get_xdg_home(),\n                 join(getcwd(), .format(self.group_name), self.app_name)])\n\n        \n        if self.search_path:\n            path = self.search_path.split(pathsep)\n\n        \n        env_path = getenv(self.env_path_name)\n\n        if env_path and env_path.startswith():\n            \n            additional_paths = env_path[1:].split(pathsep)\n            self._log.info(\n                           ,\n                           additional_paths,\n                           self.env_path_name)\n            path.extend(additional_paths)\n        elif env_path:\n            \n            self._log.info(\"Configuration search path was overridden with \"\n                           \"%r by the environment variable %r.\",\n                           env_path,\n                           self.env_path_name)\n            path = env_path.split(pathsep)\n\n        return path",
        "hard_negative_ids": [
            250,
            485,
            363,
            414,
            261,
            285,
            405,
            313,
            494,
            482,
            466,
            403,
            433,
            360,
            454,
            461,
            227,
            131,
            232,
            348,
            178,
            268,
            73,
            120,
            65,
            197,
            333,
            171,
            44,
            16,
            23,
            456,
            193,
            144,
            429,
            99,
            170,
            228,
            349,
            470,
            130,
            295,
            246,
            291,
            402,
            188,
            25,
            9,
            469,
            38
        ]
    },
    {
        "query": "Clear a cache entry, or the entire cache if no key is given\n\n        Returns CACHE_DISABLED if the cache is disabled\n        Returns True on successful operation\n\n        :param key: optional key to limit the clear operation to (defaults to None)",
        "positive_code": "def clear(self, key=None):\n        \n        if not self.options.enabled:\n            return CACHE_DISABLED\n        logger.debug(.format(repr(key)))\n        if key is not None and key in self._dict.keys():\n            del self._dict[key]\n            logger.info( + repr(key))\n        elif not key:\n            for cached_key in [k for k in self._dict.keys()]:\n                del self._dict[cached_key]\n            logger.info()\n        return True",
        "hard_negative_ids": [
            328,
            24,
            196,
            73,
            264,
            246,
            360,
            45,
            312,
            248,
            197,
            187,
            476,
            29,
            414,
            387,
            204,
            460,
            81,
            291,
            412,
            442,
            429,
            15,
            137,
            48,
            466,
            11,
            171,
            76,
            113,
            306,
            179,
            47,
            435,
            222,
            345,
            168,
            499,
            474,
            382,
            136,
            68,
            425,
            99,
            304,
            436,
            295,
            203,
            424
        ]
    },
    {
        "query": "@todo: Docstring for _build_literal\n\n      :nm: @todo\n      :clsdata: @todo\n      :returns: @todo",
        "positive_code": "def _build_literal(self, nm, clsdata):\n      \n      cls = type(str(nm), tuple((LiteralValue,)), {\n        : {\n            : clsdata,\n            : clsdata.get(),\n            : clsdata.get()}\n        })\n\n      return cls",
        "hard_negative_ids": [
            353,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            247,
            29,
            317,
            305,
            205,
            61,
            500,
            267,
            133,
            53,
            65,
            232,
            190,
            384,
            476,
            145,
            443,
            4,
            344,
            122,
            103,
            387,
            226,
            85,
            209,
            40,
            246,
            411,
            388,
            15,
            477,
            215,
            210,
            146,
            88,
            10,
            149,
            36,
            216,
            64
        ]
    },
    {
        "query": "Calculates p-values of gene i correlating with gene j by converting log likelihoods into probabilities per A for all B.\n\tdt:\tnumpy.ndarray(nt,ns,dtype=ftype(='=f4' by default)) Gene expression data for A\n\t\tEntry dt[i,j] is gene i's expression level for sample j.\n\tdt2:numpy.ndarray(nt2,ns,dtype=ftype(='=f4' by default)) Gene expression data for B.\n\t\tdt2 has the same format as dt, and can be identical with, different from, a subset of, or a superset of dt.\n\tmemlimit:\tThe approximate memory usage limit in bytes for the library.  For datasets require a larger memory, calculation will fail with an error message. memlimit=0 defaults to unlimited memory usage.\n\tReturn:\tdictionary with following keys:\n\tret:0 iff execution succeeded.\n\tp:\tnumpy.ndarray((nt,nt2),dtype=ftype(='=f4' by default)). P-values for A--B.\n\tftype and gtype can be found in auto.py.\n\t\n\tExample: see findr.examples.geuvadis1 (similar format)",
        "positive_code": "def rank_pv(self,dt,dt2,memlimit=-1):\n\t\n\tif self.lib is None:\n\t\traise ValueError(\"Not initialized.\")\n\timport numpy as np\n\tfrom .auto import ftype_np,gtype_np\n\tfrom .types import isint\n\tif dt.dtype.char!=ftype_np or dt2.dtype.char!=ftype_np:\n\t\traise ValueError()\n\tif len(dt.shape)!=2 or len(dt2.shape)!=2:\n\t\traise ValueError()\n\tif not isint(memlimit):\n\t\traise ValueError()\n\tng=dt.shape[0]\n\tnt=dt2.shape[0]\n\tns=dt.shape[1]\n\t\n\tif dt2.shape[1]!=ns:\n\t\traise ValueError()\n\tif np.isnan(dt).sum()+np.isnan(dt2).sum()>0:\n\t\traise ValueError()\n\n\tdp=np.require(np.zeros((ng,nt),dtype=dt.dtype),requirements=[,,,])\n\tdtr=np.require(dt,requirements=[,,,])\n\tdt2r=np.require(dt2,requirements=[,,,])\n\targlist=[,,,]\n\targs=[dtr,dt2r,dp,memlimit]\n\tfunc=self.cfunc(,rettype=,argtypes=arglist)\n\tret=func(*args)\n\tans={:ret,:dp}\n\treturn ans",
        "hard_negative_ids": [
            291,
            160,
            424,
            15,
            391,
            149,
            349,
            106,
            254,
            466,
            14,
            44,
            168,
            58,
            252,
            360,
            76,
            332,
            462,
            32,
            36,
            442,
            232,
            324,
            88,
            382,
            414,
            197,
            198,
            79,
            60,
            99,
            23,
            256,
            306,
            48,
            73,
            317,
            264,
            190,
            84,
            111,
            263,
            19,
            242,
            182,
            421,
            470,
            26,
            275
        ]
    },
    {
        "query": "r\"\"\"\n    Calculates the fraction of a pore or throat filled with invading fluid\n    based on the capillary pressure in the invading phase.  The invading phase\n    volume is calculated from:\n\n        .. math::\n            S_{nwp} = 1 - S_{wp}^{*} (P^{*}/P_{c})^{\\eta}\n\n    Parameters\n    ----------\n    pressure : string\n        The capillary pressure in the non-wetting phase (Pc > 0).\n\n    Pc_star : string\n        The minimum pressure required to create an interface within the pore\n        body or throat.  Typically this would be calculated using the Washburn\n        equation.\n\n    Swp_star : float\n        The residual wetting phase in an invaded pore or throat at a pressure\n        of ``pc_star``.\n\n    eta : float\n        Exponent controlling the rate at which wetting phase is displaced with\n        increasing pressure.\n\n    Returns\n    -------\n    An array containing the fraction of each pore or throat that would be\n    filled with non-wetting phase at the given phase pressure.  This does not\n    account for whether or not the element is actually invaded, which requires\n    a percolation algorithm of some sort.",
        "positive_code": "def late_filling(target, pressure=,\n                 Pc_star=,\n                 Swp_star=0.2, eta=3):\n    r\n    element = pressure.split()[0]\n    network = target.project.network\n    phase = target.project.find_phase(target)\n    pc_star = phase[Pc_star]\n    Pc = phase[pressure]\n    \n        Ts = network.map_throats(throats=target.Ts, origin=target)\n        values = values[Ts]\n    else:\n        Ps = network.map_pores(pores=target.Ps, origin=target)\n        values = values[Ps]\n    return values",
        "hard_negative_ids": [
            245,
            360,
            414,
            210,
            73,
            349,
            391,
            291,
            466,
            413,
            429,
            256,
            287,
            168,
            179,
            197,
            232,
            296,
            40,
            88,
            56,
            191,
            189,
            14,
            318,
            23,
            498,
            342,
            470,
            426,
            500,
            146,
            295,
            136,
            269,
            462,
            273,
            315,
            166,
            170,
            425,
            433,
            386,
            12,
            228,
            461,
            47,
            275,
            240,
            325
        ]
    },
    {
        "query": "Same as `@click.group()`, but with common settings (ie: \"-h\" for help, epilog, slightly larger help display)",
        "positive_code": "def group(epilog=None, help=None, width=140, **attrs):\n    \n    if epilog is None:\n        epilog = _get_caller_doc()\n    attrs = settings(epilog=epilog, help=help, width=width, **attrs)\n    return click.group(**attrs)",
        "hard_negative_ids": [
            431,
            335,
            228,
            241,
            412,
            65,
            16,
            129,
            24,
            349,
            438,
            11,
            178,
            140,
            173,
            101,
            360,
            414,
            391,
            473,
            69,
            170,
            209,
            154,
            1,
            404,
            323,
            74,
            59,
            434,
            468,
            269,
            106,
            96,
            439,
            149,
            157,
            304,
            397,
            186,
            34,
            179,
            317,
            264,
            76,
            466,
            453,
            15,
            472,
            163
        ]
    },
    {
        "query": "Start response processing.",
        "positive_code": "async def start(self, connection: ) -> :\n        \n        self._closed = False\n        self._protocol = connection.protocol\n        self._connection = connection\n\n        with self._timer:\n            while True:\n                \n                try:\n                    message, payload = await self._protocol.read()  \n                except http.HttpProcessingError as exc:\n                    raise ClientResponseError(\n                        self.request_info, self.history,\n                        status=exc.code,\n                        message=exc.message, headers=exc.headers) from exc\n\n                if (message.code < 100 or\n                        message.code > 199 or message.code == 101):\n                    break\n\n                if self._continue is not None:\n                    set_result(self._continue, True)\n                    self._continue = None\n\n        \n        payload.on_eof(self._response_eof)\n\n        \n        self.version = message.version\n        self.status = message.code\n        self.reason = message.reason\n\n        \n        self._headers = message.headers  \n        self._raw_headers = message.raw_headers  \n\n        \n        self.content = payload\n\n        \n        for hdr in self.headers.getall(hdrs.SET_COOKIE, ()):\n            try:\n                self.cookies.load(hdr)\n            except CookieError as exc:\n                client_logger.warning(\n                    , exc)\n        return self",
        "hard_negative_ids": [
            167,
            493,
            174,
            463,
            278,
            427,
            322,
            80,
            82,
            268,
            52,
            485,
            243,
            339,
            175,
            324,
            283,
            385,
            425,
            238,
            490,
            23,
            349,
            149,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            462,
            461
        ]
    },
    {
        "query": "Get a :class:`UserStory` by ref.\n\n        :param ref: :class:`UserStory` reference",
        "positive_code": "def get_userstory_by_ref(self, ref):\n        \n        response = self.requester.get(\n            ,\n            endpoint=UserStory.endpoint,\n            us_ref=ref,\n            project_id=self.id\n        )\n        return UserStory.parse(self.requester, response.json())",
        "hard_negative_ids": [
            165,
            81,
            291,
            76,
            421,
            204,
            277,
            106,
            344,
            304,
            297,
            391,
            382,
            300,
            453,
            498,
            326,
            15,
            178,
            317,
            425,
            360,
            171,
            82,
            280,
            389,
            23,
            180,
            470,
            114,
            6,
            256,
            295,
            452,
            463,
            373,
            315,
            402,
            462,
            442,
            285,
            72,
            222,
            369,
            349,
            113,
            432,
            371,
            383,
            254
        ]
    },
    {
        "query": "r'''Compressibility factor of the chemical in the solid phase at the\n        current temperature and pressure, [dimensionless].\n\n        Utilizes the object oriented interface and\n        :obj:`thermo.volume.VolumeSolid` to perform the actual calculation of\n        molar volume.\n\n        Examples\n        --------\n        >>> Chemical('palladium').Z\n        0.00036248477437931853",
        "positive_code": "def Zs(self):\n        rpalladium\n        Vms = self.Vms\n        if Vms:\n            return Z(self.T, self.P, Vms)\n        return None",
        "hard_negative_ids": [
            245,
            466,
            213,
            349,
            498,
            46,
            414,
            133,
            197,
            315,
            429,
            76,
            305,
            79,
            118,
            360,
            291,
            470,
            472,
            59,
            77,
            152,
            73,
            295,
            113,
            25,
            201,
            269,
            350,
            317,
            383,
            56,
            69,
            318,
            136,
            379,
            44,
            157,
            232,
            285,
            395,
            485,
            23,
            347,
            460,
            275,
            206,
            296,
            404,
            179
        ]
    },
    {
        "query": "Add an inline interface pair. This method is only for IPS or L2FW engine\n        types.\n        \n        :param str interface_id: interface id of first interface\n        :param str second_interface_id: second interface pair id\n        :param str, href logical_interface_ref: logical interface by href or name\n        :param str vlan_id: vlan ID for first interface in pair\n        :param str second_vlan_id: vlan ID for second interface in pair\n        :param str, href zone_ref: zone reference by name or href for first interface\n        :param str, href second_zone_ref: zone reference by nae or href for second interface\n        :param str failure_mode: normal or bypass\n        :param str comment: optional comment\n        :raises EngineCommandFailed: failure creating interface\n        :return: None",
        "positive_code": "def add_inline_interface(self, interface_id, second_interface_id,\n        logical_interface_ref=None, vlan_id=None, second_vlan_id=None, zone_ref=None,\n        second_zone_ref=None, failure_mode=, comment=None, **kw):\n        \n        interface_spec = {: interface_id, : second_interface_id,\n            : kw.get() if self._engine.type in (, )\n            else }\n        \n        _interface = {: logical_interface_ref,\n            : failure_mode, : zone_ref, : second_zone_ref,\n            : comment}\n        \n        vlan = {: vlan_id, : second_vlan_id}\n        \n        try:\n            inline_id = .format(interface_id, second_interface_id)\n            interface = self._engine.interface.get(inline_id)\n            _interface.update(vlan)\n            interface_spec.update(interfaces=[_interface])\n            interface._add_interface(**interface_spec)\n            return interface.update()\n            \n        except InterfaceNotFound:\n            _interface.update(interfaces=[vlan])\n            interface_spec.update(_interface)\n            interface = Layer2PhysicalInterface(**interface_spec)\n            return self._engine.add_interface(interface)",
        "hard_negative_ids": [
            498,
            315,
            92,
            81,
            23,
            69,
            165,
            213,
            291,
            204,
            52,
            344,
            435,
            323,
            215,
            127,
            197,
            99,
            232,
            227,
            61,
            300,
            469,
            460,
            222,
            412,
            403,
            285,
            216,
            79,
            402,
            459,
            461,
            189,
            345,
            289,
            489,
            429,
            256,
            176,
            113,
            91,
            66,
            41,
            272,
            65,
            349,
            293,
            190,
            182
        ]
    },
    {
        "query": "Downloads a report overview\n\n        :param month: month as datetime instance, or string in YYYY-MM format\n        :type month: str or datetime\n        :param str file_path: location to store output file\n        :return: outcome\n        :rtype: True or None",
        "positive_code": "def get_report_overview(self, month, file_path):\n        \n        api = self._get_api(billing.DefaultApi)\n        month = self._month_converter(month)\n        response = api.get_billing_report(month=month)\n        if file_path and response:\n            content = api.api_client.sanitize_for_serialization(response.to_dict())\n            with open(file_path, ) as fh:\n                fh.write(\n                    json.dumps(\n                        content,\n                        sort_keys=True,\n                        indent=2,\n                    )\n                )\n        return response",
        "hard_negative_ids": [
            460,
            59,
            269,
            210,
            81,
            375,
            376,
            171,
            413,
            40,
            253,
            342,
            277,
            136,
            222,
            204,
            391,
            275,
            232,
            345,
            23,
            425,
            219,
            344,
            333,
            73,
            161,
            326,
            34,
            252,
            304,
            237,
            76,
            178,
            363,
            106,
            493,
            300,
            227,
            414,
            478,
            264,
            360,
            349,
            295,
            393,
            327,
            279,
            101,
            9
        ]
    },
    {
        "query": "Inserts a word **as a correction** before an existing word.\n\n        Reverse of :meth:`Sentence.insertword`.",
        "positive_code": "def insertwordleft(self, newword, nextword, **kwargs):\n        \n        if nextword:\n            if isstring(nextword):\n                nextword = self.doc[u(nextword)]\n            if not nextword in self or not isinstance(nextword, Word):\n                raise Exception(\"Next word not found or not instance of Word!\")\n            if isinstance(newword, list) or isinstance(newword, tuple):\n                if not all([ isinstance(x, Word) for x in newword ]):\n                    raise Exception(\"New word (iterable) constains non-Word instances!\")\n            elif not isinstance(newword, Word):\n                raise Exception(\"New word no instance of Word!\")\n\n            kwargs[] = self.getindex(nextword)\n        else:\n            kwargs[] = 0\n        kwargs[] = True\n        if isinstance(newword, list) or isinstance(newword, tuple):\n            return self.correctwords([], newword, **kwargs)\n        else:\n            return self.correctwords([], [newword], **kwargs)",
        "hard_negative_ids": [
            120,
            453,
            360,
            425,
            391,
            106,
            470,
            304,
            349,
            287,
            16,
            488,
            178,
            238,
            131,
            317,
            427,
            123,
            269,
            256,
            466,
            212,
            79,
            5,
            85,
            189,
            171,
            15,
            112,
            285,
            139,
            332,
            429,
            149,
            385,
            395,
            222,
            316,
            412,
            7,
            232,
            396,
            318,
            420,
            41,
            382,
            105,
            113,
            492,
            70
        ]
    },
    {
        "query": "%prog identical *.fasta\n\n    Given multiple fasta files, find all the exactly identical records\n    based on the computed md5 hexdigest or GCG checksum of each sequence.\n\n    Output is an N + 1 column file (where N = number of input fasta files).\n    If there are duplicates within a given fasta file, they will all be\n    listed out in the same row separated by a comma.\n\n    Example output:\n    ---------------------------\n\t       tta1.fsa    tta2.fsa\n\tt0         2131          na\n\tt1         3420          na\n\tt2    3836,3847         852\n\tt3          148         890\n\tt4          584         614\n\tt5          623         684\n\tt6         1281         470\n\tt7         3367          na",
        "positive_code": "def identical(args):\n    \n    from jcvi.utils.cbook import AutoVivification\n\n    allowed_checksum = [\"MD5\", \"GCG\"]\n\n    p = OptionParser(identical.__doc__)\n    p.add_option(\"--ignore_case\", default=False, action=\"store_true\",\n            help=\"ignore case when comparing sequences [default: %default]\")\n    p.add_option(\"--ignore_N\", default=False, action=\"store_true\",\n            help=\"ignore N and X seqcountnamesnamesnamesnamesnamescountnamescountseq']), id=seqid, description=\"\")\n            SeqIO.write([rec], uniqfw, \"fasta\")\n\n    fw.close()\n    if opts.output_uniq:\n        logging.debug(\"Uniq sequences written to `{0}`\".format(uniqfile))\n        uniqfw.close()",
        "hard_negative_ids": [
            142,
            291,
            73,
            429,
            466,
            363,
            414,
            136,
            462,
            360,
            287,
            252,
            197,
            424,
            350,
            23,
            1,
            171,
            376,
            44,
            349,
            328,
            53,
            391,
            499,
            165,
            435,
            76,
            487,
            232,
            470,
            185,
            9,
            25,
            85,
            237,
            229,
            275,
            227,
            427,
            8,
            99,
            467,
            425,
            256,
            402,
            405,
            496,
            69,
            204
        ]
    },
    {
        "query": "Update the models in the pipeline.\n\n        docs (iterable): A batch of `Doc` objects.\n        golds (iterable): A batch of `GoldParse` objects.\n        drop (float): The droput rate.\n        sgd (callable): An optimizer.\n        RETURNS (dict): Results from the update.\n\n        DOCS: https://spacy.io/api/language#update",
        "positive_code": "def update(self, docs, golds, drop=0.0, sgd=None, losses=None, component_cfg=None):\n        \n        if len(docs) != len(golds):\n            raise IndexError(Errors.E009.format(n_docs=len(docs), n_golds=len(golds)))\n        if len(docs) == 0:\n            return\n        if sgd is None:\n            if self._optimizer is None:\n                self._optimizer = create_default_optimizer(Model.ops)\n            sgd = self._optimizer\n        \n        gold_objs = []\n        doc_objs = []\n        for doc, gold in zip(docs, golds):\n            if isinstance(doc, basestring_):\n                doc = self.make_doc(doc)\n            if not isinstance(gold, GoldParse):\n                gold = GoldParse(doc, **gold)\n            doc_objs.append(doc)\n            gold_objs.append(gold)\n        golds = gold_objs\n        docs = doc_objs\n        grads = {}\n\n        def get_grads(W, dW, key=None):\n            grads[key] = (W, dW)\n\n        get_grads.alpha = sgd.alpha\n        get_grads.b1 = sgd.b1\n        get_grads.b2 = sgd.b2\n        pipes = list(self.pipeline)\n        random.shuffle(pipes)\n        if component_cfg is None:\n            component_cfg = {}\n        for name, proc in pipes:\n            if not hasattr(proc, \"update\"):\n                continue\n            grads = {}\n            kwargs = component_cfg.get(name, {})\n            kwargs.setdefault(\"drop\", drop)\n            proc.update(docs, golds, sgd=get_grads, losses=losses, **kwargs)\n            for key, (W, dW) in grads.items():\n                sgd(W, dW, key=key)",
        "hard_negative_ids": [
            207,
            418,
            77,
            429,
            360,
            273,
            466,
            193,
            265,
            470,
            147,
            391,
            64,
            79,
            217,
            414,
            197,
            500,
            178,
            85,
            2,
            118,
            489,
            291,
            73,
            152,
            382,
            44,
            349,
            383,
            317,
            457,
            314,
            443,
            56,
            351,
            69,
            329,
            106,
            304,
            32,
            476,
            295,
            45,
            23,
            222,
            12,
            160,
            290,
            89
        ]
    },
    {
        "query": "Distinct subcellular locations (``location`` in :class:`.models.SubcellularLocation`)\n\n        :return: all distinct subcellular locations\n        :rtype: list[str]",
        "positive_code": "def subcellular_locations(self):\n        \n        return [x[0] for x in self.session.query(models.SubcellularLocation.location).all()]",
        "hard_negative_ids": [
            107,
            277,
            237,
            161,
            152,
            76,
            101,
            89,
            489,
            333,
            193,
            85,
            198,
            142,
            116,
            183,
            47,
            297,
            273,
            127,
            295,
            77,
            467,
            2,
            222,
            379,
            25,
            88,
            23,
            267,
            402,
            190,
            328,
            332,
            201,
            477,
            410,
            182,
            59,
            84,
            435,
            239,
            412,
            340,
            481,
            63,
            260,
            293,
            98,
            94
        ]
    },
    {
        "query": "Join a Riak cluster\n\n    .. versionchanged:: 2015.8.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' riak.cluster_join <user> <host>\n\n    username - The riak username to join the cluster\n    hostname - The riak hostname you are connecting to",
        "positive_code": "def cluster_join(username, hostname):\n    *\n    ret = {: , : False}\n\n    cmd = __execute_cmd(\n        , .format(username, hostname)\n    )\n\n    if cmd[] != 0:\n        ret[] = cmd[]\n    else:\n        ret[] = cmd[]\n        ret[] = True\n\n    return ret",
        "hard_negative_ids": [
            69,
            436,
            466,
            360,
            429,
            228,
            136,
            159,
            269,
            414,
            425,
            291,
            186,
            325,
            173,
            197,
            52,
            27,
            103,
            53,
            376,
            339,
            17,
            293,
            475,
            245,
            206,
            252,
            435,
            187,
            302,
            131,
            73,
            485,
            171,
            189,
            55,
            25,
            391,
            300,
            162,
            371,
            479,
            23,
            149,
            61,
            256,
            155,
            268,
            415
        ]
    },
    {
        "query": "Create a new instance based on the specifed CMY values.\n\n    Parameters:\n      :c:\n        The Cyan component value [0...1]\n      :m:\n        The Magenta component value [0...1]\n      :y:\n        The Yellow component value [0...1]\n      :alpha:\n        The color transparency [0...1], default is opaque\n      :wref:\n        The whitepoint reference, default is 2 D65.\n\n    Returns:\n      A grapefruit.Color instance.\n\n    >>> Color.NewFromCmy(0, 0.5, 1)\n    (1, 0.5, 0, 1.0)\n    >>> Color.NewFromCmy(0, 0.5, 1, 0.5)\n    (1, 0.5, 0, 0.5)",
        "positive_code": "def NewFromCmy(c, m, y, alpha=1.0, wref=_DEFAULT_WREF):\n    \n    return Color(Color.CmyToRgb(c, m, y), , alpha, wref)",
        "hard_negative_ids": [
            424,
            49,
            332,
            168,
            240,
            56,
            414,
            296,
            256,
            82,
            245,
            333,
            84,
            269,
            182,
            310,
            360,
            490,
            306,
            349,
            15,
            219,
            381,
            175,
            242,
            19,
            197,
            210,
            325,
            23,
            48,
            382,
            405,
            142,
            466,
            263,
            267,
            77,
            481,
            91,
            291,
            14,
            346,
            44,
            166,
            198,
            122,
            3,
            441,
            429
        ]
    },
    {
        "query": "Get information about a case from archive.",
        "positive_code": "def archive_info(database: Database, archive_case: dict) -> dict:\n    \n    data = {\n        : archive_case[],\n        : archive_case.get(),\n        : [],\n        : [],\n        : [],\n        : [],\n        : [],\n    }\n    if archive_case.get():\n        archive_user = database.user.find_one({: archive_case[]})\n        data[].append(archive_user[])\n\n    for key in [, ]:\n        for variant_id in archive_case.get(key, []):\n            archive_variant = database.variant.find_one({: variant_id})\n            data[key].append({\n                : archive_variant[],\n                : archive_variant[],\n                : archive_variant[],\n                : archive_variant[],\n                : archive_variant[],\n            })\n\n    for key in [, ]:\n        for archive_term in archive_case.get(key, []):\n            data[key].append({\n                : archive_term[],\n                : archive_term[],\n            })\n\n    return data",
        "hard_negative_ids": [
            382,
            472,
            421,
            106,
            304,
            391,
            193,
            453,
            153,
            498,
            326,
            15,
            178,
            7,
            26,
            317,
            425,
            367,
            360,
            131,
            11,
            171,
            73,
            82,
            69,
            280,
            389,
            180,
            67,
            470,
            185,
            114,
            6,
            256,
            295,
            147,
            452,
            463,
            373,
            315,
            231,
            402,
            462,
            442,
            208,
            285,
            72,
            343,
            222,
            369
        ]
    },
    {
        "query": "Part of the diagrams that are re-used. (x, y) marks the center of the\n    diagram. Label determines the modification to the \"S\" graph.",
        "positive_code": "def plot_diagram(ax, x, y, label=\"S\", title=\"syntenic\", gradient=True):\n    \n    trackgap = .06\n    tracklen = .12\n    xa, xb = x - tracklen, x + tracklen\n    ya, yb = y + trackgap, y - trackgap\n    hsps = (((60, 150), (50, 130)),\n           ((190, 225), (200, 240)),\n           ((330, 280), (360, 310)))\n\n    for yy in (ya, yb):\n        ax.plot((xa, xb), (yy, yy), \"-\", color=\"gray\", lw=2, zorder=1)\n\n    ytip = .015\n    mrange = 400\n    m = lambda t: xa + t * 1. / mrange * tracklen * 2\n\n    for i, ((a, b), (c, d)) in enumerate(hsps):\n        fb = False\n        if label == \"FB\" and i == 1:\n            c, d = 270, 280\n            fb = True\n        if label == \"G\" and i == 0:\n            c, d = 120, 65\n\n        a, b, c, d = [m(t) for t in (a, b, c, d)]\n        color = \"g\" if i == 1 else \"r\"\n        GeneGlyph(ax, a, b, ya, 2 * ytip, fc=color,\n                  gradient=gradient, zorder=10)\n\n        if i == 1 and label in (\"F\", \"G\", \"FN\"):\n            pass\n        else:\n            if fb:\n                GeneGlyph(ax, c, d, yb, 2 * ytip, fc=, tip=0,\n                          gradient=gradient, zorder=10)\n            else:\n                GeneGlyph(ax, c, d, yb, 2 * ytip, fc=,\n                          gradient=gradient, zorder=10)\n\n        r = Polygon(((a, ya - ytip), (c, yb + ytip),\n                      (d, yb + ytip), (b, ya - ytip)),\n                      fc=, alpha=.2)\n\n        if i == 1 and label not in (\"S\", \"FB\"):\n            pass\n        elif i == 0 and label == \"G\":\n            pass\n        else:\n            ax.add_patch(r)\n\n    if label == \"FN\":\n        ax.text(x + .005, yb, \"NNNNN\", ha=\"center\", size=7)\n\n    title = \"{0}: {1}\".format(label, title)\n    ax.text(x, ya + 5 * ytip, title, size=8, ha=\"center\")",
        "hard_negative_ids": [
            360,
            399,
            466,
            3,
            240,
            263,
            429,
            197,
            245,
            414,
            73,
            495,
            441,
            291,
            321,
            159,
            451,
            318,
            136,
            25,
            23,
            350,
            464,
            349,
            235,
            472,
            403,
            496,
            347,
            296,
            290,
            156,
            44,
            109,
            76,
            499,
            395,
            252,
            470,
            386,
            100,
            232,
            267,
            67,
            424,
            77,
            157,
            32,
            154,
            333
        ]
    },
    {
        "query": "r\"\"\"\n        Used to create a node in the database of type 'cls' in response to a POST request. create_resource should only \\\n        be invoked on a resource when the client specifies a POST request.\n\n        :param request_json: a dictionary formatted according to the specification at \\\n        http://jsonapi.org/format/#crud-creating\n        :return: An HTTP response object in accordance with the same specification",
        "positive_code": "def create_resource(cls, request_json):\n        r\n        response = dict()\n        new_resource, location = None, None\n        try:\n            data = request_json[]\n            if data[] != cls.__type__:\n                raise WrongTypeError()\n\n            attributes = data.get()\n            if attributes:\n                for x in attributes.keys():\n                    if x in cls.dates:\n                        dt = datetime.strptime(attributes[x], )\n                        attributes[x] = dt\n\n                new_resource = cls(**attributes)\n                new_resource.save()\n\n                enum_keys = new_resource.enums.keys()\n                for key in attributes.keys():\n                    if key in enum_keys:\n                        if attributes[key] in new_resource.enums[key]:\n                            setattr(new_resource, key, attributes[key])\n                        else:\n                            raise EnumeratedTypeError\n                    else:\n                        setattr(new_resource, key, attributes[key])\n                    new_resource.save()\n\n                for r in new_resource.hashed:\n                    unhashed = getattr(new_resource, r)\n                    if unhashed:\n                        setattr(new_resource, r, hashlib.sha256(unhashed).hexdigest())\n                        new_resource.save()\n\n            relationships = data.get()\n            if relationships:\n                for relation_name in relationships.keys():\n                    relations = relationships.get(relation_name)\n                    if relations:\n                        relations = relations[]\n                        if isinstance(relations, list):\n                            for relation in relations:\n                                the_type = relation[]  \n                                the_id = relation[]\n                                the_class = cls.get_class_from_type(the_type)\n                                new_resources_relation = the_class.nodes.get(id=the_id, active=True)\n                                meta = relation.get()\n                                eval(.format(\n                                    relation_name=relation_name)\n                                )\n                                new_resource.save()\n                        else:\n                            relation = relations\n                            the_type = relation[]\n                            the_id = relation[]\n                            the_class = cls.get_class_from_type(the_type)\n                            new_resources_relation = the_class.nodes.get(id=the_id, active=True)\n                            meta = relation.get()\n                            eval(.format(\n                                relation_name=relation_name)\n                            )\n                            new_resource.save()\n\n            response[] = new_resource.get_resource_object()\n            response[] = {: new_resource.get_self_link()}\n            status_code = http_error_codes.CREATED\n            location = new_resource.get_self_link()\n\n            r = make_response(jsonify(response))\n            r.headers[] = \"application/vnd.api+json; charset=utf-8\"\n            if location and new_resource:\n                r.headers[] = location\n\n            r.status_code = status_code\n\n        except UniqueProperty:\n            r = application_codes.error_response([application_codes.UNIQUE_KEY_VIOLATION])\n            try:\n                new_resource.delete()\n            except:\n                pass\n\n        except DoesNotExist:\n            r = application_codes.error_response([application_codes.RESOURCE_NOT_FOUND])\n            try:\n                new_resource.delete()\n            except:\n                pass\n\n        except WrongTypeError as e:\n            r = application_codes.error_response([application_codes.WRONG_TYPE_VIOLATION])\n            try:\n                new_resource.delete()\n            except:\n                pass\n\n        except KeyError as e:\n            r = application_codes.error_response([application_codes.BAD_FORMAT_VIOLATION])\n            print e\n            try:\n                new_resource.delete()\n            except:\n                pass\n\n        except EnumeratedTypeError:\n            r = application_codes.error_response([application_codes.ENUMERATED_TYPE_VIOLATION])\n            try:\n                new_resource.delete()\n            except:\n                pass\n\n        except ParameterMissing:\n            r = application_codes.error_response([application_codes.BAD_PARAMETER_VIOLATION])\n            try:\n                new_resource.delete()\n            except:\n                pass\n\n        return r",
        "hard_negative_ids": [
            171,
            427,
            414,
            360,
            466,
            322,
            391,
            291,
            232,
            470,
            73,
            167,
            500,
            423,
            382,
            425,
            349,
            139,
            178,
            429,
            402,
            491,
            222,
            462,
            131,
            81,
            204,
            325,
            79,
            463,
            113,
            269,
            308,
            52,
            305,
            170,
            69,
            106,
            197,
            317,
            207,
            174,
            304,
            129,
            99,
            297,
            264,
            23,
            215,
            295
        ]
    },
    {
        "query": "Return a list of dimensions that have not been associated with\n    any streams.",
        "positive_code": "def unbound_dimensions(streams, kdims, no_duplicates=True):\n    \n    params = stream_parameters(streams, no_duplicates)\n    return [d for d in kdims if d not in params]",
        "hard_negative_ids": [
            269,
            404,
            360,
            189,
            407,
            391,
            349,
            470,
            174,
            466,
            106,
            304,
            178,
            232,
            395,
            432,
            453,
            201,
            425,
            170,
            317,
            2,
            171,
            272,
            429,
            77,
            197,
            15,
            128,
            328,
            59,
            264,
            96,
            477,
            382,
            179,
            267,
            76,
            318,
            434,
            74,
            462,
            222,
            256,
            332,
            183,
            157,
            98,
            439,
            468
        ]
    },
    {
        "query": "Call wasGeneratedBy() for each output,copy the files into the RO.",
        "positive_code": "def generate_output_prov(self,\n                             final_output,    \n                             process_run_id,  \n                             name             \n                            ):   \n        \n        \n        timestamp = datetime.datetime.now()\n\n        \n        \n        \n        for output, value in final_output.items():\n            entity = self.declare_artefact(value)\n            if name is not None:\n                name = urllib.parse.quote(str(name), safe=\":/,\n                \n                role = self.wf_ns[\"main/%s/%s\" % (name, output)]\n            else:\n                role = self.wf_ns[\"main/%s\" % output]\n\n            if not process_run_id:\n                process_run_id = self.workflow_run_uri\n\n            self.document.wasGeneratedBy(\n                entity, process_run_id, timestamp, None, {\"prov:role\": role})",
        "hard_negative_ids": [
            287,
            16,
            136,
            363,
            376,
            34,
            414,
            360,
            227,
            197,
            291,
            9,
            207,
            23,
            402,
            466,
            405,
            44,
            252,
            73,
            420,
            275,
            149,
            171,
            429,
            74,
            27,
            25,
            427,
            327,
            81,
            344,
            76,
            285,
            256,
            467,
            144,
            169,
            109,
            1,
            277,
            99,
            289,
            264,
            135,
            489,
            321,
            35,
            234,
            223
        ]
    },
    {
        "query": "Give as input raw data and output a str in Python 3\n    and unicode in Python 2.\n\n    Args:\n        raw_data: Python 2 str, Python 3 bytes or str to porting\n        encoding: string giving the name of an encoding\n        errors: his specifies the treatment of characters\n            which are invalid in the input encoding\n\n    Returns:\n        str (Python 3) or unicode (Python 2)",
        "positive_code": "def ported_string(raw_data, encoding=, errors=):\n    \n\n    if not raw_data:\n        return six.text_type()\n\n    if isinstance(raw_data, six.text_type):\n        return raw_data.strip()\n\n    if six.PY2:\n        try:\n            return six.text_type(raw_data, encoding, errors).strip()\n        except LookupError:\n            return six.text_type(raw_data, \"utf-8\", errors).strip()\n\n    if six.PY3:\n        try:\n            return six.text_type(raw_data, encoding).strip()\n        except (LookupError, UnicodeDecodeError):\n            return six.text_type(raw_data, \"utf-8\", errors).strip()",
        "hard_negative_ids": [
            413,
            481,
            360,
            429,
            77,
            342,
            466,
            1,
            136,
            240,
            414,
            73,
            349,
            275,
            498,
            210,
            47,
            216,
            252,
            496,
            268,
            40,
            179,
            291,
            324,
            242,
            19,
            197,
            232,
            41,
            182,
            421,
            392,
            407,
            198,
            269,
            137,
            146,
            424,
            23,
            149,
            376,
            219,
            391,
            234,
            185,
            287,
            112,
            239,
            94
        ]
    },
    {
        "query": "Process patterns with MassEdit.\n\n    Arguments:\n      patterns: file pattern to identify the files to be processed.\n      expressions: single python expression to be applied line by line.\n      functions: functions to process files contents.\n      executables: os executables to execute on the argument files.\n\n    Keyword arguments:\n      max_depth: maximum recursion level when looking for file matches.\n      start_dirs: workspace(ies) where to start the file search.\n      dry_run: only display differences if True. Save modified file otherwise.\n      output: handle where the output should be redirected.\n\n    Return:\n      list of files processed.",
        "positive_code": "def edit_files(patterns, expressions=None,\n               functions=None, executables=None,\n               start_dirs=None, max_depth=1, dry_run=True,\n               output=sys.stdout, encoding=None, newline=None):\n    \n    if not is_list(patterns):\n        raise TypeError(\"patterns should be a list\")\n    if expressions and not is_list(expressions):\n        raise TypeError(\"expressions should be a list of exec expressions\")\n    if functions and not is_list(functions):\n        raise TypeError(\"functions should be a list of functions\")\n    if executables and not is_list(executables):\n        raise TypeError(\"executables should be a list of program names\")\n\n    editor = MassEdit(dry_run=dry_run, encoding=encoding, newline=newline)\n    if expressions:\n        editor.set_code_exprs(expressions)\n    if functions:\n        editor.set_functions(functions)\n    if executables:\n        editor.set_executables(executables)\n\n    processed_paths = []\n    for path in get_paths(patterns, start_dirs=start_dirs,\n                          max_depth=max_depth):\n        try:\n            diffs = list(editor.edit_file(path))\n            if dry_run:\n                \n                diff = \"\".join(diffs)\n                if not diff:\n                    continue\n                \n                \n                    diff = bytes_diff.decode(encoding=output.encoding)\n                output.write(diff)\n        except UnicodeDecodeError as err:\n            log.error(\"failed to process %s: %s\", path, err)\n            continue\n        processed_paths.append(os.path.abspath(path))\n    return processed_paths",
        "hard_negative_ids": [
            363,
            171,
            431,
            10,
            278,
            452,
            291,
            388,
            376,
            144,
            414,
            275,
            73,
            487,
            235,
            56,
            269,
            264,
            466,
            136,
            437,
            429,
            218,
            252,
            9,
            47,
            450,
            232,
            402,
            237,
            482,
            438,
            23,
            32,
            467,
            42,
            405,
            360,
            407,
            390,
            109,
            26,
            273,
            44,
            96,
            197,
            258,
            69,
            378,
            97
        ]
    },
    {
        "query": "Create an extended model for gap-filling.\n\n    Create a :class:`psamm.metabolicmodel.MetabolicModel` with\n    all reactions added (the reaction database in the model is taken\n    to be the universal database) and also with artificial exchange\n    and transport reactions added. Return the extended\n    :class:`psamm.metabolicmodel.MetabolicModel`\n    and a weight dictionary for added reactions in that model.\n\n    Args:\n        model: :class:`psamm.datasource.native.NativeModel`.\n        db_penalty: penalty score for database reactions, default is `None`.\n        ex_penalty: penalty score for exchange reactions, default is `None`.\n        tb_penalty: penalty score for transport reactions, default is `None`.\n        penalties: a dictionary of penalty scores for database reactions.",
        "positive_code": "def create_extended_model(model, db_penalty=None, ex_penalty=None,\n                          tp_penalty=None, penalties=None):\n    \n\n    \n    model_extended = model.create_metabolic_model()\n    extra_compartment = model.extracellular_compartment\n\n    compartment_ids = set(c.id for c in model.compartments)\n\n    \n    if len(compartment_ids) > 0:\n        logger.info(\n            .format(\n                .join(.format(c) for c in compartment_ids)))\n        db_added = add_all_database_reactions(model_extended, compartment_ids)\n    else:\n        logger.warning(\n            \n            \n            )\n        db_added = set()\n\n    \n    logger.info(\n        .format(\n            extra_compartment))\n    ex_added = add_all_exchange_reactions(\n        model_extended, extra_compartment, allow_duplicates=True)\n\n    \n    boundaries = model.compartment_boundaries\n    if len(boundaries) > 0:\n        logger.info(\n            \n            .format(\n                .join(.format(c1, c2) for c1, c2 in boundaries)))\n        tp_added = add_all_transport_reactions(\n            model_extended, boundaries, allow_duplicates=True)\n    else:\n        logger.warning(\n            \n            )\n        tp_added = set()\n\n    \n    weights = {}\n    if db_penalty is not None:\n        weights.update((rxnid, db_penalty) for rxnid in db_added)\n    if tp_penalty is not None:\n        weights.update((rxnid, tp_penalty) for rxnid in tp_added)\n    if ex_penalty is not None:\n        weights.update((rxnid, ex_penalty) for rxnid in ex_added)\n\n    if penalties is not None:\n        for rxnid, penalty in iteritems(penalties):\n            weights[rxnid] = penalty\n    return model_extended, weights",
        "hard_negative_ids": [
            360,
            76,
            168,
            89,
            424,
            333,
            489,
            325,
            405,
            198,
            382,
            308,
            466,
            306,
            414,
            84,
            170,
            37,
            178,
            291,
            232,
            459,
            269,
            197,
            304,
            9,
            73,
            391,
            349,
            297,
            470,
            273,
            106,
            219,
            467,
            171,
            152,
            23,
            179,
            324,
            25,
            429,
            287,
            462,
            112,
            41,
            488,
            277,
            39,
            425
        ]
    },
    {
        "query": "Register callback that we will have to wait for",
        "positive_code": "def register_callback(self):\n        \n\n        cid = str(self.__cid)\n        self.__cid += 1\n        event = queue.Queue()\n        self.__callbacks[cid] = event\n        return cid, event",
        "hard_negative_ids": [
            455,
            248,
            189,
            297,
            330,
            404,
            453,
            360,
            230,
            227,
            496,
            415,
            109,
            171,
            269,
            131,
            414,
            368,
            376,
            295,
            275,
            264,
            73,
            47,
            76,
            157,
            99,
            266,
            466,
            329,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133
        ]
    },
    {
        "query": "Find whether the files on the left and right are different. Note,\n        modified implies the contents of the file have changed, which is\n        predicated on the file existing on both the left and right. Therefore\n        this will be false if the file on the left has been deleted, or the\n        file on the right is new.\n\n        :return: Whether the file has been modified.",
        "positive_code": "def is_modified(self) -> bool:\n        \n        if self.is_new or self.is_deleted:\n            return False\n        return self.left.md5 != self.right.md5",
        "hard_negative_ids": [
            197,
            363,
            499,
            291,
            82,
            466,
            414,
            189,
            204,
            360,
            171,
            429,
            136,
            275,
            23,
            47,
            464,
            44,
            232,
            146,
            73,
            130,
            187,
            268,
            25,
            109,
            144,
            349,
            273,
            318,
            470,
            467,
            62,
            192,
            345,
            405,
            376,
            157,
            402,
            60,
            90,
            210,
            1,
            462,
            424,
            24,
            97,
            386,
            274,
            122
        ]
    },
    {
        "query": ":return: the first child node matching the given constraints, or \\\n                 *None* if there are no matching child nodes.\n\n        Delegates to :meth:`NodeList.filter`.",
        "positive_code": "def child(self, local_name=None, name=None, ns_uri=None, node_type=None,\n            filter_fn=None):\n        \n        return self.children(name=name, local_name=local_name, ns_uri=ns_uri,\n            node_type=node_type, filter_fn=filter_fn, first_only=True)",
        "hard_negative_ids": [
            388,
            73,
            291,
            311,
            376,
            305,
            136,
            174,
            215,
            360,
            212,
            126,
            246,
            18,
            197,
            466,
            414,
            109,
            144,
            379,
            429,
            285,
            464,
            366,
            474,
            203,
            23,
            469,
            403,
            269,
            5,
            107,
            112,
            295,
            78,
            31,
            499,
            287,
            425,
            16,
            266,
            272,
            25,
            488,
            123,
            240,
            99,
            235,
            191,
            496
        ]
    },
    {
        "query": "Get the if-none-match option of a request.\n\n        :return: True, if if-none-match is present\n        :rtype : bool",
        "positive_code": "def if_none_match(self):\n        \n        for option in self.options:\n            if option.number == defines.OptionRegistry.IF_NONE_MATCH.number:\n                return True\n        return False",
        "hard_negative_ids": [
            130,
            435,
            429,
            491,
            139,
            182,
            466,
            318,
            64,
            73,
            197,
            349,
            425,
            360,
            402,
            421,
            222,
            331,
            391,
            129,
            304,
            470,
            12,
            131,
            414,
            285,
            382,
            415,
            369,
            326,
            258,
            232,
            106,
            15,
            105,
            260,
            10,
            179,
            76,
            423,
            498,
            157,
            462,
            395,
            272,
            136,
            291,
            453,
            373,
            178
        ]
    },
    {
        "query": "Define the selection of trials, using ranges or actual values.\n\n    Parameters\n    ----------\n    data : instance of Data\n        data to select from.\n    trial : list of int or ndarray (dtype='i'), optional\n        index of trials of interest\n    **axes_to_select, optional\n        Values need to be tuple or list. If the values in one axis are string,\n        then you need to specify all the strings that you want. If the values\n        are numeric, then you should specify the range (you cannot specify\n        single values, nor multiple values). To select only up to one point,\n        you can use (None, value_of_interest)\n    invert : bool\n        take the opposite selection\n\n    Returns\n    -------\n    instance, same class as input\n        data where selection has been applied.",
        "positive_code": "def select(data, trial=None, invert=False, **axes_to_select):\n    \n    if trial is not None and not isinstance(trial, Iterable):\n        raise TypeError()\n\n    for axis_to_select, values_to_select in axes_to_select.items():\n        if (not isinstance(values_to_select, Iterable) or\n           isinstance(values_to_select, str)):\n            raise TypeError(axis_to_select + )\n\n    if trial is None:\n        trial = range(data.number_of())\n    else:\n        trial = trial\n        if invert:\n            trial = setdiff1d(range(data.number_of()), trial)\n\n    \n    output = data._copy(axis=False)\n    for one_axis in output.axis:\n        output.axis[one_axis] = empty(len(trial), dtype=)\n    output.data = empty(len(trial), dtype=)\n\n    to_select = {}\n    for cnt, i in enumerate(trial):\n        lg.debug(.format(i))\n        for one_axis in output.axis:\n            values = data.axis[one_axis][i]\n\n            if one_axis in axes_to_select.keys():\n                values_to_select = axes_to_select[one_axis]\n\n                if len(values_to_select) == 0:\n                    selected_values = ()\n\n                elif isinstance(values_to_select[0], str):\n                    selected_values = asarray(values_to_select, dtype=)\n\n                else:\n                    if (values_to_select[0] is None and\n                       values_to_select[1] is None):\n                        bool_values = ones(len(values), dtype=bool)\n                    elif values_to_select[0] is None:\n                        bool_values = values < values_to_select[1]\n                    elif values_to_select[1] is None:\n                        bool_values = values_to_select[0] <= values\n                    else:\n                        bool_values = ((values_to_select[0] <= values) &\n                                       (values < values_to_select[1]))\n                    selected_values = values[bool_values]\n\n                if invert:\n                    selected_values = setdiff1d(values, selected_values)\n\n                lg.debug(\n                         .format(one_axis,\n                                         len(selected_values)))\n                to_select[one_axis] = selected_values\n            else:\n                lg.debug( + one_axis + \n                         )\n                selected_values = data.axis[one_axis][i]\n\n            output.axis[one_axis][cnt] = selected_values\n\n        output.data[cnt] = data(trial=i, **to_select)\n\n    return output",
        "hard_negative_ids": [
            332,
            269,
            360,
            466,
            429,
            142,
            295,
            127,
            414,
            232,
            166,
            333,
            424,
            413,
            136,
            291,
            349,
            267,
            462,
            256,
            182,
            15,
            255,
            210,
            213,
            90,
            328,
            496,
            460,
            73,
            40,
            85,
            324,
            421,
            56,
            99,
            53,
            23,
            79,
            76,
            435,
            195,
            395,
            185,
            197,
            477,
            192,
            189,
            440,
            11
        ]
    },
    {
        "query": "Get a valid semantic version for tag",
        "positive_code": "def semantic_version(tag):\n    \n    try:\n        version = list(map(int, tag.split()))\n        assert len(version) == 3\n        return tuple(version)\n    except Exception as exc:\n        raise CommandError(\n            \n             % tag\n        ) from exc",
        "hard_negative_ids": [
            475,
            379,
            311,
            1,
            73,
            149,
            47,
            222,
            421,
            466,
            106,
            304,
            386,
            391,
            382,
            429,
            147,
            15,
            317,
            137,
            180,
            453,
            498,
            326,
            178,
            425,
            360,
            136,
            171,
            82,
            157,
            280,
            389,
            470,
            434,
            243,
            114,
            6,
            256,
            315,
            295,
            402,
            452,
            463,
            113,
            373,
            462,
            371,
            442,
            272
        ]
    },
    {
        "query": "Compute auto-correlation for the input data X1 and X2.\n\n        it will generate the correlation between some voxels and all voxels\n\n        Parameters\n        ----------\n        X1: a list of numpy array in shape [num_TRs, num_voxels1]\n            X1 contains the activity data filtered by ROIs\n            and prepared for correlation computation.\n            All elements of X1 must have the same num_voxels value.\n        X2: a list of numpy array in shape [num_TRs, num_voxels2]\n            len(X1) equals len(X2).\n            All elements of X2 must have the same num_voxels value.\n            X2 can be identical to X1; if not, X1 must have more voxels\n            than X2 (guaranteed by self.fit and/or self.predict).\n        start_voxel: int, default 0\n            the starting voxel id for correlation computation\n        num_processed_voxels: int, default None\n            the number of voxels it computes for correlation computation\n            if it is None, it is set to self.num_voxels\n\n        Returns\n        -------\n        corr_data: the correlation data\n                    in shape [len(X), num_processed_voxels, num_voxels2]",
        "positive_code": "def _prepare_corerelation_data(self, X1, X2,\n                                   start_voxel=0,\n                                   num_processed_voxels=None):\n        \n        num_samples = len(X1)\n        assert num_samples > 0, \\\n            \n        num_voxels1 = X1[0].shape[1]\n        num_voxels2 = X2[0].shape[1]\n        assert num_voxels1 * num_voxels2 == self.num_features_, \\\n             \\\n            \n        assert X1[0].shape[0] == X2[0].shape[0], \\\n            \n        if num_processed_voxels is None:\n            num_processed_voxels = num_voxels1\n        corr_data = np.zeros((num_samples, num_processed_voxels, num_voxels2),\n                             np.float32, order=)\n        \n        for idx, data in enumerate(X1):\n            data2 = X2[idx]\n            num_TRs = data.shape[0]\n            blas.compute_corr_vectors(, ,\n                                      num_voxels2, num_processed_voxels,\n                                      num_TRs,\n                                      1.0, data2, num_voxels2,\n                                      data, num_voxels1,\n                                      0.0, corr_data, num_voxels2,\n                                      start_voxel, idx)\n        logger.debug(\n            \n        )\n        return corr_data",
        "hard_negative_ids": [
            416,
            424,
            232,
            291,
            88,
            386,
            256,
            240,
            142,
            349,
            76,
            23,
            414,
            166,
            382,
            466,
            25,
            429,
            197,
            470,
            317,
            252,
            295,
            267,
            168,
            360,
            85,
            318,
            12,
            462,
            440,
            461,
            84,
            149,
            189,
            433,
            306,
            263,
            421,
            56,
            195,
            391,
            101,
            81,
            496,
            179,
            490,
            185,
            332,
            69
        ]
    },
    {
        "query": "Computes a semantic similarity matrix for a set of concepts.",
        "positive_code": "def _similarity_matrix(self, concepts):\n        \n        n_cons = len(concepts)\n        sim_mat = np.zeros((n_cons, n_cons))\n        for i, c1 in enumerate(concepts):\n            for j, c2 in enumerate(concepts):\n                \n                if i >= j:\n                    sim_mat[i,j] = self._semsim(c1, c2) if i != j else 1.\n        return sim_mat + sim_mat.T - np.diag(sim_mat.diagonal())",
        "hard_negative_ids": [
            177,
            106,
            304,
            470,
            391,
            349,
            317,
            453,
            178,
            466,
            272,
            425,
            15,
            360,
            232,
            171,
            395,
            23,
            25,
            256,
            382,
            11,
            97,
            222,
            429,
            197,
            462,
            90,
            61,
            289,
            184,
            76,
            318,
            236,
            109,
            239,
            157,
            472,
            235,
            258,
            127,
            180,
            490,
            135,
            489,
            321,
            35,
            363,
            234,
            223
        ]
    },
    {
        "query": "PUT /tag/name. Returns a new Tag object based on the API response.",
        "positive_code": "def modify_tag(self, name, description=None, servers=None, new_name=None):\n        \n        res = self._modify_tag(name, description, servers, new_name)\n        return Tag(cloud_manager=self, **res[])",
        "hard_negative_ids": [
            475,
            379,
            82,
            429,
            207,
            167,
            79,
            311,
            391,
            149,
            498,
            360,
            463,
            500,
            470,
            202,
            499,
            425,
            159,
            427,
            322,
            457,
            1,
            176,
            317,
            291,
            52,
            204,
            394,
            106,
            265,
            243,
            339,
            304,
            297,
            361,
            466,
            382,
            130,
            58,
            65,
            197,
            414,
            162,
            453,
            66,
            462,
            150,
            69,
            178
        ]
    },
    {
        "query": "Netmiko is being used to push set commands.",
        "positive_code": "def _send_merge_commands(self, config, file_config):\n        \n        if self.loaded is False:\n            if self._save_backup() is False:\n                raise MergeConfigException(\n                                           )\n        if self.ssh_connection is False:\n            self._open_ssh()\n\n        if file_config:\n            if isinstance(config, str):\n                config = config.splitlines()\n        else:\n            if isinstance(config, str):\n                config = str(config).split()\n\n        self.ssh_device.send_config_set(config)\n        self.loaded = True\n        self.merge_config = True",
        "hard_negative_ids": [
            444,
            359,
            236,
            166,
            179,
            171,
            97,
            25,
            394,
            385,
            368,
            11,
            269,
            109,
            73,
            131,
            47,
            90,
            184,
            376,
            295,
            239,
            414,
            264,
            189,
            423,
            272,
            289,
            235,
            275,
            360,
            258,
            61,
            99,
            76,
            266,
            157,
            224,
            472,
            329,
            66,
            127,
            466,
            490,
            345,
            328,
            212,
            243,
            398,
            23
        ]
    },
    {
        "query": "Wrapper for calling the clean method of services attribute\n\n        :return: None",
        "positive_code": "def clean(self):\n        \n        logger.debug(\"Cleaning configuration objects before configuration sending:\")\n        types_creations = self.__class__.types_creations\n        for o_type in types_creations:\n            (_, _, inner_property, _, _) = types_creations[o_type]\n            logger.debug(\"  . for %s\", inner_property, )\n            inner_object = getattr(self, inner_property)\n            inner_object.clean()",
        "hard_negative_ids": [
            91,
            267,
            41,
            323,
            424,
            112,
            297,
            466,
            425,
            470,
            197,
            330,
            25,
            70,
            324,
            139,
            402,
            44,
            429,
            414,
            232,
            360,
            349,
            291,
            395,
            439,
            73,
            136,
            434,
            318,
            87,
            23,
            157,
            272,
            109,
            388,
            53,
            304,
            423,
            328,
            212,
            46,
            222,
            478,
            279,
            72,
            62,
            216,
            333,
            413
        ]
    },
    {
        "query": "Checks for existance of parameters file against supported suffixes and returns parameters file path if found\n    Args:\n      template_full_path: full filepath for template file\n    Returns:\n      filename of parameters file if it exists",
        "positive_code": "def get_template_parameters_file(template_full_path):\n    \n    for suffix in EFConfig.PARAMETER_FILE_SUFFIXES:\n      parameters_file = template_full_path.replace(\"/templates\", \"/parameters\") + suffix\n      if exists(parameters_file):\n        return parameters_file\n      else:\n        continue\n    return None",
        "hard_negative_ids": [
            480,
            38,
            363,
            169,
            325,
            44,
            23,
            349,
            170,
            171,
            373,
            364,
            144,
            219,
            287,
            198,
            488,
            157,
            41,
            233,
            71,
            185,
            457,
            275,
            456,
            201,
            269,
            179,
            272,
            499,
            147,
            467,
            197,
            1,
            324,
            329,
            112,
            289,
            232,
            246,
            264,
            395,
            385,
            98,
            117,
            165,
            376,
            470,
            254,
            148
        ]
    },
    {
        "query": "Unpack a where clause tuple and concatenate a MySQL WHERE statement.\n\n        :param where: 2 or 3 part tuple containing a where_column and a where_value (optional operator)\n        :return: WHERE clause statement",
        "positive_code": "def _where_clause(where):\n        \n        assert isinstance(where, tuple)\n        if len(where) == 3:\n            where_col, operator, where_val = where\n        else:\n            where_col, where_val = where\n            operator = \n        assert operator in SELECT_WHERE_OPERATORS\n\n        \n        return \"{0}{1}\".format(where_col, operator, where_val)",
        "hard_negative_ids": [
            487,
            329,
            171,
            48,
            90,
            237,
            77,
            429,
            460,
            391,
            240,
            450,
            106,
            81,
            267,
            256,
            304,
            15,
            425,
            141,
            435,
            184,
            159,
            453,
            178,
            198,
            192,
            317,
            149,
            84,
            360,
            462,
            204,
            349,
            24,
            20,
            152,
            344,
            137,
            234,
            179,
            54,
            470,
            300,
            182,
            382,
            95,
            326,
            94,
            347
        ]
    },
    {
        "query": "Listen on TCP/IP socket.\n\n        Parameters\n        ----------\n        host: str\n            Host like '127.0.0.1'\n        port:\n            Port like 80.",
        "positive_code": "def listen(self, *, host, port, override=False, forever=False, **kwargs):\n        \n        if override:\n            argv = dict(enumerate(sys.argv))\n            host = argv.get(1, host)\n            port = int(argv.get(2, port))\n        server = self.loop.create_server(\n            self.__handler.fork, host, port, **kwargs)\n        server = self.loop.run_until_complete(server)\n        self.log(,\n            .\n            format(host=host, port=port))\n        if forever:\n            try:\n                self.loop.run_forever()\n            except KeyboardInterrupt:\n                pass\n        return server",
        "hard_negative_ids": [
            429,
            325,
            147,
            293,
            61,
            262,
            227,
            302,
            173,
            439,
            361,
            205,
            162,
            130,
            58,
            177,
            391,
            265,
            95,
            240,
            379,
            499,
            69,
            435,
            204,
            245,
            426,
            207,
            462,
            266,
            350,
            17,
            77,
            183,
            268,
            175,
            457,
            155,
            88,
            450,
            347,
            486,
            349,
            12,
            500,
            472,
            412,
            340,
            47,
            23
        ]
    },
    {
        "query": "Match function used for filtering non-indexed event arguments.\n\n    Values provided through the match_values_and_abi parameter are\n    compared to the abi decoded log data.",
        "positive_code": "def match_fn(match_values_and_abi, data):\n    \n    abi_types, all_match_values = zip(*match_values_and_abi)\n    decoded_values = decode_abi(abi_types, HexBytes(data))\n    for data_value, match_values, abi_type in zip(decoded_values, all_match_values, abi_types):\n        if match_values is None:\n            continue\n        normalized_data = normalize_data_values(abi_type, data_value)\n        for value in match_values:\n            if not is_encodable(abi_type, value):\n                raise ValueError(\n                    \"Value {0} is of the wrong abi type. \"\n                    \"Expected {1} typed value.\".format(value, abi_type))\n            if value == normalized_data:\n                break\n        else:\n            return False\n\n    return True",
        "hard_negative_ids": [
            42,
            314,
            257,
            332,
            372,
            73,
            142,
            360,
            429,
            424,
            466,
            197,
            414,
            421,
            156,
            291,
            237,
            235,
            136,
            327,
            269,
            223,
            195,
            330,
            376,
            56,
            252,
            318,
            15,
            25,
            498,
            203,
            275,
            202,
            264,
            85,
            33,
            440,
            333,
            357,
            50,
            393,
            154,
            266,
            109,
            267,
            324,
            499,
            283,
            23
        ]
    },
    {
        "query": "Connect with a Target or Initiator\n\n        The calling thread is blocked until a single activation and\n        deactivation has completed or a callback function supplied as\n        the keyword argument ``terminate`` returns a true value. The\n        example below makes :meth:`~connect()` return after 5 seconds,\n        regardless of whether a peer device was connected or not.\n\n        >>> import nfc, time\n        >>> clf = nfc.ContactlessFrontend('usb')\n        >>> after5s = lambda: time.time() - started > 5\n        >>> started = time.time(); clf.connect(llcp={}, terminate=after5s)\n\n        Connect options are given as keyword arguments with dictionary\n        values. Possible options are:\n\n        * ``rdwr={key: value, ...}`` - options for reader/writer\n        * ``llcp={key: value, ...}`` - options for peer to peer\n        * ``card={key: value, ...}`` - options for card emulation\n\n        **Reader/Writer Options**\n\n        'targets' : iterable\n           A list of bitrate and technology type strings that will\n           produce the :class:`~nfc.clf.RemoteTarget` objects to\n           discover. The default is ``('106A', '106B', '212F')``.\n\n        'on-startup' : function(targets)\n           This function is called before any attempt to discover a\n           remote card. The *targets* argument provides a list of\n           :class:`RemoteTarget` objects prepared from the 'targets'\n           bitrate and technology type strings. The function must\n           return a list of of those :class:`RemoteTarget` objects\n           that shall be finally used for discovery, those targets may\n           have additional attributes. An empty list or anything else\n           that evaluates false will remove the 'rdwr' option\n           completely.\n\n        'on-discover' : function(target)\n           This function is called when a :class:`RemoteTarget` has\n           been discovered. The *target* argument contains the\n           technology type specific discovery responses and should be\n           evaluated for multi-protocol support. The target will be\n           further activated only if this function returns a true\n           value. The default function depends on the 'llcp' option,\n           if present then the function returns True only if the\n           target does not indicate peer to peer protocol support,\n           otherwise it returns True for all targets.\n\n        'on-connect' : function(tag)\n           This function is called when a remote tag has been\n           activated. The *tag* argument is an instance of class\n           :class:`nfc.tag.Tag` and can be used for tag reading and\n           writing within the callback or in a separate thread. Any\n           true return value instructs :meth:`connect` to wait until\n           the tag is no longer present and then return True, any\n           false return value implies immediate return of the\n           :class:`nfc.tag.Tag` object.\n\n        'on-release' : function(tag)\n           This function is called when the presence check was run\n           (the 'on-connect' function returned a true value) and\n           determined that communication with the *tag* has become\n           impossible, or when the 'terminate' function returned a\n           true value. The *tag* object may be used for cleanup\n           actions but not for communication.\n\n        'iterations' : integer\n           This determines the number of sense cycles performed\n           between calls to the terminate function. Each iteration\n           searches once for all specified targets. The default value\n           is 5 iterations and between each iteration is a waiting\n           time determined by the 'interval' option described below.\n           As an effect of math there will be no waiting time if\n           iterations is set to 1.\n\n        'interval' : float\n           This determines the waiting time between iterations. The\n           default value of 0.5 seconds is considered a sensible\n           tradeoff between responsiveness in terms of tag discovery\n           and power consumption. It should be clear that changing\n           this value will impair one or the other. There is no free\n           beer.\n\n        'beep-on-connect': boolean\n            If the device supports beeping or flashing an LED,\n            automatically perform this functionality when a tag is\n            successfully detected AND the 'on-connect' function\n            returns a true value. Defaults to True.\n\n        .. sourcecode:: python\n\n           import nfc\n\n           def on_startup(targets):\n               for target in targets:\n                   target.sensf_req = bytearray.fromhex(\"0012FC0000\")\n               return targets\n\n           def on_connect(tag):\n               print(tag)\n\n           rdwr_options = {\n               'targets': ['212F', '424F'],\n               'on-startup': on_startup,\n               'on-connect': on_connect,\n           }\n           with nfc.ContactlessFrontend('usb') as clf:\n               tag = clf.connect(rdwr=rdwr_options)\n               if tag.ndef:\n                   print(tag.ndef.message.pretty())\n\n        **Peer To Peer Options**\n\n        'on-startup' : function(llc)\n           This function is called before any attempt to establish\n           peer to peer communication. The *llc* argument provides the\n           :class:`~nfc.llcp.llc.LogicalLinkController` that may be\n           used to allocate and bind listen sockets for local\n           services. The function should return the *llc* object if\n           activation shall continue. Any other value removes the\n           'llcp' option.\n\n        'on-connect' : function(llc)\n           This function is called when peer to peer communication is\n           successfully established. The *llc* argument provides the\n           now activated :class:`~nfc.llcp.llc.LogicalLinkController`\n           ready for allocation of client communication sockets and\n           data exchange in separate work threads. The function should\n           a true value return more or less immediately, unless it\n           wishes to handle the logical link controller run loop by\n           itself and anytime later return a false value.\n\n        'on-release' : function(llc)\n           This function is called when the symmetry loop was run (the\n           'on-connect' function returned a true value) and determined\n           that communication with the remote peer has become\n           impossible, or when the 'terminate' function returned a\n           true value. The *llc* object may be used for cleanup\n           actions but not for communication.\n\n        'role' : string\n           This attribute determines whether the local device will\n           restrict itself to either ``'initiator'`` or ``'target'``\n           mode of operation. As Initiator the local device will try\n           to discover a remote device. As Target it waits for being\n           discovered. The default is to alternate between both roles.\n\n        'miu' : integer\n           This attribute sets the maximum information unit size that\n           is announced to the remote device during link activation.\n           The default and also smallest possible value is 128 bytes.\n\n        'lto' : integer\n           This attribute sets the link timeout value (given in\n           milliseconds) that is announced to the remote device during\n           link activation. It informs the remote device that if the\n           local device does not return a protocol data unit before\n           the timeout expires, the communication link is broken and\n           can not be recovered. The *lto* is an important part of the\n           user experience, it ultimately tells when the user should\n           no longer expect communication to continue. The default\n           value is 500 millisecond.\n\n        'agf' : boolean\n           Some early phone implementations did not properly handle\n           aggregated protocol data units. This attribute allows to\n           disable the use af aggregation at the cost of efficiency.\n           Aggregation is disabled with a false value. The default\n           is to use aggregation.\n\n        'brs' : integer\n           For the local device in Initiator role the bit rate\n           selector determines the the bitrate to negotiate with the\n           remote Target. The value may be 0, 1, or 2 for 106, 212, or\n           424 kbps, respectively. The default is to negotiate 424\n           kbps.\n\n        'acm' : boolean\n           For the local device in Initiator role this attribute\n           determines whether a remote Target may also be activated in\n           active communication mode. In active communication mode\n           both peer devices mutually generate a radio field when\n           sending. The default is to use passive communication mode.\n\n        'rwt' : float\n           For the local device in Target role this attribute sets the\n           response waiting time announced during link activation. The\n           response waiting time is a medium access layer (NFC-DEP)\n           value that indicates when the remote Initiator shall\n           attempt error recovery after missing a Target response. The\n           value is the waiting time index *wt* that determines the\n           effective response waiting time by the formula ``rwt =\n           4096/13.56E6 * pow(2, wt)``. The value shall not be greater\n           than 14. The default value is 8 and yields an effective\n           response waiting time of 77.33 ms.\n\n        'lri' : integer\n           For the local device in Initiator role this attribute sets\n           the length reduction for medium access layer (NFC-DEP)\n           information frames. The value may be 0, 1, 2, or 3 for a\n           maximum payload size of 64, 128, 192, or 254 bytes,\n           respectively. The default value is 3.\n\n        'lrt' : integer\n           For the local device in Target role this attribute sets\n           the length reduction for medium access layer (NFC-DEP)\n           information frames. The value may be 0, 1, 2, or 3 for a\n           maximum payload size of 64, 128, 192, or 254 bytes,\n           respectively. The default value is 3.\n\n        .. sourcecode:: python\n\n           import nfc\n           import nfc.llcp\n           import threading\n\n           def server(socket):\n               message, address = socket.recvfrom()\n               socket.sendto(\"It's me!\", address)\n               socket.close()\n\n           def client(socket):\n               socket.sendto(\"Hi there!\", address=32)\n               socket.close()\n\n           def on_startup(llc):\n               socket = nfc.llcp.Socket(llc, nfc.llcp.LOGICAL_DATA_LINK)\n               socket.bind(address=32)\n               threading.Thread(target=server, args=(socket,)).start()\n               return llc\n\n           def on_connect(llc):\n               socket = nfc.llcp.Socket(llc, nfc.llcp.LOGICAL_DATA_LINK)\n               threading.Thread(target=client, args=(socket,)).start()\n               return True\n\n           llcp_options = {\n               'on-startup': on_startup,\n               'on-connect': on_connect,\n           }\n           with nfc.ContactlessFrontend('usb') as clf:\n               clf.connect(llcp=llcp_options)\n               print(\"link terminated\")\n\n        **Card Emulation Options**\n\n        'on-startup' : function(target)\n           This function is called to prepare a local target for\n           discovery. The input argument is a fresh instance of an\n           unspecific :class:`LocalTarget` that can be set to the\n           desired bitrate and modulation type and populated with the\n           type specific discovery responses (see :meth:`listen` for\n           response data that is needed). The fully specified target\n           object must then be returned.\n\n        'on-discover' : function(target)\n           This function is called when the :class:`LocalTarget` has\n           been discovered. The *target* argument contains the\n           technology type specific discovery commands. The target\n           will be further activated only if this function returns a\n           true value. The default function always returns True.\n\n        'on-connect' : function(tag)\n           This function is called when the local target was\n           discovered and a :class:`nfc.tag.TagEmulation` object\n           successfully initialized. The function receives the\n           emulated *tag* object which stores the first command\n           received after inialization as ``tag.cmd``. The function\n           should return a true value if the tag.process_command() and\n           tag.send_response() methods shall be called repeatedly\n           until either the remote device terminates communication or\n           the 'terminate' function returns a true value. The function\n           should return a false value if the :meth:`connect` method\n           shall return immediately with the emulated *tag* object.\n\n        'on-release' : function(tag)\n           This function is called when the Target was released by the\n           Initiator or simply moved away, or if the terminate\n           callback function has returned a true value. The emulated\n           *tag* object may be used for cleanup actions but not for\n           communication.\n\n        .. sourcecode:: python\n\n           import nfc\n\n           def on_startup(target):\n               idm = bytearray.fromhex(\"01010501b00ac30b\")\n               pmm = bytearray.fromhex(\"03014b024f4993ff\")\n               sys = bytearray.fromhex(\"1234\")\n               target.brty = \"212F\"\n               target.sensf_res = chr(1) + idm + pmm + sys\n               return target\n\n           def on_connect(tag):\n               print(\"discovered by remote reader\")\n               return True\n\n           def on_release(tag):\n               print(\"remote reader is gone\")\n               return True\n\n           card_options = {\n               'on-startup': on_startup,\n               'on-connect': on_connect,\n               'on-release': on_release,\n           }\n           with nfc.ContactlessFrontend('usb') as clf:\n               clf.connect(card=card_options)\n\n        **Return Value**\n\n        The :meth:`connect` method returns :const:`None` if there were\n        no options left after the 'on-startup' functions have been\n        executed or when the 'terminate' function returned a true\n        value. It returns :const:`False` when terminated by any of the\n        following exceptions: :exc:`~exceptions.KeyboardInterrupt`,\n        :exc:`~exceptions.IOError`, :exc:`UnsupportedTargetError`.\n\n        The :meth:`connect` method returns a :class:`~nfc.tag.Tag`,\n        :class:`~nfc.llcp.llc.LogicalLinkController`, or\n        :class:`~nfc.tag.TagEmulation` object if the associated\n        'on-connect' function returned a false value to indicate that\n        it will handle presence check, peer to peer symmetry loop, or\n        command/response processing by itself.",
        "positive_code": "def connect(self, **options):\n        \n        if self.device is None:\n            raise IOError(errno.ENODEV, os.strerror(errno.ENODEV))\n\n        log.debug(\"connect{0}\".format(\n            tuple([k for k in options if options[k]])))\n\n        terminate = options.get(, lambda: False)\n        rdwr_options = options.get()\n        llcp_options = options.get()\n        card_options = options.get()\n\n        try:\n            assert isinstance(rdwr_options, (dict, type(None))), \"rdwr\"\n            assert isinstance(llcp_options, (dict, type(None))), \"llcp\"\n            assert isinstance(card_options, (dict, type(None))), \"card\"\n        except AssertionError as error:\n            raise TypeError(\"argument  must be a dictionary\" % error)\n\n        if llcp_options is not None:\n            llcp_options = dict(llcp_options)\n            llcp_options.setdefault(, lambda llc: llc)\n            llcp_options.setdefault(, lambda llc: True)\n            llcp_options.setdefault(, lambda llc: True)\n\n            llc = nfc.llcp.llc.LogicalLinkController(**llcp_options)\n            llc = llcp_options[](llc)\n            if isinstance(llc, nfc.llcp.llc.LogicalLinkController):\n                llcp_options[] = llc\n            else:\n                log.debug(\"removing llcp_options after on-startup\")\n                llcp_options = None\n\n        if rdwr_options is not None:\n            def on_discover(target):\n                if target.sel_res and target.sel_res[0] & 0x40:\n                    return False\n                elif target.sensf_res and target.sensf_res[1:3] == b\"\\x01\\xFE\":\n                    return False\n                else:\n                    return True\n\n            rdwr_options = dict(rdwr_options)\n            rdwr_options.setdefault(, [, , ])\n            rdwr_options.setdefault(, lambda targets: targets)\n            rdwr_options.setdefault(, on_discover)\n            rdwr_options.setdefault(, lambda tag: True)\n            rdwr_options.setdefault(, lambda tag: True)\n            rdwr_options.setdefault(, 5)\n            rdwr_options.setdefault(, 0.5)\n            rdwr_options.setdefault(, True)\n\n            targets = [RemoteTarget(brty) for brty in rdwr_options[]]\n            targets = rdwr_options[](targets)\n            if targets and all([isinstance(o, RemoteTarget) for o in targets]):\n                rdwr_options[] = targets\n            else:\n                log.debug(\"removing rdwr_options after on-startup\")\n                rdwr_options = None\n\n        if card_options is not None:\n            card_options = dict(card_options)\n            card_options.setdefault(, lambda target: None)\n            card_options.setdefault(, lambda target: True)\n            card_options.setdefault(, lambda tag: True)\n            card_options.setdefault(, lambda tag: True)\n\n            target = nfc.clf.LocalTarget()\n            target = card_options[](target)\n            if isinstance(target, LocalTarget):\n                card_options[] = target\n            else:\n                log.debug(\"removing card_options after on-startup\")\n                card_options = None\n\n        if not (rdwr_options or llcp_options or card_options):\n            log.warning(\"no options to connect\")\n            return None\n\n        log.debug(\"connect options after startup: %s\",\n                  .join(filter(bool, [\"rdwr\" if rdwr_options else None,\n                                          \"llcp\" if llcp_options else None,\n                                          \"card\" if card_options else None])))\n\n        try:\n            while not terminate():\n                if rdwr_options:\n                    result = self._rdwr_connect(rdwr_options, terminate)\n                    if bool(result) is True:\n                        return result\n                if llcp_options:\n                    result = self._llcp_connect(llcp_options, terminate)\n                    if bool(result) is True:\n                        return result\n                if card_options:\n                    result = self._card_connect(card_options, terminate)\n                    if bool(result) is True:\n                        return result\n        except IOError as error:\n            log.error(error)\n            return False\n        except UnsupportedTargetError as error:\n            log.info(error)\n            return False\n        except KeyboardInterrupt:\n            log.debug(\"terminated by keyboard interrupt\")\n            return False",
        "hard_negative_ids": [
            360,
            291,
            201,
            91,
            130,
            182,
            73,
            269,
            232,
            56,
            76,
            179,
            414,
            385,
            134,
            349,
            424,
            425,
            382,
            23,
            69,
            47,
            77,
            109,
            379,
            25,
            58,
            275,
            142,
            149,
            262,
            342,
            466,
            189,
            485,
            197,
            490,
            475,
            470,
            462,
            264,
            192,
            92,
            429,
            423,
            496,
            235,
            404,
            266,
            202
        ]
    },
    {
        "query": "Over which devices do we split each training batch.\n\n  In old-fashioned async mode, we split the batch over all GPUs on the\n  current worker.\n\n  In sync mode, we split the batch over all the parameter server GPUs.\n\n  This function returns an expert_utils.Parallelism object, which can be used\n  to build the model.  It is configured in a way that any variables created\n  by `tf.get_variable` will be assigned to the parameter servers and shared\n  between datashards.\n\n  Args:\n    daisy_chain_variables: whether to copy variables in a daisy chain on GPUs.\n    all_workers: whether the devices are all async workers or just this one.\n\n  Returns:\n    a expert_utils.Parallelism.",
        "positive_code": "def data_parallelism_from_flags(daisy_chain_variables=True, all_workers=False):\n  \n  dp_arg_names = inspect.getargspec(data_parallelism).args\n\n  blacklist = [\"daisy_chain_variables\", \"all_workers\"]\n\n  kwargs = {}\n  for arg in dp_arg_names:\n    if arg in blacklist:\n      continue\n    kwargs[arg] = getattr(tf.flags.FLAGS, arg)\n\n  return data_parallelism(\n      daisy_chain_variables=daisy_chain_variables,\n      all_workers=all_workers,\n      **kwargs)",
        "hard_negative_ids": [
            360,
            414,
            291,
            376,
            287,
            466,
            489,
            189,
            391,
            153,
            66,
            368,
            373,
            38,
            47,
            269,
            179,
            295,
            324,
            458,
            23,
            116,
            76,
            73,
            146,
            109,
            232,
            105,
            249,
            470,
            499,
            496,
            275,
            42,
            79,
            136,
            142,
            25,
            89,
            171,
            255,
            254,
            64,
            434,
            333,
            197,
            192,
            462,
            370,
            198
        ]
    },
    {
        "query": "When we have a model, save the relation in the database, to later create\n        RelatedCollection objects in the related model",
        "positive_code": "def _attach_to_model(self, model):\n        \n        super(RelatedFieldMixin, self)._attach_to_model(model)\n\n        if model.abstract:\n            \n        relation = (self._model._name, self.name, self.related_name)\n        self.database._relations[self.related_to].append(relation)",
        "hard_negative_ids": [
            89,
            333,
            489,
            467,
            360,
            325,
            273,
            198,
            222,
            73,
            414,
            189,
            459,
            466,
            170,
            79,
            452,
            291,
            152,
            197,
            9,
            171,
            39,
            106,
            470,
            136,
            496,
            304,
            409,
            383,
            109,
            391,
            23,
            44,
            429,
            237,
            317,
            178,
            329,
            453,
            193,
            260,
            425,
            25,
            63,
            15,
            297,
            76,
            163,
            474
        ]
    },
    {
        "query": "Create a collection object from a Cary UV VIS absorbance file.\n\n    We hope to support as many Cary instruments and datasets as possible.\n    This function has been tested with data collected on a Cary50 UV/VIS spectrometer.\n    If any alternate instruments are found not to work as expected, please\n    submit a bug report on our `issue tracker`__.\n\n    __ github.com/wright-group/WrightTools/issues\n\n    .. plot::\n\n        >>> import WrightTools as wt\n        >>> from WrightTools import datasets\n        >>> p = datasets.Cary.CuPCtS_H2O_vis\n        >>> data = wt.collection.from_Cary(p)[0]\n        >>> wt.artists.quick1D(data)\n\n    Parameters\n    ----------\n    filepath : path-like\n        Path to Cary output file (.csv).\n    parent : WrightTools.Collection\n        A collection object in which to place a collection of Data objects.\n    verbose : boolean (optional)\n        Toggle talkback. Default is True.\n\n    Returns\n    -------\n    data\n        New data object.",
        "positive_code": "def from_Cary(filepath, name=None, parent=None, verbose=True):\n    \n    \n    filestr = os.fspath(filepath)\n    filepath = pathlib.Path(filepath)\n\n    if \".csv\" not in filepath.suffixes:\n        wt_exceptions.WrongFileTypeWarning.warn(filepath, \"csv\")\n    if name is None:\n        name = \"cary\"\n    \n    lines = []\n    ds = np.DataSource(None)\n    with ds.open(filestr, \"rt\", encoding=\"iso-8859-1\") as f:\n        header = f.readline()\n        columns = f.readline()\n        while True:\n            line = f.readline()\n            if line == \"\\n\" or line == \"\" or line == \"\\r\\n\":\n                break\n            else:\n                \n                \n                line = line.replace(\",,\", \",nan,\")\n                line = line.replace(\",,\", \",nan,\")\n                \n                if line[0] == \",\":\n                    line = \"nan\" + line\n                clean = line[:-2]  \n                lines.append(np.fromstring(clean, sep=\",\"))\n    lines = [line for line in lines if len(line) > 0]\n    header = header.split(\",\")\n    columns = columns.split(\",\")\n    arr = np.array(lines).T\n    duplicate = len(header) // 2 == len(set(header) - {\"\"})\n    \n    datas = Collection(name=name, parent=parent, edit_local=parent is not None)\n    units_dict = {\"c\": \"deg_C\", \"f\": \"deg_F\"}\n    for i in range(0, len(header) - 1, 2):\n        r = re.compile(r\"[ \\t\\(\\)]+\")\n        spl = r.split(columns[i])\n        ax = spl[0].lower() if len(spl) > 0 else None\n        units = spl[1].lower() if len(spl) > 1 else None\n        units = units_dict.get(units, units)\n        if duplicate:\n            name = \"{}_{:03d}\".format(header[i], i // 2)\n        else:\n            name = header[i]\n        dat = datas.create_data(name, kind=\"Cary\", source=filestr)\n        dat.create_variable(ax, arr[i][~np.isnan(arr[i])], units=units)\n        dat.create_channel(\n            columns[i + 1].lower(), arr[i + 1][~np.isnan(arr[i + 1])], label=columns[i + 1].lower()\n        )\n        dat.transform(ax)\n    \n    if verbose:\n        print(\"{0} data objects successfully created from Cary file:\".format(len(datas)))\n        for i, data in enumerate(datas):\n            print(\"  {0}: {1}\".format(i, data))\n    return datas",
        "hard_negative_ids": [
            424,
            475,
            500,
            349,
            376,
            136,
            429,
            170,
            480,
            254,
            171,
            252,
            150,
            391,
            275,
            79,
            14,
            421,
            404,
            23,
            443,
            193,
            460,
            39,
            383,
            470,
            33,
            269,
            76,
            99,
            256,
            154,
            363,
            163,
            82,
            466,
            435,
            265,
            412,
            38,
            253,
            414,
            131,
            111,
            360,
            101,
            207,
            81,
            159,
            499
        ]
    },
    {
        "query": "Set the prefix for the node (see Leaf class).\n\n        DEPRECATED; use the prefix property directly.",
        "positive_code": "def set_prefix(self, prefix):\n        \n        warnings.warn(\"set_prefix() is deprecated; use the prefix property\",\n                      DeprecationWarning, stacklevel=2)\n        self.prefix = prefix",
        "hard_negative_ids": [
            341,
            305,
            244,
            165,
            174,
            414,
            126,
            215,
            122,
            360,
            18,
            311,
            25,
            197,
            291,
            379,
            466,
            272,
            113,
            366,
            136,
            73,
            319,
            23,
            31,
            429,
            44,
            109,
            277,
            47,
            76,
            297,
            464,
            11,
            97,
            90,
            61,
            289,
            184,
            236,
            239,
            426,
            266,
            235,
            258,
            127,
            490,
            135,
            489,
            321
        ]
    },
    {
        "query": "Uses Extended Bayesian Information Criteria for model selection.\n\n        Can only be used in path mode (doesn't really make sense otherwise).\n\n        See:\n        Extended Bayesian Information Criteria for Gaussian Graphical Models\n        R. Foygel and M. Drton\n        NIPS 2010\n\n        Parameters\n        ----------\n        gamma : (float) \\in (0, 1)\n            Choice of gamma=0 leads to classical BIC\n            Positive gamma leads to stronger penalization of large graphs.\n\n        Returns\n        -------\n        Lambda index with best ebic score.  When multiple ebic scores are the\n        same, returns the smallest lambda (largest index) with minimum score.",
        "positive_code": "def ebic_select(self, gamma=0):\n        \n        if not isinstance(self.precision_, list):\n            raise ValueError(\"EBIC requires multiple models to select from.\")\n            return\n\n        if not self.is_fitted_:\n            return\n\n        ebic_scores = self.ebic(gamma=gamma)\n        min_indices = np.where(np.abs(ebic_scores - ebic_scores.min()) < 1e-10)\n        return np.max(min_indices)",
        "hard_negative_ids": [
            333,
            414,
            280,
            466,
            152,
            345,
            38,
            462,
            269,
            136,
            347,
            238,
            79,
            493,
            291,
            489,
            368,
            127,
            382,
            89,
            232,
            198,
            160,
            254,
            233,
            37,
            349,
            23,
            73,
            360,
            381,
            149,
            245,
            56,
            429,
            69,
            109,
            122,
            386,
            279,
            275,
            255,
            170,
            496,
            77,
            197,
            239,
            142,
            426,
            272
        ]
    },
    {
        "query": "Execute an Analytics query.\n\n        This method is mainly a wrapper around the :class:`~.AnalyticsQuery`\n        and :class:`~.AnalyticsRequest` objects, which contain the inputs\n        and outputs of the query.\n\n        Using an explicit :class:`~.AnalyticsQuery`::\n\n            query = AnalyticsQuery(\n                \"SELECT VALUE bw FROM breweries bw WHERE bw.name = ?\", \"Kona Brewing\")\n            for row in cb.analytics_query(query, \"127.0.0.1\"):\n                print('Entry: {0}'.format(row))\n\n        Using an implicit :class:`~.AnalyticsQuery`::\n\n            for row in cb.analytics_query(\n                \"SELECT VALUE bw FROM breweries bw WHERE bw.name = ?\", \"127.0.0.1\", \"Kona Brewing\"):\n                print('Entry: {0}'.format(row))\n\n        :param query: The query to execute. This may either be a\n            :class:`.AnalyticsQuery` object, or a string (which will be\n            implicitly converted to one).\n        :param host: The host to send the request to.\n        :param args: Positional arguments for :class:`.AnalyticsQuery`.\n        :param kwargs: Named arguments for :class:`.AnalyticsQuery`.\n        :return: An iterator which yields rows. Each row is a dictionary\n            representing a single result",
        "positive_code": "def analytics_query(self, query, host, *args, **kwargs):\n        \n        if not isinstance(query, AnalyticsQuery):\n            query = AnalyticsQuery(query, *args, **kwargs)\n        else:\n            query.update(*args, **kwargs)\n\n        return couchbase.analytics.gen_request(query, host, self)",
        "hard_negative_ids": [
            360,
            142,
            287,
            269,
            166,
            429,
            297,
            291,
            41,
            232,
            487,
            81,
            246,
            171,
            414,
            112,
            73,
            76,
            243,
            222,
            382,
            324,
            139,
            349,
            146,
            470,
            131,
            425,
            189,
            466,
            424,
            450,
            182,
            137,
            173,
            413,
            478,
            23,
            79,
            295,
            135,
            325,
            386,
            210,
            311,
            178,
            103,
            156,
            323,
            376
        ]
    },
    {
        "query": "Copy memory writes from Manticore back into Unicorn in real-time",
        "positive_code": "def write_back_memory(self, where, expr, size):\n        \n        if self.write_backs_disabled:\n            return\n        if type(expr) is bytes:\n            self._emu.mem_write(where, expr)\n        else:\n            if issymbolic(expr):\n                data = [Operators.CHR(Operators.EXTRACT(expr, offset, 8)) for offset in range(0, size, 8)]\n                concrete_data = []\n                for c in data:\n                    if issymbolic(c):\n                        c = chr(solver.get_value(self._cpu.memory.constraints, c))\n                    concrete_data.append(c)\n                data = concrete_data\n            else:\n                data = [Operators.CHR(Operators.EXTRACT(expr, offset, 8)) for offset in range(0, size, 8)]\n            logger.debug(f\"Writing back {hr_size(size // 8)} to {hex(where)}: {data}\")\n            ",
        "hard_negative_ids": [
            80,
            202,
            25,
            490,
            201,
            58,
            440,
            420,
            193,
            7,
            76,
            34,
            26,
            67,
            414,
            24,
            69,
            367,
            64,
            131,
            74,
            11,
            256,
            81,
            344,
            185,
            153,
            147,
            231,
            208,
            343,
            77,
            245,
            73,
            95,
            268,
            472,
            53,
            23,
            155,
            349,
            435,
            1,
            56,
            99,
            17,
            416,
            361,
            391,
            149
        ]
    },
    {
        "query": "Check if path exists, if it does add number to path (incrementing until\n  a unique path is found).\n\n  Parameters\n  ----------\n    path : string\n      Path of directory to try.\n\n  Returns\n  ----------\n    string\n      Path of unique directory.",
        "positive_code": "def CheckPathExists(path):\n  \n  i = 0\n  root, ext = os.path.splitext(path)\n  while os.path.exists(path):\n    i = i + 1\n    goodlogging.Log.Info(\"UTIL\", \"Path {0} already exists\".format(path))\n    path = \"{0}_{1}\".format(root, i) + ext\n  return path",
        "hard_negative_ids": [
            38,
            210,
            170,
            413,
            333,
            40,
            349,
            342,
            456,
            254,
            425,
            142,
            44,
            246,
            380,
            457,
            201,
            363,
            466,
            185,
            458,
            197,
            23,
            193,
            234,
            453,
            169,
            272,
            391,
            171,
            73,
            144,
            470,
            289,
            98,
            252,
            436,
            163,
            275,
            76,
            215,
            34,
            31,
            394,
            138,
            1,
            157,
            109,
            69,
            360
        ]
    },
    {
        "query": "Add a Metric Point to a Metric\n\n        :param int metric_id: Metric ID\n        :param int value: Value to plot on the metric graph\n        :param str timestamp: Unix timestamp of the point was measured\n        :return: Created metric point data (:class:`dict`)\n\n        .. seealso:: https://docs.cachethq.io/reference#post-metric-points",
        "positive_code": "def create(self, metric_id, value, timestamp=None):\n        \n        data = ApiParams()\n        data[] = value\n        data[] = timestamp\n        return self._post( % metric_id, data=data)[]",
        "hard_negative_ids": [
            492,
            122,
            300,
            207,
            265,
            81,
            204,
            382,
            349,
            360,
            256,
            466,
            429,
            391,
            56,
            197,
            33,
            105,
            165,
            489,
            424,
            361,
            222,
            481,
            195,
            418,
            453,
            414,
            500,
            178,
            73,
            147,
            421,
            267,
            332,
            76,
            272,
            127,
            235,
            171,
            462,
            91,
            344,
            166,
            15,
            279,
            441,
            232,
            2,
            291
        ]
    },
    {
        "query": ":return: an attribute from the parsed element if it has the attribute,\n    otherwise the default value",
        "positive_code": "def get_element_attribute(elem_to_parse, attrib_name, default_value=u):\n    \n\n    element = get_element(elem_to_parse)\n\n    if element is None:\n        return default_value\n\n    return element.attrib.get(attrib_name, default_value)",
        "hard_negative_ids": [
            91,
            424,
            168,
            433,
            360,
            461,
            348,
            306,
            73,
            414,
            84,
            56,
            405,
            11,
            69,
            178,
            197,
            375,
            291,
            267,
            332,
            481,
            466,
            166,
            441,
            227,
            136,
            366,
            362,
            189,
            311,
            382,
            349,
            19,
            242,
            76,
            268,
            429,
            44,
            193,
            199,
            7,
            26,
            182,
            23,
            280,
            99,
            367,
            25,
            131
        ]
    },
    {
        "query": "Fetch a gateway device.",
        "positive_code": "def show_gateway_device(self, gateway_device_id, **_params):\n        \n        return self.get(self.gateway_device_path % gateway_device_id,\n                        params=_params)",
        "hard_negative_ids": [
            395,
            106,
            304,
            391,
            277,
            293,
            453,
            178,
            317,
            425,
            360,
            171,
            15,
            470,
            256,
            382,
            462,
            222,
            349,
            472,
            76,
            466,
            180,
            272,
            23,
            29,
            28,
            27,
            26,
            25,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471,
            469,
            468,
            467,
            465
        ]
    },
    {
        "query": "Figure out which handler to use, based on metadata.\n    Returns a handler instance or None.\n\n    ``text`` should be unicode text about to be parsed.\n\n    ``handlers`` is a dictionary where keys are opening delimiters \n    and values are handler instances.",
        "positive_code": "def detect_format(text, handlers):\n    \n    for pattern, handler in handlers.items():\n        if pattern.match(text):\n            return handler\n\n    \n    return None",
        "hard_negative_ids": [
            385,
            269,
            261,
            481,
            382,
            178,
            425,
            499,
            349,
            333,
            291,
            487,
            472,
            462,
            15,
            332,
            308,
            219,
            47,
            414,
            360,
            232,
            182,
            437,
            146,
            62,
            327,
            433,
            131,
            171,
            435,
            466,
            192,
            464,
            90,
            424,
            304,
            470,
            391,
            429,
            122,
            106,
            237,
            386,
            52,
            222,
            23,
            11,
            196,
            109
        ]
    },
    {
        "query": "Map of json-rpc available calls.\n\n        :return str:",
        "positive_code": "def jsonrpc_map(self):\n        \n        result = \"<h1>JSON-RPC map</h1><pre>{0}</pre>\".format(\"\\n\\n\".join([\n            \"{0}: {1}\".format(fname, f.__doc__)\n            for fname, f in self.dispatcher.items()\n        ]))\n        return Response(result)",
        "hard_negative_ids": [
            428,
            98,
            16,
            424,
            292,
            152,
            207,
            429,
            349,
            434,
            343,
            265,
            52,
            392,
            379,
            466,
            395,
            470,
            232,
            58,
            484,
            435,
            377,
            188,
            376,
            412,
            340,
            463,
            222,
            197,
            318,
            450,
            393,
            190,
            157,
            192,
            230,
            127,
            481,
            63,
            414,
            331,
            94,
            165,
            339,
            183,
            59,
            84,
            367,
            138
        ]
    },
    {
        "query": "Authenticates account, if no password given tries to pre-authenticate.\n        @param transport: transport to use for method calls\n        @param account_name: account name\n        @param password: account password\n        @return: AuthToken if authentication succeeded\n        @raise AuthException: if authentication fails",
        "positive_code": "def authenticate(self, transport, account_name, password):\n        \n        if not isinstance(transport, ZimbraClientTransport):\n            raise ZimbraClientException()\n\n        if util.empty(account_name):\n            raise AuthException()",
        "hard_negative_ids": [
            191,
            55,
            81,
            251,
            52,
            189,
            425,
            323,
            204,
            73,
            344,
            41,
            498,
            252,
            122,
            300,
            203,
            47,
            16,
            414,
            70,
            176,
            139,
            402,
            201,
            269,
            131,
            76,
            386,
            66,
            496,
            65,
            99,
            412,
            171,
            264,
            295,
            44,
            150,
            275,
            360,
            87,
            454,
            376,
            324,
            109,
            368,
            291,
            197,
            321
        ]
    },
    {
        "query": "Simple slice.",
        "positive_code": "def on_slice(self, node):    \n        \n        return slice(self.run(node.lower),\n                     self.run(node.upper),\n                     self.run(node.step))",
        "hard_negative_ids": [
            88,
            481,
            16,
            17,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453,
            452,
            451
        ]
    },
    {
        "query": "A helper method for scanning the footpaths. Updates self._stop_profiles accordingly",
        "positive_code": "def _scan_footpaths_to_departure_stop(self, connection_dep_stop, connection_dep_time, arrival_time_target):\n        \n        for _, neighbor, data in self._walk_network.edges_iter(nbunch=[connection_dep_stop],\n                                                               data=True):\n            d_walk = data[]\n            neighbor_dep_time = connection_dep_time - d_walk / self._walk_speed\n            pt = LabelTimeSimple(departure_time=neighbor_dep_time, arrival_time_target=arrival_time_target)\n            self._stop_profiles[neighbor].update_pareto_optimal_tuples(pt)",
        "hard_negative_ids": [
            323,
            429,
            41,
            360,
            402,
            70,
            139,
            466,
            106,
            44,
            304,
            391,
            414,
            197,
            85,
            291,
            317,
            453,
            178,
            15,
            425,
            476,
            136,
            351,
            23,
            73,
            171,
            434,
            45,
            295,
            76,
            470,
            87,
            25,
            382,
            256,
            222,
            412,
            462,
            186,
            64,
            420,
            180,
            349,
            67,
            109,
            472,
            90,
            336,
            272
        ]
    },
    {
        "query": "Get a cursor for the specified transaction connection\n        or acquire from the pool.",
        "positive_code": "async def cursor(self, conn=None, *args, **kwargs):\n        \n        in_transaction = conn is not None\n        if not conn:\n            conn = await self.acquire()\n        cursor = await conn.cursor(*args, **kwargs)\n        cursor.release = functools.partial(\n            self.release_cursor, cursor,\n            in_transaction=in_transaction)\n        return cursor",
        "hard_negative_ids": [
            125,
            73,
            249,
            360,
            474,
            291,
            450,
            466,
            414,
            266,
            326,
            421,
            197,
            391,
            136,
            106,
            425,
            304,
            11,
            382,
            23,
            15,
            317,
            318,
            193,
            453,
            153,
            498,
            178,
            7,
            26,
            72,
            429,
            295,
            44,
            367,
            131,
            25,
            462,
            113,
            171,
            185,
            82,
            69,
            280,
            389,
            180,
            349,
            67,
            191
        ]
    },
    {
        "query": "Collects the tracing data from the given parameters.\n        :param request: The Flask request.\n        :param response: The flask response.\n        :param error: The error occurred if any.\n        :param latency: The time elapsed to process the request.\n        :return: The tracing data.",
        "positive_code": "def __collect_trace_data(self, request, response, error, latency):\n        \n\n        data = OrderedDict()\n        data[] = latency.elapsed\n        data[] = request.environ[]\n        data[] = request.url\n        data[] = request.headers\n\n        body = request.get_data(as_text=True)\n        if body:\n            data[] = body\n\n        if response:\n            data[] = response.status_code\n\n        if error:\n            data[] = str(error)\n\n        return data",
        "hard_negative_ids": [
            10,
            421,
            73,
            139,
            491,
            167,
            131,
            81,
            200,
            360,
            490,
            427,
            402,
            414,
            197,
            344,
            463,
            201,
            204,
            466,
            129,
            415,
            52,
            202,
            25,
            425,
            44,
            223,
            322,
            285,
            269,
            291,
            404,
            498,
            300,
            32,
            23,
            243,
            33,
            195,
            136,
            339,
            141,
            357,
            222,
            85,
            424,
            369,
            154,
            440
        ]
    },
    {
        "query": "Parse a SCOPE element and return a dictionary with an item for each\n        specified scope attribute.\n\n        The keys of the dictionary items are the scope names in upper case; the\n        values are the Python boolean values True or False.\n\n        Unspecified scope attributes are not represented in the returned\n        dictionary; the user is expected to assume their default value of\n        False.\n\n        The returned dictionary does not preserve order of the scope\n        attributes.\n\n          ::\n\n            <!ELEMENT SCOPE EMPTY>\n            <!ATTLIST SCOPE\n                CLASS (true | false) \"false\"\n                ASSOCIATION (true | false) \"false\"\n                REFERENCE (true | false) \"false\"\n                PROPERTY (true | false) \"false\"\n                METHOD (true | false) \"false\"\n                PARAMETER (true | false) \"false\"\n                INDICATION (true | false) \"false\"",
        "positive_code": "def parse_scope(self, tup_tree):\n        \n\n        self.check_node(tup_tree, , (),\n                        (, , , ,\n                         , , ), ())\n\n        \n        \n        \n        scopes = NocaseDict()\n        for k, v in attrs(tup_tree).items():\n            v_ = self.unpack_boolean(v)\n            if v_ is None:\n                raise CIMXMLParseError(\n                    _format(\"Element {0!A} has an invalid value {1!A} for its \"\n                            \"boolean attribute {2!A}\", name(tup_tree), v, k),\n                    conn_id=self.conn_id)\n            scopes[k] = v_\n        return scopes",
        "hard_negative_ids": [
            91,
            360,
            429,
            84,
            349,
            424,
            466,
            332,
            197,
            382,
            136,
            433,
            178,
            308,
            15,
            222,
            291,
            352,
            66,
            73,
            23,
            113,
            414,
            85,
            485,
            461,
            44,
            348,
            107,
            327,
            425,
            318,
            76,
            287,
            306,
            165,
            168,
            56,
            333,
            345,
            252,
            368,
            159,
            142,
            232,
            323,
            11,
            182,
            192,
            311
        ]
    },
    {
        "query": "Run bamCoverage from deeptools",
        "positive_code": "def _bam_coverage(name, bam_input, data):\n    \n    cmd = (\"{bam_coverage} -b {bam_input} -o {bw_output} \"\n          \"--binSize 20 --effectiveGenomeSize {size} \"\n          \"--smoothLength 60 --extendReads 150 --centerReads -p {cores}\")\n    size = bam.fasta.total_sequence_length(dd.get_ref_file(data))\n    cores = dd.get_num_cores(data)\n    try:\n        bam_coverage = config_utils.get_program(\"bamCoverage\", data)\n    except config_utils.CmdNotFound:\n        logger.info(\"No bamCoverage found, skipping bamCoverage.\")\n        return None\n    resources = config_utils.get_resources(\"bamCoverage\", data[\"config\"])\n    if resources:\n        options = resources.get(\"options\")\n        if options:\n            cmd += \" %s\" % \" \".join([str(x) for x in options])\n    bw_output = os.path.join(os.path.dirname(bam_input), \"%s.bw\" % name)\n    if utils.file_exists(bw_output):\n        return bw_output\n    with file_transaction(bw_output) as out_tx:\n        do.run(cmd.format(**locals()), \"Run bamCoverage in %s\" % name)\n    return bw_output",
        "hard_negative_ids": [
            451,
            370,
            216,
            193,
            181,
            7,
            26,
            438,
            367,
            322,
            131,
            11,
            9,
            69,
            153,
            67,
            201,
            185,
            236,
            277,
            147,
            231,
            208,
            343,
            289,
            73,
            99,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458
        ]
    },
    {
        "query": "Return the application URL from the app info page on the Spark master.\n        Due to a bug, we need to parse the HTML manually because we cannot\n        fetch JSON data from HTTP interface.",
        "positive_code": "def _get_standalone_app_url(self, app_id, spark_master_address, requests_config, tags):\n        \n        app_page = self._rest_request(\n            spark_master_address,\n            SPARK_MASTER_APP_PATH,\n            SPARK_STANDALONE_SERVICE_CHECK,\n            requests_config,\n            tags,\n            appId=app_id,\n        )\n\n        dom = BeautifulSoup(app_page.text, )\n        app_detail_ui_links = dom.find_all(, string=)\n\n        if app_detail_ui_links and len(app_detail_ui_links) == 1:\n            return app_detail_ui_links[0].attrs[]",
        "hard_negative_ids": [
            193,
            498,
            306,
            254,
            429,
            315,
            360,
            73,
            414,
            395,
            117,
            322,
            482,
            428,
            273,
            466,
            357,
            217,
            421,
            197,
            480,
            178,
            255,
            131,
            264,
            389,
            474,
            484,
            171,
            291,
            109,
            496,
            376,
            223,
            463,
            47,
            499,
            38,
            402,
            161,
            136,
            368,
            326,
            500,
            204,
            434,
            256,
            187,
            7,
            106
        ]
    },
    {
        "query": "Reset the internal buffers for the abstract canvas.",
        "positive_code": "def reset(self):\n        \n        \n        self._start_line = 0\n        self._x = self._y = None\n        self._buffer = _DoubleBuffer(self._buffer_height, self.width)\n        self._reset()",
        "hard_negative_ids": [
            360,
            414,
            197,
            291,
            466,
            9,
            97,
            136,
            73,
            429,
            44,
            472,
            23,
            25,
            285,
            109,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190,
            443,
            145,
            103,
            4,
            344,
            122,
            387,
            246,
            411,
            477
        ]
    },
    {
        "query": "Creates and sends a new SignatureRequest with the submitted documents\n\n        Creates and sends a new SignatureRequest with the submitted documents.\n        If form_fields_per_document is not specified, a signature page will be\n        affixed where all signers will be required to add their signature,\n        signifying their agreement to all contained documents.\n\n        Args:\n\n            test_mode (bool, optional):             Whether this is a test, the signature request will not be legally binding if set to True. Defaults to False.\n\n            files (list of str):                    The uploaded file(s) to send for signature\n\n            file_urls (list of str):                URLs of the file for HelloSign to download to send for signature. Use either `files` or `file_urls`\n\n            title (str, optional):                  The title you want to assign to the SignatureRequest\n\n            subject (str, optional):                The subject in the email that will be sent to the signers\n\n            message (str, optional):                The custom message in the email that will be sent to the signers\n\n            signing_redirect_url (str, optional):   The URL you want the signer redirected to after they successfully sign.\n\n            signers (list of dict):                 A list of signers, which each has the following attributes:\n\n                name (str):                         The name of the signer\n                email_address (str):                Email address of the signer\n                order (str, optional):              The order the signer is required to sign in\n                pin (str, optional):                The 4- to 12-character access code that will secure this signer's signature page\n\n            cc_email_addresses (list, optional):    A list of email addresses that should be CC'd\n\n            form_fields_per_document (str):         The fields that should appear on the document, expressed as a serialized JSON data structure which is a list of lists of the form fields. Please refer to the API reference of HelloSign for more details (https://www.hellosign.com/api/reference#SignatureRequest)\n\n            use_text_tags (bool, optional):         Use text tags in the provided file(s) to create form fields\n\n            hide_text_tags (bool, optional):        Hide text tag areas\n\n            metadata (dict, optional):              Metadata to associate with the signature request\n\n            ux_version (int):                       UX version, either 1 (default) or 2.\n\n            allow_decline(bool, optional):         Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        Returns:\n            A SignatureRequest object",
        "positive_code": "def send_signature_request(self, test_mode=False, files=None, file_urls=None, title=None, subject=None, message=None, signing_redirect_url=None, signers=None, cc_email_addresses=None, form_fields_per_document=None, use_text_tags=False, hide_text_tags=False, metadata=None, ux_version=None, allow_decline=False):\n        s signature page\n\n            cc_email_addresses (list, optional):    A list of email addresses that should be CC\n\n        self._check_required_fields({\n            \"signers\": signers\n        }, [{\n            \"files\": files,\n            \"file_urls\": file_urls\n            }]\n        )\n\n        params = {\n            : test_mode,\n            : files,\n            : file_urls,\n            : title,\n            : subject,\n            : message,\n            : signing_redirect_url,\n            : signers,\n            : cc_email_addresses,\n            : form_fields_per_document,\n            : use_text_tags,\n            : hide_text_tags,\n            : metadata,\n            : allow_decline\n        }\n\n        if ux_version is not None:\n            params[] = ux_version\n\n        return self._send_signature_request(**params)",
        "hard_negative_ids": [
            429,
            360,
            168,
            466,
            306,
            414,
            291,
            386,
            382,
            268,
            73,
            200,
            23,
            402,
            264,
            136,
            127,
            275,
            47,
            171,
            84,
            76,
            462,
            425,
            500,
            269,
            415,
            207,
            412,
            379,
            149,
            349,
            460,
            424,
            265,
            197,
            1,
            470,
            488,
            189,
            435,
            391,
            182,
            232,
            222,
            2,
            193,
            179,
            91,
            405
        ]
    },
    {
        "query": "I run functions from the command-line!",
        "positive_code": "def command_line_runner():\n    \n    filename = sys.argv[-1]\n    if not filename.endswith(\".rst\"):\n        print(\"ERROR! Please enter a ReStructuredText filename!\")\n        sys.exit()\n    print(rst_to_json(file_opener(filename)))",
        "hard_negative_ids": [
            444,
            452,
            235,
            66,
            438,
            166,
            407,
            360,
            245,
            236,
            9,
            42,
            69,
            314,
            394,
            359,
            135,
            58,
            451,
            393,
            64,
            385,
            317,
            252,
            370,
            414,
            109,
            53,
            171,
            73,
            216,
            130,
            89,
            218,
            149,
            466,
            197,
            61,
            186,
            413,
            181,
            160,
            472,
            193,
            291,
            182,
            4,
            464,
            324,
            7
        ]
    },
    {
        "query": "Returns a NumPy array that represents the 2D pixel location,\n        which is defined by PFNC, of the original image data.\n\n        You may use the returned NumPy array for a calculation to map the\n        original image to another format.\n\n        :return: A NumPy array that represents the 2D pixel location.",
        "positive_code": "def represent_pixel_location(self):\n        \n        if self.data is None:\n            return None\n\n        \n        return self._data.reshape(\n            self.height + self.y_padding,\n            int(self.width * self._num_components_per_pixel + self.x_padding)\n        )",
        "hard_negative_ids": [
            360,
            466,
            12,
            291,
            414,
            88,
            271,
            264,
            197,
            146,
            256,
            161,
            136,
            73,
            171,
            269,
            276,
            277,
            286,
            304,
            421,
            106,
            101,
            23,
            349,
            429,
            189,
            122,
            237,
            470,
            391,
            100,
            47,
            223,
            81,
            453,
            317,
            154,
            425,
            15,
            178,
            232,
            192,
            152,
            498,
            157,
            343,
            239,
            195,
            222
        ]
    },
    {
        "query": "Returns the default collector settings",
        "positive_code": "def get_default_config(self):\n        \n        config = super(UDPCollector, self).get_default_config()\n        config.update({\n            :          ,\n            :  +\n                             \n        })\n        return config",
        "hard_negative_ids": [
            168,
            424,
            306,
            65,
            84,
            16,
            405,
            473,
            73,
            360,
            76,
            197,
            414,
            323,
            291,
            209,
            466,
            136,
            429,
            44,
            23,
            25,
            99,
            179,
            109,
            176,
            150,
            380,
            328,
            460,
            485,
            498,
            487,
            478,
            435,
            481,
            94,
            441,
            390,
            21,
            134,
            386,
            5,
            250,
            193,
            454,
            226,
            112,
            86,
            128
        ]
    },
    {
        "query": ":param status_code:\n    :param kwargs:\n    :return:",
        "positive_code": "def write_error(self, status_code, **kwargs):\n    \n    if \"exc_info\" in kwargs:\n      exc_info = kwargs[\"exc_info\"]\n      error = exc_info[1]\n\n      errormessage = \"%s: %s\" % (status_code, error)\n      self.render(\"error.html\", errormessage=errormessage)\n    else:\n      errormessage = \"%s\" % (status_code)\n      self.render(\"error.html\", errormessage=errormessage)",
        "hard_negative_ids": [
            81,
            478,
            230,
            204,
            344,
            212,
            16,
            300,
            396,
            123,
            5,
            45,
            287,
            488,
            52,
            226,
            139,
            191,
            269,
            316,
            85,
            295,
            112,
            420,
            412,
            7,
            138,
            222,
            82,
            451,
            324,
            369,
            33,
            41,
            219,
            227,
            67,
            207,
            188,
            285,
            385,
            179,
            427,
            264,
            192,
            279,
            176,
            150,
            380,
            328
        ]
    },
    {
        "query": "Runs all set type transformers / validators against the provided input parameters and returns any errors",
        "positive_code": "def validate(self, input_parameters, context):\n        \n        errors = {}\n\n        for key, type_handler in self.input_transformations.items():\n            if self.raise_on_invalid:\n                if key in input_parameters:\n                    input_parameters[key] = self.initialize_handler(\n                        type_handler,\n                        input_parameters[key],\n                        context=context\n                    )\n            else:\n                try:\n                    if key in input_parameters:\n                        input_parameters[key] = self.initialize_handler(\n                            type_handler,\n                            input_parameters[key],\n                            context=context\n                        )\n                except InvalidTypeData as error:\n                    errors[key] = error.reasons or str(error.message)\n                except Exception as error:\n                    if hasattr(error, ) and error.args:\n                        errors[key] = error.args[0]\n                    else:\n                        errors[key] = str(error)\n        for require in self.required:\n            if not require in input_parameters:\n                errors[require] = \"Required parameter  not supplied\".format(require)\n        if not errors and getattr(self, , False):\n            errors = self.validate_function(input_parameters)\n        return errors",
        "hard_negative_ids": [
            429,
            201,
            496,
            404,
            25,
            23,
            232,
            413,
            76,
            185,
            291,
            269,
            360,
            174,
            197,
            207,
            88,
            85,
            116,
            345,
            181,
            457,
            295,
            349,
            289,
            44,
            500,
            280,
            414,
            252,
            279,
            109,
            184,
            73,
            133,
            233,
            90,
            115,
            466,
            265,
            20,
            159,
            361,
            236,
            451,
            113,
            12,
            32,
            296,
            142
        ]
    },
    {
        "query": "r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.",
        "positive_code": "def ystep(self):\n        r\n\n        if self.opt[] or self.opt[]:\n            Y1 = self.block_sep1(self.Y)\n            if self.opt[]:\n                Y1[Y1 < 0.0] = 0.0\n            if self.opt[]:\n                for n in range(0, self.cri.dimN):\n                    Y1[(slice(None),)*n +\n                       (slice(1-self.D.shape[n], None),)] = 0.0\n            self.block_sep1(self.Y)[:] = Y1",
        "hard_negative_ids": [
            3,
            269,
            263,
            296,
            240,
            391,
            495,
            321,
            245,
            496,
            179,
            206,
            464,
            77,
            280,
            472,
            230,
            329,
            427,
            156,
            318,
            75,
            264,
            73,
            414,
            171,
            170,
            290,
            386,
            34,
            143,
            275,
            131,
            181,
            96,
            306,
            444,
            368,
            376,
            434,
            74,
            295,
            67,
            189,
            59,
            57,
            439,
            468,
            397,
            448
        ]
    },
    {
        "query": "Add the GO parents of a gene's associated GO IDs to the gene's association.",
        "positive_code": "def update_association(self, association):\n        \n        bad_goids = set()\n        \n        for goids in association.values():\n            parents = set()\n            \n            goids.update(parents)\n        if bad_goids:\n            sys.stdout.write(\"{N} GO IDs in assc. are not found in the GO-DAG: {GOs}\\n\".format(\n                N=len(bad_goids), GOs=\" \".join(bad_goids)))",
        "hard_negative_ids": [
            197,
            44,
            360,
            466,
            150,
            128,
            253,
            453,
            258,
            414,
            73,
            386,
            215,
            15,
            429,
            470,
            272,
            171,
            349,
            291,
            178,
            366,
            256,
            289,
            106,
            462,
            76,
            304,
            391,
            77,
            477,
            275,
            61,
            368,
            8,
            136,
            500,
            407,
            264,
            90,
            434,
            395,
            201,
            326,
            173,
            329,
            232,
            375,
            23,
            317
        ]
    },
    {
        "query": "Works with CSVs generated by the Android app 'Battery Log' (https://play.google.com/store/apps/details?id=kr.hwangti.batterylog)",
        "positive_code": "def upload_batterystats(filename, username, password, bucket_name=BUCKET_NAME, bucket_desc=BUCKET_DESC):\n    \n\n    zapi = pyzenobase.ZenobaseAPI(username, password)\n    bucket = zapi.create_or_get_bucket(bucket_name, description=bucket_desc)\n    bucket_id = bucket[\"@id\"]\n\n    events = []\n    with open(filename, newline=\"\") as f:\n        reader = csv.reader(f)\n        header = next(reader)\n        for row in reader:\n            events.append({header[i]: row[i] for i in range(len(header))})\n\n    print(\"Read {} events\".format(len(events)))\n    for event in events:\n        \n        event[\"timestamp\"] = pyzenobase.fmt_datetime(datetime.strptime(event.pop(\"datetime\"), \"%Y-%m-%d %H:%M:%S\"), timezone=\"Europe/Stockholm\")\n        event[\"tag\"] = event.pop(\"status\")\n        event[\"percentage\"] = float(event.pop(\"level\"))\n        event[\"temperature\"] = {\"@value\": float(event.pop(\"temperature\")), \"unit\": \"C\"}\n        event.pop(\"voltage\")\n\n    print(\"Checking that events are valid...\")\n    events = [pyzenobase.ZenobaseEvent(event) for event in events]\n    print(\"Uploading...\")\n    zapi.create_events(bucket_id, events)\n    zapi.close()\n    print(\"Done!\")",
        "hard_negative_ids": [
            254,
            207,
            500,
            265,
            291,
            359,
            197,
            360,
            429,
            217,
            391,
            361,
            457,
            296,
            159,
            275,
            162,
            73,
            69,
            414,
            459,
            23,
            79,
            256,
            50,
            177,
            388,
            439,
            434,
            466,
            88,
            264,
            446,
            350,
            489,
            187,
            376,
            281,
            42,
            322,
            52,
            34,
            95,
            307,
            160,
            382,
            140,
            266,
            136,
            464
        ]
    },
    {
        "query": "Joins given arguments into a url, removing duplicate slashes\n    Thanks http://stackoverflow.com/a/11326230/1267398\n\n    >>> urljoin('/lol', '///lol', '/lol//')\n    '/lol/lol/lol'",
        "positive_code": "def urljoin(*args):\n    \n    value = \"/\".join(map(lambda x: str(x).strip(), args))\n    return \"/{}\".format(value)",
        "hard_negative_ids": [
            500,
            207,
            429,
            265,
            391,
            69,
            159,
            322,
            457,
            317,
            361,
            162,
            222,
            203,
            389,
            382,
            106,
            304,
            38,
            350,
            462,
            177,
            388,
            296,
            88,
            206,
            73,
            161,
            453,
            187,
            178,
            277,
            357,
            291,
            256,
            425,
            339,
            426,
            472,
            364,
            269,
            360,
            95,
            160,
            249,
            171,
            275,
            15,
            402,
            245
        ]
    },
    {
        "query": "Create an info-like tuple for feature given some shapes and vocab size.",
        "positive_code": "def _make_info(shape_list, num_classes):\n  \n  feature_info = collections.namedtuple(\"FeatureInfo\", [\"shape\", \"num_classes\"])\n  cur_shape = list(shape_list[0])\n  \n  for shape in shape_list:\n    if len(shape) != len(cur_shape):\n      raise ValueError(\"Shapes need to have the same number of dimensions.\")\n    for i in range(len(shape)):\n      if cur_shape[i] is not None:\n        if shape[i] != cur_shape[i]:\n          cur_shape[i] = None\n  return feature_info(cur_shape, num_classes)",
        "hard_negative_ids": [
            212,
            199,
            325,
            326,
            73,
            459,
            170,
            267,
            184,
            179,
            240,
            448,
            39,
            99,
            427,
            471,
            327,
            189,
            84,
            90,
            50,
            317,
            163,
            360,
            201,
            324,
            20,
            12,
            340,
            439,
            472,
            414,
            290,
            71,
            358,
            96,
            140,
            263,
            167,
            275,
            88,
            46,
            256,
            15,
            149,
            318,
            349,
            440,
            329,
            347
        ]
    },
    {
        "query": "The method can be used as a simple iterator computing and blocking\n            the hitting sets on the fly. It essentially calls :func:`get`\n            followed by :func:`block`. Each hitting set is reported as a list\n            of objects in the original problem domain, i.e. it is mapped back\n            from the solutions over Boolean variables computed by the\n            underlying oracle.\n\n            :rtype: list(obj)",
        "positive_code": "def enumerate(self):\n        \n\n        done = False\n        while not done:\n            hset = self.get()\n\n            if hset != None:\n                self.block(hset)\n                yield hset\n            else:\n                done = True",
        "hard_negative_ids": [
            291,
            360,
            453,
            29,
            112,
            217,
            337,
            69,
            287,
            425,
            470,
            373,
            133,
            297,
            383,
            119,
            254,
            466,
            414,
            186,
            79,
            197,
            323,
            305,
            23,
            76,
            42,
            59,
            317,
            324,
            118,
            179,
            255,
            25,
            97,
            232,
            320,
            382,
            73,
            402,
            304,
            61,
            462,
            349,
            106,
            429,
            109,
            182,
            44,
            149
        ]
    },
    {
        "query": "read a block of aligned words in memory. Returns\n        an array of word values",
        "positive_code": "def read_memory_block32(self, addr, size):\n        \n        data = self.ap.read_memory_block32(addr, size)\n        return self.bp_manager.filter_memory_aligned_32(addr, size, data)",
        "hard_negative_ids": [
            120,
            313,
            332,
            186,
            349,
            88,
            15,
            449,
            395,
            470,
            360,
            232,
            69,
            466,
            356,
            459,
            106,
            142,
            333,
            304,
            382,
            256,
            391,
            56,
            189,
            272,
            267,
            149,
            178,
            317,
            429,
            453,
            197,
            327,
            481,
            12,
            222,
            100,
            425,
            166,
            90,
            441,
            479,
            318,
            299,
            192,
            424,
            171,
            81,
            157
        ]
    },
    {
        "query": "Returns the appropriate StaticMask array for the image.",
        "positive_code": "def getMaskArray(self, signature):\n        \n        if signature in self.masklist:\n            mask =  self.masklist[signature]\n        else:\n            mask = None\n        return mask",
        "hard_negative_ids": [
            12,
            88,
            276,
            286,
            360,
            414,
            264,
            197,
            291,
            466,
            136,
            73,
            429,
            100,
            44,
            23,
            299,
            25,
            81,
            256,
            192,
            109,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            247,
            29,
            317,
            305,
            205,
            61,
            500,
            267,
            133,
            53,
            65,
            232,
            190,
            384,
            476,
            145,
            443,
            4,
            344
        ]
    },
    {
        "query": "Given a total and a progress position, output a progress bar\n    to stderr. It is important to not output anything else while\n    using this, as it relies soley on the behavior of carriage\n    return (\\\\r).\n\n    Can also take an optioal message to add after the\n    progressbar. It must not contain newlines.\n\n    The progress bar will look something like this:\n\n    [099/500][=========...............................] ETA: 13:36:59\n\n    Of course, the ETA part should be supplied be the calling\n    function.",
        "positive_code": "def progressbar(total, pos, msg=\"\"):\n    \n    width = get_terminal_size()[0] - 40\n    rel_pos = int(float(pos) / total * width)\n    bar = .join([\"=\" * rel_pos, \".\" * (width - rel_pos)])\n\n    \n    digits_total = len(str(total))\n    fmt_width = \"%0\" + str(digits_total) + \"d\"\n    fmt = \"\\r[\" + fmt_width + \"/\" + fmt_width + \"][%s] %s\"\n\n    progress_stream.write(fmt % (pos, total, bar, msg))",
        "hard_negative_ids": [
            360,
            232,
            73,
            386,
            429,
            291,
            470,
            466,
            414,
            252,
            136,
            69,
            328,
            189,
            382,
            327,
            47,
            462,
            264,
            166,
            349,
            125,
            376,
            197,
            301,
            488,
            42,
            109,
            192,
            171,
            275,
            99,
            23,
            453,
            262,
            255,
            391,
            20,
            269,
            159,
            97,
            179,
            34,
            295,
            182,
            240,
            345,
            37,
            181,
            304
        ]
    },
    {
        "query": "This is a \"factory\" procedure that creates a new canvas.T object.\n    Both parameters, <fname> and\n    <format>, are optional. Parameter <fname> specifies either the output\n    file name or a file object. Parameter <format>, if specified, defines the\n    file's format. Its value must be one of \"ps\", \"pdf\", \"svg\", \"x11\", or\n    \"png\".\n\n    When <fname> is omitted or is None, the output is sent to standard\n    output. When <format> is omitted, it is guessed from the <fname>'s\n    suffix; failing that, \"ps\" is selected.",
        "positive_code": "def init(fname=None, format=None):\n    \n\n    fname = fname or theme.output_file\n    format = format or theme.output_format\n\n    if format == None:\n        if not isinstance(fname, str):\n            format = \"ps\"\n        elif re.search(\"pdf$\", fname):\n            format = \"pdf\"\n        elif re.search(\"png$\", fname):\n            format = \"png\"\n        elif re.search(\"svg$\", fname):\n            format = \"svg\"\n        else:\n            format = \"ps\"\n\n    if format == \"ps\":\n        can = pscanvas.T(fname)\n    elif format == \"png\":\n        can = pngcanvas.T(fname)\n    elif format == \"x11\":\n        can = x11canvas.T(fname)\n    elif format == \"svg\":\n        can = svgcanvas.T(fname)\n    elif format == \"pdf-uncompressed\":\n        can = pdfcanvas.T(fname, False)\n    else:\n        can = pdfcanvas.T(fname, theme.compress_output)\n    return can",
        "hard_negative_ids": [
            360,
            232,
            429,
            159,
            73,
            470,
            386,
            197,
            291,
            136,
            376,
            466,
            475,
            257,
            252,
            171,
            280,
            382,
            275,
            349,
            23,
            15,
            79,
            81,
            56,
            82,
            414,
            295,
            460,
            462,
            318,
            485,
            182,
            14,
            366,
            326,
            297,
            19,
            242,
            237,
            165,
            391,
            69,
            375,
            149,
            435,
            99,
            425,
            254,
            227
        ]
    },
    {
        "query": "duration : duration IN DURATION_UNIT",
        "positive_code": "def p_duration_conversion(self, p):\n        \n        logger.debug(, p[1], p[3])\n        p[0] = .format(p[1], p[3])",
        "hard_negative_ids": [
            305,
            135,
            321,
            215,
            209,
            489,
            35,
            363,
            234,
            155,
            387,
            223,
            377,
            345,
            104,
            29,
            36,
            247,
            4,
            317,
            205,
            61,
            500,
            65,
            267,
            133,
            53,
            424,
            455,
            384,
            413,
            344,
            476,
            190,
            142,
            258,
            443,
            332,
            149,
            145,
            103,
            311,
            222,
            291,
            122,
            246,
            411,
            225,
            5,
            283
        ]
    },
    {
        "query": "Returns code for parameter variable declarations specifying the size of each\n    dimension in the specified parameter.",
        "positive_code": "def _ctypes_indices(parameter):\n    \n    if (parameter.dimension is not None and \":\" in parameter.dimension):\n        splice = _ctypes_splice(parameter)\n        if \"out\" in parameter.direction:\n            \n            \n            return (\"integer, intent(inout) :: {}\".format(splice), False)\n        else:\n            return (\"integer, intent(in) :: {}\".format(splice), False)",
        "hard_negative_ids": [
            373,
            287,
            324,
            339,
            466,
            197,
            179,
            73,
            360,
            318,
            429,
            414,
            291,
            471,
            327,
            300,
            136,
            69,
            349,
            232,
            448,
            326,
            395,
            470,
            44,
            23,
            25,
            163,
            307,
            138,
            157,
            272,
            109,
            135,
            305,
            321,
            489,
            35,
            363,
            234,
            223,
            377,
            247,
            29,
            317,
            205,
            209,
            61,
            215,
            142
        ]
    },
    {
        "query": "float_precision changed, set float_format accordingly.\n\n        float_precision can be set by int or str.\n        This will set float_format, after interpreting input.\n        If numpy has been imported, numpy print precision will also be set.\n\n        integer `n` sets format to '%.nf', otherwise, format set directly.\n\n        An empty string returns to defaults (repr for float, 8 for numpy).\n\n        This parameter can be set via the '%precision' magic.",
        "positive_code": "def _float_precision_changed(self, name, old, new):\n        \n\n        if  in new:\n            \n            fmt = new\n            try:\n                fmt%3.14159\n            except Exception:\n                raise ValueError(\"Precision must be int or format string, not %r\"%new)\n        elif new:\n            \n            try:\n                i = int(new)\n                assert i >= 0\n            except ValueError:\n                raise ValueError(\"Precision must be int or format string, not %r\"%new)\n            except AssertionError:\n                raise ValueError(\"int precision must be non-negative, not %r\"%i)\n\n            fmt = %i\n            if  in sys.modules:\n                \n                import numpy\n                numpy.set_printoptions(precision=i)\n        else:\n            \n            fmt = \n            if  in sys.modules:\n                import numpy\n                \n                numpy.set_printoptions(precision=8)\n        self.float_format = fmt",
        "hard_negative_ids": [
            366,
            97,
            76,
            135,
            462,
            291,
            386,
            271,
            414,
            255,
            90,
            23,
            40,
            239,
            189,
            73,
            210,
            413,
            412,
            232,
            360,
            171,
            25,
            342,
            466,
            56,
            211,
            53,
            109,
            496,
            47,
            490,
            328,
            275,
            424,
            376,
            182,
            44,
            315,
            254,
            11,
            168,
            229,
            381,
            84,
            99,
            160,
            306,
            269,
            478
        ]
    },
    {
        "query": "Increments counter by given value.\n\n        :param name: a counter name of Increment type.\n\n        :param value: a value to add to the counter.",
        "positive_code": "def increment(self, name, value):\n        \n        for counter in self._counters:\n            counter.increment(name, value)",
        "hard_negative_ids": [
            24,
            232,
            349,
            56,
            366,
            498,
            73,
            360,
            291,
            81,
            91,
            332,
            382,
            267,
            466,
            453,
            481,
            272,
            280,
            166,
            441,
            391,
            15,
            394,
            176,
            171,
            222,
            76,
            204,
            199,
            362,
            11,
            414,
            424,
            182,
            106,
            178,
            19,
            242,
            470,
            344,
            197,
            304,
            215,
            429,
            300,
            127,
            65,
            142,
            353
        ]
    },
    {
        "query": "Set the focus node(s).  If no focus node is specified, the evaluation will occur for all non-BNode\n        graph subjects.  Otherwise it can be a string, a URIRef or a list of string/URIRef combinations\n\n        :param focus: None if focus should be all URIRefs in the graph otherwise a URI or list of URI's",
        "positive_code": "def focus(self, focus: Optional[URIPARM]) -> None:\n        \n        self._focus = normalize_uriparm(focus) if focus else None",
        "hard_negative_ids": [
            210,
            255,
            277,
            413,
            291,
            197,
            462,
            40,
            466,
            77,
            73,
            305,
            232,
            235,
            342,
            215,
            386,
            391,
            470,
            174,
            272,
            18,
            360,
            76,
            429,
            366,
            25,
            81,
            349,
            126,
            97,
            382,
            23,
            201,
            109,
            304,
            182,
            15,
            311,
            425,
            496,
            106,
            379,
            318,
            192,
            317,
            178,
            414,
            477,
            344
        ]
    },
    {
        "query": "All resulting versions of all plugins in the group filtered by ``blacklist``\n\n        Returns:\n            dict: Nested dictionary of plugins accessible through dot-notation.\n\n        Similar to :py:attr:`plugins`, but lowest level is a regular dictionary of\n        all unfiltered plugin versions for the given plugin type and name.\n\n        Parent types are always included.\n        Child plugins will only be included if at least one valid, non-blacklisted plugin\n        is available.",
        "positive_code": "def plugins_all(self):\n        \n\n        if not self.loaded:\n            self.load_modules()\n\n        \n        return get_plugins()[self.group]._filter(blacklist=self.blacklist,\n                                                 type_filter=self.type_filter)",
        "hard_negative_ids": [
            349,
            438,
            232,
            295,
            178,
            466,
            150,
            73,
            291,
            360,
            429,
            382,
            308,
            76,
            340,
            36,
            253,
            388,
            412,
            47,
            32,
            386,
            470,
            54,
            197,
            414,
            15,
            23,
            424,
            26,
            136,
            25,
            157,
            69,
            500,
            222,
            99,
            286,
            345,
            84,
            204,
            49,
            338,
            318,
            272,
            498,
            85,
            274,
            2,
            201
        ]
    },
    {
        "query": "Executes the request.\n\n    Returns:\n       An array of tuples representing the metric evaluations--each of the form\n       (<wall time in secs>, <training step>, <metric value>).",
        "positive_code": "def run(self):\n    \n    run, tag = metrics.run_tag_from_session_and_metric(\n        self._request.session_name, self._request.metric_name)\n    body, _ = self._scalars_plugin_instance.scalars_impl(\n        tag, run, None, scalars_plugin.OutputFormat.JSON)\n    return body",
        "hard_negative_ids": [
            429,
            492,
            415,
            260,
            159,
            197,
            287,
            122,
            56,
            466,
            202,
            349,
            360,
            25,
            139,
            491,
            414,
            475,
            485,
            285,
            88,
            245,
            232,
            17,
            291,
            252,
            73,
            490,
            222,
            162,
            267,
            332,
            24,
            129,
            268,
            206,
            131,
            182,
            481,
            149,
            402,
            430,
            166,
            12,
            395,
            441,
            142,
            81,
            154,
            136
        ]
    },
    {
        "query": "Connects to Youtube Api and retrieves the video entry object\n\n        Return:\n            gdata.youtube.YouTubeVideoEntry",
        "positive_code": "def entry(self):\n        \n        api = Api()\n        api.authenticate()\n        return api.fetch_video(self.video_id)",
        "hard_negative_ids": [
            126,
            246,
            79,
            137,
            429,
            360,
            414,
            68,
            207,
            73,
            470,
            297,
            466,
            291,
            197,
            113,
            131,
            81,
            427,
            295,
            136,
            171,
            275,
            269,
            25,
            44,
            368,
            376,
            189,
            264,
            23,
            109,
            24,
            76,
            485,
            47,
            345,
            184,
            219,
            46,
            257,
            477,
            94,
            21,
            266,
            118,
            473,
            201,
            149,
            349
        ]
    },
    {
        "query": "A custom save that publishes or unpublishes the object where\n        appropriate.\n\n        Save with keyword argument obj.save(publish=False) to skip the process.",
        "positive_code": "def save(self, *args, **kwargs):\n        \n        from bakery import tasks\n        from django.contrib.contenttypes.models import ContentType\n        \n        if not kwargs.pop(, True):\n            super(AutoPublishingBuildableModel, self).save(*args, **kwargs)\n        \n        else:\n            \n            \n            try:\n                preexisting = self.__class__.objects.get(pk=self.pk)\n            except self.__class__.DoesNotExist:\n                preexisting = None\n            \n            if not preexisting:\n                \n                if not self.get_publication_status() and \\\n                        preexisting.get_publication_status():\n                    action = \n                \n                else:\n                    action = None\n            \n            \n            \n            with transaction.atomic():\n                super(AutoPublishingBuildableModel, self).save(*args, **kwargs)\n            \n            ct = ContentType.objects.get_for_model(self.__class__)\n            if action == :\n                tasks.publish_object.delay(ct.pk, self.pk)\n            elif action == :\n                tasks.unpublish_object.delay(ct.pk, self.pk)",
        "hard_negative_ids": [
            360,
            10,
            133,
            487,
            79,
            59,
            452,
            305,
            390,
            118,
            76,
            414,
            467,
            409,
            466,
            429,
            291,
            73,
            391,
            470,
            383,
            197,
            130,
            237,
            136,
            273,
            260,
            171,
            163,
            425,
            256,
            269,
            450,
            333,
            106,
            297,
            304,
            277,
            113,
            275,
            23,
            29,
            90,
            179,
            453,
            81,
            295,
            178,
            44,
            317
        ]
    },
    {
        "query": "Retrieve and update the application configuration with information from the user-data\n\n    Returns:\n        `None`",
        "positive_code": "def get_user_data_configuration():\n    \n    from cloud_inquisitor import get_local_aws_session, app_config\n\n    kms_region = app_config.kms_region\n    session = get_local_aws_session()\n\n    if session.get_credentials().method == :\n        kms = session.client(, region_name=kms_region)\n    else:\n        sts = session.client()\n        audit_role = sts.assume_role(RoleArn=app_config.aws_api.instance_role_arn, RoleSessionName=)\n        kms = boto3.session.Session(\n            audit_role[][],\n            audit_role[][],\n            audit_role[][],\n        ).client(, region_name=kms_region)\n\n    user_data_url = app_config.user_data_url\n    res = requests.get(user_data_url)\n\n    if res.status_code == 200:\n        data = kms.decrypt(CiphertextBlob=b64decode(res.content))\n        kms_config = json.loads(zlib.decompress(data[]).decode())\n\n        app_config.database_uri = kms_config[]\n    else:\n        raise RuntimeError(.format(res.status_code, res.content))",
        "hard_negative_ids": [
            85,
            466,
            421,
            131,
            187,
            414,
            55,
            382,
            291,
            425,
            223,
            360,
            415,
            197,
            73,
            67,
            424,
            103,
            283,
            498,
            357,
            295,
            33,
            195,
            440,
            351,
            412,
            492,
            393,
            154,
            324,
            193,
            7,
            136,
            163,
            252,
            186,
            45,
            429,
            476,
            25,
            173,
            484,
            402,
            404,
            256,
            26,
            76,
            44,
            78
        ]
    },
    {
        "query": "Given field_key will return value held at self.model_instance.  If\n        model_instance has not been provided will return None.",
        "positive_code": "def get_field_value(self, field_key):\n        \n\n        def get_value(document, field_key):\n            \n            if document is None:\n                return None\n\n            current_key, new_key_array = trim_field_key(document, field_key)\n            key_array_digit = int(new_key_array[-1]) if new_key_array and has_digit(new_key_array) else None\n            new_key = make_key(new_key_array)\n\n            if key_array_digit is not None and len(new_key_array) > 0:\n                \n                if len(new_key_array) == 1:\n                    return_data = document._data.get(current_key, [])\n                elif isinstance(document, BaseList):\n                    return_list = []\n                    if len(document) > 0:\n                        return_list = [get_value(doc, new_key) for doc in document]\n                    return_data = return_list\n                else:\n                    return_data = get_value(getattr(document, current_key), new_key)\n\n            elif len(new_key_array) > 0:\n                return_data = get_value(document._data.get(current_key), new_key)\n            else:\n                \n                try: \n                    return_data = (document._data.get(None, None) if current_key == \"id\" else\n                              document._data.get(current_key, None))\n                except: \n                    return_data = document._data.get(current_key, None)\n\n            return return_data\n\n        if self.is_initialized:\n            return get_value(self.model_instance, field_key)\n        else:\n            return None",
        "hard_negative_ids": [
            349,
            56,
            481,
            267,
            73,
            332,
            166,
            441,
            382,
            295,
            91,
            362,
            424,
            366,
            268,
            11,
            19,
            242,
            199,
            232,
            222,
            228,
            182,
            280,
            99,
            165,
            142,
            15,
            253,
            375,
            423,
            311,
            414,
            103,
            448,
            192,
            157,
            121,
            272,
            195,
            212,
            224,
            384,
            127,
            128,
            435,
            460,
            243,
            388,
            46
        ]
    },
    {
        "query": "Grabs filename and enables it to be read.\n        :return: raw_file = unaltered text; file_lines = text split by lines.",
        "positive_code": "def read_file(self):\n        \n        with open(self.filename, mode=, encoding=) as text_file:\n            self.raw_file = text_file.read()  \n        self.file_lines = [x.rstrip() for x in self.raw_file.splitlines()]",
        "hard_negative_ids": [
            38,
            291,
            373,
            437,
            386,
            169,
            364,
            433,
            117,
            62,
            464,
            449,
            327,
            186,
            452,
            425,
            341,
            349,
            69,
            171,
            329,
            252,
            232,
            459,
            356,
            275,
            407,
            148,
            52,
            94,
            319,
            131,
            413,
            371,
            375,
            4,
            283,
            359,
            462,
            149,
            295,
            78,
            40,
            272,
            438,
            470,
            206,
            227,
            109,
            479
        ]
    },
    {
        "query": "For a given specific window, i.e. an element of :attr:`windows`, get the windows of all resolutions.\n\n        Arguments:\n            ij_win {int} -- The index specifying the window for which to return the resolution-windows.",
        "positive_code": "def ji_windows(self, ij_win):  \n        \n        ji_windows = {}\n        transform_src = self._layer_meta[self._res_indices[self._windows_res][0]][\"transform\"]\n        for res in self._res_indices:\n            transform_dst = self._layer_meta[self._res_indices[res][0]][\"transform\"]\n            ji_windows[res] = window_from_window(window_src=self.windows[ij_win],\n                                                 transform_src=transform_src,\n                                                 transform_dst=transform_dst)\n        return ji_windows",
        "hard_negative_ids": [
            327,
            73,
            360,
            466,
            414,
            79,
            433,
            15,
            461,
            197,
            348,
            146,
            272,
            493,
            230,
            317,
            349,
            84,
            429,
            245,
            204,
            76,
            274,
            347,
            295,
            320,
            470,
            462,
            326,
            490,
            269,
            291,
            135,
            189,
            307,
            25,
            279,
            391,
            88,
            427,
            149,
            109,
            53,
            171,
            227,
            421,
            233,
            232,
            61,
            157
        ]
    },
    {
        "query": "Setter method for log_bad_packet, mapped from YANG variable /rbridge_id/ipv6/router/ospf/log/log_bad_packet (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_log_bad_packet is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_log_bad_packet() directly.\n\n    YANG Description: Configure logging for bad packets",
        "positive_code": "def _set_log_bad_packet(self, v, load=False):\n    \n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=log_bad_packet.log_bad_packet, is_container=, presence=True, yang_name=\"log-bad-packet\", rest_name=\"bad-packet\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u: {u: u, u: u}}, namespace=, defining_module=, yang_type=, is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          : ,\n          : \"container\",\n          : ,\n        })\n\n    self.__log_bad_packet = t\n    if hasattr(self, ):\n      self._set()",
        "hard_negative_ids": [
            373,
            324,
            323,
            189,
            275,
            130,
            391,
            414,
            69,
            409,
            50,
            171,
            429,
            454,
            41,
            178,
            425,
            369,
            361,
            76,
            360,
            207,
            291,
            197,
            73,
            500,
            462,
            466,
            405,
            402,
            44,
            70,
            457,
            376,
            296,
            228,
            317,
            139,
            99,
            422,
            264,
            488,
            304,
            449,
            47,
            265,
            192,
            117,
            363,
            427
        ]
    },
    {
        "query": "Sort rows in this table, preserving a record of how that\n        sorting is done in TableFu.options['sorted_by']",
        "positive_code": "def sort(self, column_name=None, reverse=False):\n        \n        if not column_name and self.options.has_key():\n            column_name = self.options[].keys()[0]\n        if column_name not in self.default_columns:\n            raise ValueError(\"%s isnsorted_byreverse': reverse}}",
        "hard_negative_ids": [
            130,
            142,
            103,
            450,
            312,
            97,
            329,
            360,
            354,
            244,
            384,
            90,
            182,
            385,
            291,
            349,
            303,
            470,
            304,
            106,
            33,
            239,
            64,
            466,
            181,
            62,
            391,
            232,
            137,
            113,
            47,
            189,
            105,
            425,
            317,
            395,
            178,
            156,
            453,
            171,
            197,
            15,
            183,
            424,
            429,
            23,
            222,
            272,
            318,
            365
        ]
    },
    {
        "query": "Creates a parser with arguments specific to sending HTTP requests\n    to multiple REST APIs.\n\n    Returns:\n        {ArgumentParser}: Base parser with default HTTP args",
        "positive_code": "def base_multinode_parser():\n    \n    base_parser = ArgumentParser(add_help=False)\n\n    base_parser.add_argument(\n        ,\n        type=str,\n        nargs=,\n        help=\"The URLs of the validator--usersappendUSERNAME[:PASSWORD]Specify the users to authorize requests, in the same order as the URLs, separate by commas. Passing empty strings between commas is supported.')\n\n    return base_parser",
        "hard_negative_ids": [
            269,
            203,
            168,
            359,
            352,
            169,
            407,
            40,
            424,
            405,
            306,
            84,
            287,
            322,
            379,
            488,
            41,
            76,
            131,
            500,
            70,
            171,
            391,
            369,
            219,
            185,
            147,
            139,
            491,
            360,
            112,
            179,
            385,
            277,
            425,
            198,
            106,
            316,
            324,
            304,
            264,
            414,
            487,
            159,
            170,
            222,
            275,
            466,
            453,
            96
        ]
    },
    {
        "query": "NAME:\n           Tphi\n        PURPOSE:\n           Calculate the azimuthal period\n        INPUT:\n           +scipy.integrate.quadrature keywords\n        OUTPUT:\n           T_phi(R,vT,vT)/ro/vc + estimate of the error\n        HISTORY:\n           2010-12-01 - Written - Bovy (NYU)",
        "positive_code": "def Tphi(self,**kwargs): \n        \n        if hasattr(self,):\n            return self._Tphi\n        (rperi,rap)= self.calcRapRperi(**kwargs)\n        if rap == rperi:\n            return 2.*m.pi*self._R/self._vT\n        TR= self.TR(**kwargs)\n        I= self.I(**kwargs)\n        Tphi= TR/I*m.pi\n        self._Tphi= Tphi\n        return self._Tphi",
        "hard_negative_ids": [
            429,
            414,
            345,
            496,
            136,
            197,
            466,
            391,
            179,
            34,
            498,
            360,
            260,
            252,
            227,
            296,
            77,
            73,
            500,
            162,
            291,
            361,
            207,
            349,
            159,
            32,
            376,
            66,
            149,
            44,
            457,
            9,
            176,
            88,
            265,
            218,
            95,
            386,
            426,
            275,
            472,
            464,
            412,
            177,
            230,
            69,
            185,
            181,
            427,
            64
        ]
    },
    {
        "query": "Create an empty dataset in the current repo.",
        "positive_code": "def create(client, name):\n    \n    from renku.models.datasets import Author\n\n    with client.with_dataset(name=name) as dataset:\n        click.echo(, nl=False)\n        author = Author.from_git(client.repo)\n        if author not in dataset.authors:\n            dataset.authors.append(author)\n\n    click.secho(, fg=)",
        "hard_negative_ids": [
            458,
            325,
            466,
            343,
            459,
            360,
            51,
            170,
            414,
            44,
            424,
            285,
            39,
            73,
            97,
            189,
            291,
            381,
            197,
            327,
            136,
            427,
            329,
            429,
            23,
            99,
            25,
            109,
            305,
            135,
            321,
            215,
            209,
            489,
            35,
            363,
            234,
            155,
            387,
            223,
            377,
            345,
            104,
            29,
            36,
            247,
            4,
            317,
            205,
            61
        ]
    },
    {
        "query": "Convert fileattr metadata in json metadata\n    :param dict md: metadata dictionary\n    :rtype: PosixFileAttr or WindowsFileAttr or None\n    :return: fileattr metadata",
        "positive_code": "def fileattr_from_metadata(md):\n    \n    \n    try:\n        mdattr = json.loads(\n            md[JSON_KEY_BLOBXFER_METADATA])[_JSON_KEY_FILE_ATTRIBUTES]\n    except (KeyError, TypeError):\n        return None\n    else:\n        if blobxfer.util.on_windows():\n            global _FILEATTR_WARNED_ON_WINDOWS\n            if not _FILEATTR_WARNED_ON_WINDOWS:\n                _FILEATTR_WARNED_ON_WINDOWS = True\n                logger.warning(\n                    \n                    )\n            fileattr = None\n        else:\n            try:\n                fileattr = PosixFileAttr(\n                    mode=mdattr[_JSON_KEY_FILE_ATTRIBUTES_POSIX][\n                        _JSON_KEY_FILE_ATTRIBUTES_MODE],\n                    uid=mdattr[_JSON_KEY_FILE_ATTRIBUTES_POSIX][\n                        _JSON_KEY_FILE_ATTRIBUTES_UID],\n                    gid=mdattr[_JSON_KEY_FILE_ATTRIBUTES_POSIX][\n                        _JSON_KEY_FILE_ATTRIBUTES_GID],\n                )\n            except KeyError:\n                fileattr = None\n        return fileattr",
        "hard_negative_ids": [
            500,
            308,
            428,
            178,
            81,
            382,
            265,
            2,
            204,
            344,
            300,
            434,
            52,
            127,
            489,
            345,
            275,
            377,
            270,
            5,
            484,
            425,
            72,
            141,
            463,
            326,
            215,
            235,
            179,
            376,
            112,
            240,
            387,
            182,
            207,
            283,
            188,
            230,
            191,
            11,
            331,
            306,
            429,
            443,
            211,
            260,
            184,
            181,
            414,
            136
        ]
    },
    {
        "query": "Sets the target root count in the run tracker's daemon stats object.",
        "positive_code": "def _set_target_root_count_in_runtracker(self):\n    \n    \n    \n    target_count = len(self._target_roots)\n    self.run_tracker.pantsd_stats.set_target_root_size(target_count)\n    return target_count",
        "hard_negative_ids": [
            134,
            363,
            322,
            6,
            79,
            252,
            197,
            43,
            109,
            360,
            294,
            414,
            218,
            291,
            87,
            451,
            386,
            201,
            466,
            297,
            470,
            73,
            25,
            370,
            181,
            216,
            361,
            44,
            136,
            90,
            149,
            329,
            236,
            366,
            113,
            23,
            77,
            429,
            477,
            438,
            81,
            289,
            105,
            12,
            407,
            9,
            15,
            326,
            375,
            173
        ]
    },
    {
        "query": "Instance depends on the API version:\n\n           * 2015-06-15: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2015_06_15.operations.ApplicationGatewaysOperations>`\n           * 2016-09-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2016_09_01.operations.ApplicationGatewaysOperations>`\n           * 2016-12-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2016_12_01.operations.ApplicationGatewaysOperations>`\n           * 2017-03-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2017_03_01.operations.ApplicationGatewaysOperations>`\n           * 2017-06-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2017_06_01.operations.ApplicationGatewaysOperations>`\n           * 2017-08-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2017_08_01.operations.ApplicationGatewaysOperations>`\n           * 2017-09-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2017_09_01.operations.ApplicationGatewaysOperations>`\n           * 2017-10-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2017_10_01.operations.ApplicationGatewaysOperations>`\n           * 2017-11-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2017_11_01.operations.ApplicationGatewaysOperations>`\n           * 2018-01-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2018_01_01.operations.ApplicationGatewaysOperations>`\n           * 2018-02-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2018_02_01.operations.ApplicationGatewaysOperations>`\n           * 2018-04-01: :class:`ApplicationGatewaysOperations<azure.mgmt.network.v2018_04_01.operations.ApplicationGatewaysOperations>`",
        "positive_code": "def application_gateways(self):\n        \n        api_version = self._get_api_version()\n        if api_version == :\n            from .v2015_06_15.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2016_09_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2016_12_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2017_03_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2017_06_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2017_08_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2017_09_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2017_10_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2017_11_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2018_01_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2018_02_01.operations import ApplicationGatewaysOperations as OperationClass\n        elif api_version == :\n            from .v2018_04_01.operations import ApplicationGatewaysOperations as OperationClass\n        else:\n            raise NotImplementedError(\"APIVersion {} is not available\".format(api_version))\n        return OperationClass(self._client, self.config, Serializer(self._models_dict(api_version)), Deserializer(self._models_dict(api_version)))",
        "hard_negative_ids": [
            29,
            429,
            159,
            469,
            17,
            293,
            269,
            414,
            475,
            245,
            485,
            466,
            64,
            297,
            252,
            76,
            256,
            162,
            412,
            268,
            197,
            374,
            277,
            56,
            206,
            149,
            96,
            73,
            430,
            207,
            287,
            16,
            95,
            53,
            379,
            488,
            219,
            154,
            460,
            350,
            60,
            240,
            404,
            347,
            435,
            123,
            1,
            472,
            77,
            156
        ]
    },
    {
        "query": "Aggregate a composite array and compute the totals on a given key.\n\n    >>> dt = numpy.dtype([('name', (bytes, 10)), ('value', int)])\n    >>> tbl = numpy.array([('a', 1), ('a', 2), ('b', 3)], dt)\n    >>> sum_tbl(tbl, 'name', ['value'])['value']\n    array([3, 3])",
        "positive_code": "def sum_tbl(tbl, kfield, vfields):\n    \n    pairs = [(n, tbl.dtype[n]) for n in [kfield] + vfields]\n    dt = numpy.dtype(pairs + [(, int)])\n\n    def sum_all(group):\n        vals = numpy.zeros(1, dt)[0]\n        for rec in group:\n            for vfield in vfields:\n                vals[vfield] += rec[vfield]\n            vals[] += 1\n        vals[kfield] = rec[kfield]\n        return vals\n    rows = groupby(tbl, operator.itemgetter(kfield), sum_all).values()\n    array = numpy.zeros(len(rows), dt)\n    for i, row in enumerate(rows):\n        for j, name in enumerate(dt.names):\n            array[i][name] = row[j]\n    return array",
        "hard_negative_ids": [
            48,
            77,
            391,
            15,
            106,
            56,
            256,
            88,
            182,
            149,
            382,
            252,
            366,
            271,
            498,
            58,
            349,
            294,
            60,
            11,
            91,
            240,
            196,
            19,
            242,
            239,
            386,
            332,
            360,
            267,
            481,
            342,
            222,
            324,
            81,
            166,
            198,
            159,
            105,
            441,
            73,
            414,
            179,
            304,
            57,
            176,
            424,
            45,
            412,
            142
        ]
    },
    {
        "query": "Compute clustering and transform a list of bag features into its\n        bag-of-words representation. Like calling fit(X) and then transform(X),\n        but more efficient.\n\n        Parameters\n        ----------\n        X : :class:`skl_groups.features.Features` or list of bag feature arrays\n            New data to transform.\n\n        Returns\n        -------\n        X_new : integer array, shape [len(X), kmeans.n_clusters]\n            X transformed into the new space.",
        "positive_code": "def fit_transform(self, X):\n        \n        X = as_features(X, stack=True)\n        self.kmeans_fit_ = copy(self.kmeans)\n        assignments = self.kmeans_fit_.fit_predict(X.stacked_features) \n        return self._group_assignments(X, assignments)",
        "hard_negative_ids": [
            212,
            199,
            240,
            440,
            82,
            152,
            349,
            263,
            318,
            88,
            76,
            466,
            360,
            256,
            313,
            267,
            462,
            149,
            25,
            3,
            58,
            245,
            120,
            49,
            23,
            317,
            12,
            46,
            472,
            499,
            490,
            185,
            391,
            77,
            430,
            421,
            290,
            186,
            69,
            197,
            470,
            157,
            495,
            414,
            429,
            178,
            424,
            81,
            333,
            100
        ]
    },
    {
        "query": "Merges data from the two strands into strand-agnostic counts.",
        "positive_code": "def merge_chromosome_dfs(df_tuple):\n    \n    \n\n    plus_df, minus_df = df_tuple\n    index_cols = \"Chromosome Bin\".split()\n    count_column = plus_df.columns[0]\n\n    if plus_df.empty:\n        return return_other(minus_df, count_column, index_cols)\n    if minus_df.empty:\n        return return_other(plus_df, count_column, index_cols)\n\n    \n    \n    plus_df = plus_df.groupby(index_cols).sum()\n    minus_df = minus_df.groupby(index_cols).sum()\n\n    \n    df = pd.concat([plus_df, minus_df], axis=1).fillna(0).sum(axis=1)\n    df = df.reset_index().sort_values(by=\"Bin\")\n\n    df.columns = [\"Chromosome\", \"Bin\", count_column]\n\n    df = df.sort_values([\"Chromosome\", \"Bin\"])\n    df[[\"Bin\", count_column]] = df[[\"Bin\", count_column]].astype(int32)\n    df = df[[count_column, \"Chromosome\", \"Bin\"]]\n    return df.reset_index(drop=True)",
        "hard_negative_ids": [
            421,
            223,
            498,
            252,
            466,
            33,
            195,
            440,
            414,
            357,
            85,
            424,
            73,
            393,
            154,
            360,
            43,
            283,
            197,
            361,
            193,
            492,
            291,
            324,
            484,
            294,
            7,
            256,
            26,
            78,
            67,
            69,
            367,
            131,
            136,
            11,
            163,
            429,
            22,
            141,
            149,
            153,
            25,
            44,
            185,
            12,
            101,
            383,
            147,
            100
        ]
    },
    {
        "query": "Parse 10-Q or 10-K XML report.",
        "positive_code": "def parse_10qk(self, response):\n        \n        loader = ReportItemLoader(response=response)\n        item = loader.load_item()\n\n        if  in item:\n            doc_type = item[]\n            if doc_type in (, ):\n                return item\n\n        return None",
        "hard_negative_ids": [
            160,
            107,
            339,
            190,
            133,
            480,
            287,
            97,
            34,
            472,
            350,
            4,
            304,
            230,
            377,
            37,
            149,
            92,
            461,
            178,
            411,
            90,
            58,
            240,
            252,
            182,
            293,
            324,
            311,
            414,
            391,
            300,
            152,
            183,
            319,
            349,
            105,
            462,
            326,
            162,
            95,
            347,
            268,
            141,
            425,
            127,
            270,
            435,
            1,
            245
        ]
    },
    {
        "query": "shut down the pool's workers\n\n        this method sets the :attr:`closing` attribute, and once all queued\n        work has been completed it will set the :attr:`closed` attribute",
        "positive_code": "def close(self):\n        \n        self._closing = True\n        for i in xrange(self.size):\n            self.inq.put(_STOP)",
        "hard_negative_ids": [
            91,
            15,
            323,
            84,
            204,
            128,
            90,
            274,
            25,
            197,
            13,
            414,
            490,
            66,
            44,
            41,
            360,
            458,
            291,
            272,
            201,
            70,
            375,
            139,
            466,
            47,
            410,
            23,
            73,
            402,
            76,
            386,
            109,
            136,
            434,
            85,
            116,
            477,
            69,
            149,
            295,
            275,
            184,
            268,
            189,
            429,
            179,
            326,
            11,
            97
        ]
    },
    {
        "query": "Do something with all startup nodes and filters out any duplicates",
        "positive_code": "def populate_startup_nodes(self):\n        \n        for item in self.startup_nodes:\n            self.set_node_name(item)\n\n        for n in self.nodes.values():\n            if n not in self.startup_nodes:\n                self.startup_nodes.append(n)\n\n        \n        uniq = {frozenset(node.items()) for node in self.startup_nodes}\n        \n        self.startup_nodes = [dict(node) for node in uniq]",
        "hard_negative_ids": [
            269,
            174,
            404,
            283,
            435,
            201,
            189,
            163,
            439,
            246,
            305,
            131,
            126,
            85,
            116,
            215,
            464,
            295,
            18,
            76,
            311,
            474,
            379,
            109,
            393,
            212,
            266,
            366,
            142,
            107,
            170,
            235,
            237,
            88,
            414,
            388,
            96,
            25,
            47,
            179,
            434,
            74,
            31,
            59,
            272,
            149,
            468,
            291,
            397,
            383
        ]
    },
    {
        "query": "J'.G",
        "positive_code": "def gradient(x, a, c):\n    \n    return jac(x, a).T.dot(g(x, a, c))",
        "hard_negative_ids": [
            18,
            79,
            462,
            160,
            88,
            149,
            4,
            58,
            99,
            12,
            293,
            472,
            300,
            105,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453
        ]
    },
    {
        "query": "Get an Entity",
        "positive_code": "def e(self, eid):\n    \n    ta = datetime.datetime.now()\n    rs = self.rest(, self.uri_db + , data={:int(eid)}, parse=True)\n    tb =  datetime.datetime.now() - ta\n    print cl( % (eid, tb.microseconds/1000.0), )\n    return rs",
        "hard_negative_ids": [
            209,
            322,
            421,
            376,
            374,
            189,
            360,
            73,
            498,
            326,
            427,
            82,
            280,
            389,
            114,
            6,
            295,
            382,
            414,
            452,
            463,
            373,
            315,
            402,
            442,
            285,
            72,
            369,
            113,
            432,
            180,
            371,
            383,
            254,
            50,
            420,
            20,
            191,
            153,
            130,
            426,
            331,
            4,
            105,
            265,
            9,
            353,
            230,
            61,
            15
        ]
    },
    {
        "query": "Writes the set of prefixes to a file this is useful for pretty\n        printing in results.latex_output.",
        "positive_code": "def output_story_prefixes(self):\n        \n\n        if not self.test_story:\n            raise NotImplementedError(\n                \"I want to write the prefixes to a file\"\n                \"called <test_story>_prefixes.txt, but there's no test_story.\")\n\n        fn = os.path.join(TGT_DIR, \"%s_prefixes.txt\" % self.test_story)\n        with open(fn, \"w\") as f:\n            for utter_id in self.test_prefixes:\n                print(utter_id.split(\"/\")[1], file=f)",
        "hard_negative_ids": [
            171,
            360,
            312,
            363,
            414,
            466,
            197,
            32,
            189,
            90,
            349,
            223,
            304,
            25,
            275,
            23,
            438,
            47,
            470,
            109,
            73,
            106,
            429,
            151,
            341,
            376,
            222,
            452,
            272,
            264,
            232,
            178,
            201,
            493,
            44,
            391,
            226,
            317,
            291,
            329,
            165,
            15,
            289,
            425,
            395,
            157,
            97,
            2,
            453,
            76
        ]
    },
    {
        "query": "Create a symbolic link at `link_path` pointing to `target_path`.\n\n    :param unicode target_path:\n        Link target\n\n    :param unicode link_path:\n        Fullpath to link name\n\n    :param bool override:\n        If True and `link_path` already exists as a link, that link is overridden.",
        "positive_code": "def CreateLink(target_path, link_path, override=True):\n    \n    _AssertIsLocal(target_path)\n    _AssertIsLocal(link_path)\n\n    if override and IsLink(link_path):\n        DeleteLink(link_path)\n\n    \n    dirname = os.path.dirname(link_path)\n    if dirname:\n        CreateDirectory(dirname)\n\n    if sys.platform != :\n        return os.symlink(target_path, link_path)  \n    else:\n        \n        \n\n        import jaraco.windows.filesystem\n        return jaraco.windows.filesystem.symlink(target_path, link_path)\n\n        from ._easyfs_win32 import CreateSymbolicLink\n        try:\n            dw_flags = 0\n            if target_path and os.path.isdir(target_path):\n                dw_flags = 1\n            return CreateSymbolicLink(target_path, link_path, dw_flags)\n        except Exception as e:\n            reraise(e,  % locals())",
        "hard_negative_ids": [
            92,
            21,
            481,
            81,
            134,
            170,
            360,
            325,
            295,
            349,
            171,
            204,
            329,
            344,
            391,
            498,
            188,
            459,
            304,
            420,
            106,
            300,
            89,
            73,
            109,
            38,
            76,
            131,
            176,
            179,
            414,
            425,
            453,
            218,
            275,
            178,
            39,
            66,
            269,
            317,
            331,
            260,
            12,
            15,
            228,
            264,
            201,
            91,
            345,
            65
        ]
    },
    {
        "query": "Create a new MDWrap by parsing root.\n\n        :param root: Element or ElementTree to be parsed into a MDWrap.\n        :raises exceptions.ParseError: If mdWrap does not contain MDTYPE\n        :raises exceptions.ParseError: If xmlData contains no children",
        "positive_code": "def parse(cls, root):\n        \n        if root.tag != utils.lxmlns(\"mets\") + \"mdWrap\":\n            raise exceptions.ParseError(\n                \"MDWrap can only parse mdWrap elements with METS namespace.\"\n            )\n        mdtype = root.get(\"MDTYPE\")\n        if not mdtype:\n            raise exceptions.ParseError(\"mdWrap must have a MDTYPE\")\n        othermdtype = root.get(\"OTHERMDTYPE\")\n        document = root.xpath(\"mets:xmlData/*\", namespaces=utils.NAMESPACES)\n        if len(document) == 0:\n            raise exceptions.ParseError(\n                \"All mdWrap/xmlData elements must have at least one child; this\"\n                \" one has none\"\n            )\n        elif len(document) == 1:\n            document = document[0]\n\n        \n        document = copy.deepcopy(document)\n\n        return cls(document, mdtype, othermdtype)",
        "hard_negative_ids": [
            363,
            82,
            291,
            178,
            322,
            433,
            325,
            446,
            461,
            348,
            81,
            459,
            170,
            360,
            232,
            470,
            388,
            462,
            391,
            171,
            203,
            382,
            496,
            425,
            106,
            204,
            304,
            386,
            311,
            201,
            23,
            429,
            39,
            344,
            329,
            453,
            295,
            227,
            266,
            73,
            66,
            317,
            136,
            349,
            307,
            269,
            144,
            300,
            85,
            182
        ]
    },
    {
        "query": "Set up coredns instance so it can be used in OpenMetricsBaseCheck",
        "positive_code": "def _create_core_dns_instance(self, instance):\n        \n        endpoint = instance.get()\n        if endpoint is None:\n            raise ConfigurationError(\"Unable to find prometheus endpoint in config file.\")\n\n        metrics = [DEFAULT_METRICS, GO_METRICS]\n        metrics.extend(instance.get(, []))\n\n        instance.update({: endpoint, : , : metrics})\n\n        return instance",
        "hard_negative_ids": [
            255,
            269,
            97,
            219,
            333,
            232,
            254,
            386,
            315,
            69,
            375,
            25,
            23,
            470,
            109,
            382,
            11,
            293,
            192,
            462,
            291,
            90,
            149,
            179,
            289,
            61,
            182,
            184,
            99,
            272,
            236,
            239,
            235,
            258,
            127,
            180,
            490,
            305,
            135,
            321,
            215,
            209,
            489,
            35,
            363,
            234,
            155,
            387,
            223,
            377
        ]
    },
    {
        "query": "Returns the part of the region that is visible on a screen\n\n        If the region equals to all visible screens, returns Screen(-1).\n        If the region is visible on multiple screens, returns the screen with the smallest ID.\n        Returns None if the region is outside the screen.",
        "positive_code": "def clipRegionToScreen(self):\n        \n        if not self.isRegionValid():\n            return None\n        screens = PlatformManager.getScreenDetails()\n        total_x, total_y, total_w, total_h = Screen(-1).getBounds()\n        containing_screen = None\n        for screen in screens:\n            s_x, s_y, s_w, s_h = screen[\"rect\"]\n            if self.x >= s_x and self.x+self.w <= s_x+s_w and self.y >= s_y and self.y+self.h <= s_y+s_h:\n                \n                return self\n            elif self.x+self.w <= s_x or s_x+s_w <= self.x or self.y+self.h <= s_y or s_y+s_h <= self.y:\n                \n                continue\n            elif self.x == total_x and self.y == total_y and self.w == total_w and self.h == total_h:\n                \n                return self\n            else:\n                \n                x = max(self.x, s_x)\n                y = max(self.y, s_y)\n                w = min(self.w, s_w)\n                h = min(self.h, s_h)\n                return Region(x, y, w, h)\n        return None",
        "hard_negative_ids": [
            433,
            360,
            124,
            197,
            466,
            414,
            47,
            499,
            73,
            291,
            429,
            256,
            349,
            391,
            76,
            130,
            25,
            204,
            171,
            136,
            159,
            23,
            185,
            304,
            494,
            44,
            470,
            232,
            295,
            459,
            85,
            52,
            79,
            269,
            423,
            425,
            106,
            157,
            434,
            318,
            109,
            116,
            489,
            128,
            222,
            382,
            15,
            395,
            96,
            462
        ]
    },
    {
        "query": "Returns a new L{ImageLoadConfigDirectory64} object.\n        \n        @type readDataInstance: L{ReadData}\n        @param readDataInstance: A L{ReadData} object containing data to create a new L{ImageLoadConfigDirectory64} object.\n        \n        @rtype: L{ImageLoadConfigDirectory64}\n        @return: A new L{ImageLoadConfigDirectory64} object.",
        "positive_code": "def parse(readDataInstance):\n        \n        configDir = ImageLoadConfigDirectory64()\n\n        configDir.size.value = readDataInstance.readDword()\n        configDir.timeDateStamp.value = readDataInstance.readDword()\n        configDir.majorVersion.value = readDataInstance.readWord()\n        configDir.minorVersion.value = readDataInstance.readWord()\n        configDir.globalFlagsClear.value = readDataInstance.readDword()\n        configDir.globalFlagsSet.value = readDataInstance.readDword()\n        configDir.criticalSectionDefaultTimeout.value = readDataInstance.readDword()\n        configDir.deCommitFreeBlockThreshold.value = readDataInstance.readQword()\n        configDir.deCommitTotalFreeThreshold.value = readDataInstance.readQword()\n        configDir.lockPrefixTable.value = readDataInstance.readQword()\n        configDir.maximumAllocationSize.value = readDataInstance.readQword()\n        configDir.virtualMemoryThreshold.value = readDataInstance.readQword()\n        configDir.processAffinityMask.value = readDataInstance.readQword()\n        configDir.processHeapFlags.value = readDataInstance.readDword()\n        configDir.cdsVersion.value = readDataInstance.readWord()\n        configDir.reserved1.value = readDataInstance.readWord()\n        configDir.editList.value = readDataInstance.readQword()\n        configDir.securityCookie.value = readDataInstance.readQword()\n        configDir.SEHandlerTable.value = readDataInstance.readQword()\n        configDir.SEHandlerCount.value = readDataInstance.readQword()\n\n        \n        configDir.GuardCFCheckFunctionPointer.value = readDataInstance.readQword() \n        configDir.Reserved2.value = readDataInstance.readQword()\n        configDir.GuardCFFunctionTable.value = readDataInstance.readQword() \n        configDir.GuardCFFunctionCount.value = readDataInstance.readQword()\n        configDir.GuardFlags.value = readDataInstance.readQword()\n        return configDir",
        "hard_negative_ids": [
            82,
            79,
            135,
            53,
            81,
            470,
            325,
            237,
            297,
            109,
            106,
            421,
            304,
            178,
            113,
            391,
            459,
            171,
            360,
            170,
            256,
            453,
            58,
            232,
            223,
            425,
            317,
            393,
            76,
            204,
            39,
            498,
            15,
            344,
            33,
            195,
            357,
            179,
            85,
            424,
            222,
            440,
            154,
            300,
            280,
            283,
            382,
            466,
            492,
            279
        ]
    },
    {
        "query": "Get an expire downtime brok\n\n        :param host_name: host concerned by the downtime\n        :type host_name\n        :param service_name: service concerned by the downtime\n        :type service_name\n        :return: brok with wanted data\n        :rtype: alignak.brok.Brok",
        "positive_code": "def get_expire_brok(self, host_name, service_name=):\n        \n        data = self.serialize()\n        data[] = host_name\n        if service_name != :\n            data[] = service_name\n\n        return Brok({: , : data})",
        "hard_negative_ids": [
            291,
            421,
            81,
            325,
            360,
            232,
            498,
            414,
            439,
            280,
            302,
            204,
            73,
            393,
            344,
            173,
            61,
            466,
            429,
            223,
            23,
            20,
            300,
            25,
            470,
            197,
            279,
            133,
            113,
            115,
            353,
            33,
            195,
            357,
            85,
            424,
            189,
            440,
            154,
            411,
            136,
            273,
            163,
            226,
            283,
            492,
            117,
            285,
            427,
            484
        ]
    },
    {
        "query": "Combines the Q objects returned by a valid\n        filter form with any other arguments and\n        returns a list of Q objects that can be passed\n        to a queryset.",
        "positive_code": "def get_filter(self, **filter_kwargs):\n        \n\n        q_objects = super(ListView, self).get_filter(**filter_kwargs)\n        form = self.get_filter_form()\n        if form:\n            q_objects.extend(form.get_filter())\n\n        return q_objects",
        "hard_negative_ids": [
            107,
            485,
            250,
            360,
            10,
            470,
            160,
            291,
            269,
            97,
            429,
            494,
            79,
            287,
            415,
            383,
            474,
            466,
            255,
            404,
            246,
            414,
            391,
            232,
            201,
            106,
            349,
            264,
            304,
            171,
            47,
            23,
            90,
            197,
            382,
            222,
            462,
            453,
            193,
            136,
            178,
            472,
            252,
            212,
            63,
            317,
            425,
            254,
            81,
            203
        ]
    },
    {
        "query": "Rotation of device\n        Returns:\n            int (0-3)",
        "positive_code": "def rotation(self):\n        \n        rs = dict(PORTRAIT=0, LANDSCAPE=1, UIA_DEVICE_ORIENTATION_LANDSCAPERIGHT=3)\n        return rs.get(self.session.orientation, 0)",
        "hard_negative_ids": [
            77,
            75,
            245,
            240,
            349,
            386,
            298,
            95,
            361,
            54,
            149,
            466,
            232,
            395,
            234,
            211,
            221,
            198,
            470,
            268,
            17,
            416,
            147,
            450,
            252,
            137,
            429,
            318,
            462,
            197,
            41,
            157,
            40,
            206,
            239,
            489,
            256,
            58,
            238,
            414,
            105,
            307,
            195,
            272,
            329,
            101,
            175,
            155,
            300,
            490
        ]
    },
    {
        "query": "Move a page to before some other page of the document. Specify 'to = -1' to move after last page.",
        "positive_code": "def movePage(self, pno, to = -1):\n        \n        pl = list(range(len(self)))\n        if pno < 0 or pno > pl[-1]:\n            raise ValueError(\" page number out of range\")\n        if to < -1 or to > pl[-1]:\n            raise ValueError(\" page number out of range\")\n        pl.remove(pno)\n        if to == -1:\n            pl.append(pno)\n        else:\n            pl.insert(to-1, pno)\n        return self.select(pl)",
        "hard_negative_ids": [
            193,
            306,
            482,
            250,
            273,
            485,
            414,
            268,
            494,
            472,
            360,
            466,
            295,
            242,
            19,
            171,
            349,
            275,
            403,
            197,
            73,
            391,
            470,
            429,
            157,
            106,
            269,
            304,
            76,
            131,
            368,
            232,
            376,
            395,
            317,
            291,
            453,
            189,
            264,
            256,
            178,
            136,
            109,
            425,
            462,
            44,
            47,
            318,
            77,
            285
        ]
    },
    {
        "query": "Generate new results object from the output of nhmmer search",
        "positive_code": "def import_from_nhmmer_table(hmmout_path):\n        \n        \n        \n        \n        res=HMMSearchResult()\n        res.fields = [\n                       SequenceSearchResult.QUERY_ID_FIELD,\n                       SequenceSearchResult.HMM_NAME_FIELD,\n                       SequenceSearchResult.ALIGNMENT_LENGTH_FIELD,\n                       SequenceSearchResult.QUERY_FROM_FIELD,\n                       SequenceSearchResult.QUERY_TO_FIELD,\n                       SequenceSearchResult.HIT_FROM_FIELD,\n                       SequenceSearchResult.HIT_TO_FIELD,\n                       SequenceSearchResult.ALIGNMENT_BIT_SCORE,\n                       SequenceSearchResult.ALIGNMENT_DIRECTION,\n                       ]\n        \n        for row in [x.rstrip().split() for x in open(hmmout_path) if not x.startswith()]:\n            alifrom    = int(row[6])\n            alito      = int(row[7])\n            aln_length = (alito-alifrom if alito-alifrom>0 else alifrom-alito)\n            res.results.append([row[0],\n                                row[2],\n                                aln_length,\n                                int(row[4]),\n                                int(row[5]),\n                                alifrom,\n                                alito,\n                                row[13],\n                                alito > alifrom\n                                ])\n        return res",
        "hard_negative_ids": [
            82,
            482,
            79,
            438,
            136,
            470,
            32,
            466,
            197,
            376,
            414,
            360,
            227,
            9,
            452,
            223,
            333,
            429,
            493,
            297,
            151,
            154,
            34,
            73,
            201,
            252,
            58,
            349,
            395,
            193,
            291,
            226,
            7,
            232,
            26,
            363,
            113,
            367,
            2,
            81,
            131,
            11,
            327,
            199,
            417,
            329,
            69,
            109,
            153,
            67
        ]
    },
    {
        "query": "u\"\"\"\n        Returns a generator yielding the elements of `texts` matching this pattern.\n\n        :type texts: typing.Iterable[text_type]\n        :param texts: An iterable collection of texts to match\n        :rtype: typing.Iterable[text_type]\n        :return: A generator of filtered elements.",
        "positive_code": "def filter(self, texts):\n        u\n        return (text for text in texts if self.regex.match(text) is not None)",
        "hard_negative_ids": [
            77,
            437,
            433,
            360,
            166,
            349,
            388,
            216,
            232,
            466,
            425,
            189,
            429,
            348,
            461,
            414,
            73,
            376,
            470,
            62,
            15,
            464,
            443,
            327,
            197,
            227,
            81,
            292,
            144,
            272,
            171,
            106,
            178,
            318,
            304,
            39,
            395,
            258,
            391,
            1,
            117,
            204,
            453,
            427,
            76,
            339,
            47,
            344,
            302,
            317
        ]
    },
    {
        "query": "@deprecated\n\n        :param message:\n        :return:",
        "positive_code": "def log(self, message: str):\n        \n        dset_log_id =  % self.iid\n\n        if dset_log_id not in self.parent.data.keys():\n            dset = self.parent.data.create_dataset(\n                dset_log_id, shape=(1,),\n                dtype=np.dtype([\n                    (, ),\n                    (, )\n                ])\n            )\n        else:\n            dset = self.parent.data[dset_log_id]\n\n        timestamp = np.array(\n            datetime.now().strftime(\"%s\")\n        ).astype().view()\n\n        dset[] = timestamp.view()\n        dset[] = message\n        self.parent.data.flush()",
        "hard_negative_ids": [
            488,
            262,
            244,
            301,
            37,
            81,
            327,
            264,
            204,
            344,
            300,
            427,
            176,
            150,
            380,
            328,
            460,
            485,
            498,
            487,
            478,
            435,
            481,
            94,
            441,
            390,
            21,
            134,
            386,
            5,
            250,
            193,
            454,
            226,
            112,
            86,
            128,
            210,
            42,
            3,
            56,
            433,
            141,
            425,
            55,
            304,
            118,
            424,
            453,
            48
        ]
    },
    {
        "query": "Gets the 20 most recent direct messages received by the authenticating\n        user.\n\n        https://dev.twitter.com/docs/api/1.1/get/direct_messages\n\n        :param str since_id:\n            Returns results with an ID greater than (that is, more recent than)\n            the specified ID. There are limits to the number of Tweets which\n            can be accessed through the API. If the limit of Tweets has occured\n            since the since_id, the since_id will be forced to the oldest ID\n            available.\n\n        :params str max_id:\n            Returns results with an ID less than (that is, older than) or equal\n            to the specified ID.\n\n        :param int count:\n            Specifies the number of direct messages to try and retrieve, up to\n            a maximum of ``200``. The value of count is best thought of as a\n            limit to the number of Tweets to return because suspended or\n            deleted content is removed after the count has been applied.\n\n        :param bool include_entities:\n            The entities node will not be included when set to ``False``.\n\n        :param bool skip_status:\n            When set to ``True``, statuses will not be included in the returned\n            user objects.\n\n        :returns:\n            A list of direct message dicts.",
        "positive_code": "def direct_messages(self, since_id=None, max_id=None, count=None,\n                        include_entities=None, skip_status=None):\n        \n        params = {}\n        set_str_param(params, , since_id)\n        set_str_param(params, , max_id)\n        set_int_param(params, , count)\n        set_bool_param(params, , include_entities)\n        set_bool_param(params, , skip_status)\n        return self._get_api(, params)",
        "hard_negative_ids": [
            360,
            291,
            73,
            429,
            207,
            197,
            414,
            187,
            466,
            232,
            81,
            56,
            252,
            382,
            470,
            349,
            264,
            142,
            312,
            425,
            322,
            105,
            265,
            391,
            12,
            79,
            361,
            23,
            275,
            424,
            179,
            222,
            488,
            386,
            500,
            97,
            301,
            395,
            462,
            329,
            318,
            402,
            262,
            256,
            52,
            136,
            109,
            272,
            289,
            300
        ]
    },
    {
        "query": "Turn the Box and sub Boxes back into a native\n        python dictionary.\n\n        :return: python dictionary of this Box",
        "positive_code": "def to_dict(self):\n        \n        out_dict = dict(self)\n        for k, v in out_dict.items():\n            if v is self:\n                out_dict[k] = out_dict\n            elif hasattr(v, ):\n                out_dict[k] = v.to_dict()\n            elif hasattr(v, ):\n                out_dict[k] = v.to_list()\n        return out_dict",
        "hard_negative_ids": [
            308,
            178,
            47,
            382,
            466,
            444,
            360,
            349,
            197,
            414,
            470,
            188,
            429,
            90,
            106,
            304,
            391,
            291,
            189,
            395,
            453,
            232,
            425,
            317,
            318,
            136,
            23,
            73,
            171,
            15,
            462,
            275,
            192,
            25,
            44,
            256,
            272,
            24,
            485,
            76,
            157,
            345,
            184,
            219,
            46,
            222,
            257,
            477,
            180,
            109
        ]
    },
    {
        "query": "Save word to storage",
        "positive_code": "def SSTORE(self, offset, value):\n        \n        storage_address = self.address\n        self._publish(, storage_address, offset, value)\n        \n        \n        \n        \n\n        if istainted(self.pc):\n            for taint in get_taints(self.pc):\n                value = taint_with(value, taint)\n        self.world.set_storage_data(storage_address, offset, value)\n        self._publish(, storage_address, offset, value)",
        "hard_negative_ids": [
            120,
            285,
            452,
            467,
            409,
            273,
            260,
            171,
            269,
            149,
            163,
            131,
            368,
            376,
            295,
            414,
            264,
            189,
            73,
            275,
            360,
            47,
            76,
            266,
            157,
            329,
            466,
            99,
            109,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468
        ]
    },
    {
        "query": "Form of distribution must be an array of counts in order of self.keys.",
        "positive_code": "def logProbability(self, distn):\n    \n    x = numpy.asarray(distn)\n    n = x.sum()\n    return (logFactorial(n) - numpy.sum([logFactorial(k) for k in x]) +\n      numpy.sum(x * numpy.log(self.dist.pmf)))",
        "hard_negative_ids": [
            232,
            470,
            415,
            386,
            429,
            88,
            382,
            349,
            196,
            395,
            318,
            466,
            12,
            45,
            476,
            189,
            192,
            197,
            43,
            295,
            4,
            387,
            291,
            294,
            360,
            48,
            442,
            249,
            100,
            105,
            157,
            299,
            182,
            361,
            81,
            462,
            427,
            113,
            252,
            73,
            272,
            15,
            256,
            23,
            436,
            414,
            11,
            97,
            149,
            490
        ]
    },
    {
        "query": "Ensure path exists.\n\n    Arguments:\n        *components (str[]): Path components.\n\n    Returns:\n        str: File path.\n\n    Raises:\n        File404: If path does not exist.",
        "positive_code": "def must_exist(*components):\n    \n    _path = path(*components)\n    if not exists(_path):\n        raise File404(_path)\n    return _path",
        "hard_negative_ids": [
            145,
            49,
            170,
            363,
            38,
            456,
            44,
            254,
            169,
            457,
            144,
            246,
            380,
            230,
            98,
            269,
            68,
            436,
            458,
            329,
            171,
            193,
            333,
            138,
            203,
            394,
            31,
            163,
            23,
            222,
            234,
            289,
            194,
            275,
            150,
            261,
            1,
            412,
            243,
            34,
            311,
            379,
            190,
            345,
            339,
            435,
            27,
            367,
            63,
            188
        ]
    },
    {
        "query": "Create a JuiceBox from a list of header lines.\n\n    @param lines: a list of lines.",
        "positive_code": "def parseJuiceHeaders(lines):\n    \n    b = JuiceBox()\n    bodylen = 0\n    key = None\n    for L in lines:\n        if L[0] == :\n            \n            assert key is not None\n            b[key] += +L[1:]\n            continue\n        parts = L.split(, 1)\n        if len(parts) != 2:\n            raise MalformedJuiceBox(\"Wrong number of parts: %r\" % (L,))\n        key, value = parts\n        key = normalizeKey(key)\n        b[key] = value\n    return int(b.pop(LENGTH, 0)), b",
        "hard_negative_ids": [
            223,
            452,
            341,
            186,
            325,
            81,
            171,
            407,
            300,
            470,
            283,
            349,
            459,
            106,
            304,
            391,
            359,
            170,
            438,
            344,
            69,
            466,
            453,
            236,
            178,
            9,
            64,
            204,
            252,
            317,
            425,
            395,
            39,
            360,
            232,
            15,
            272,
            77,
            2,
            193,
            429,
            256,
            197,
            328,
            382,
            7,
            267,
            26,
            265,
            76
        ]
    },
    {
        "query": "Query widget option.\n\n        :param key: option name\n        :type key: str\n        :return: value of the option\n\n        To get the list of options for this widget, call the method :meth:`~ItemsCanvas.keys`.",
        "positive_code": "def cget(self, key):\n        \n        if key is \"canvaswidth\":\n            return self._canvaswidth\n        elif key is \"canvasheight\":\n            return self._canvasheight\n        elif key is \"function_new\":\n            return self._function_new\n        elif key is \"callback_add\":\n            return self._callback_add\n        elif key is \"callback_del\":\n            return self._callback_del\n        elif key is \"callback_move\":\n            return self._callback_move\n        else:\n            ttk.Frame.cget(self, key)",
        "hard_negative_ids": [
            130,
            182,
            360,
            196,
            64,
            232,
            424,
            314,
            45,
            323,
            498,
            16,
            466,
            476,
            414,
            442,
            222,
            11,
            197,
            113,
            402,
            349,
            387,
            280,
            81,
            243,
            382,
            15,
            105,
            267,
            303,
            91,
            429,
            48,
            353,
            332,
            73,
            481,
            76,
            366,
            291,
            41,
            56,
            179,
            385,
            345,
            44,
            62,
            344,
            189
        ]
    },
    {
        "query": "Checks a given client against labels/owners whitelists.",
        "positive_code": "def CheckClientLabels(client_id,\n                      labels_whitelist=None,\n                      labels_owners_whitelist=None,\n                      token=None):\n  \n\n  labels_whitelist = labels_whitelist or []\n  labels_owners_whitelist = labels_owners_whitelist or []\n\n  if data_store.RelationalDBEnabled():\n    labels = data_store.REL_DB.ReadClientLabels(str(client_id))\n  else:\n    with aff4.FACTORY.Open(\n        client_id.ToClientURN(), aff4_type=aff4_grr.VFSGRRClient,\n        token=token) as fd:\n      labels = fd.GetLabels()\n\n  for label in labels:\n    if (label.name in labels_whitelist and\n        label.owner in labels_owners_whitelist):\n      return\n\n  raise access_control.UnauthorizedAccess(\n      \"Client %s doesn't have necessary labels.\" % utils.SmartStr(client_id))",
        "hard_negative_ids": [
            423,
            425,
            391,
            184,
            271,
            73,
            185,
            451,
            201,
            106,
            207,
            317,
            157,
            304,
            369,
            191,
            457,
            103,
            12,
            500,
            382,
            453,
            429,
            178,
            265,
            100,
            159,
            361,
            113,
            462,
            360,
            171,
            15,
            222,
            162,
            427,
            99,
            69,
            470,
            472,
            177,
            388,
            197,
            256,
            296,
            88,
            350,
            95,
            160,
            349
        ]
    },
    {
        "query": "This event is executed after each transition and delegates further\n    actions to 'workflow.<portal_type>.events.after_<transition_id> function\n    if exists for the instance passed in.\n    :param instance: the instance that has been transitioned\n    :type instance: ATContentType\n    :param event: event that holds the transition performed\n    :type event: IObjectEvent",
        "positive_code": "def AfterTransitionEventHandler(instance, event):\n    \n    if call_workflow_event(instance, event, after=True):\n        return\n\n    \n    \n    if not event.transition:\n        return\n    \n        after_event = getattr(instance, key, False)\n    if not after_event:\n        return\n    after_event()",
        "hard_negative_ids": [
            314,
            257,
            372,
            269,
            237,
            360,
            156,
            219,
            81,
            287,
            159,
            42,
            429,
            327,
            330,
            414,
            197,
            252,
            232,
            333,
            202,
            485,
            23,
            466,
            291,
            204,
            235,
            17,
            475,
            344,
            73,
            268,
            142,
            275,
            345,
            329,
            300,
            38,
            209,
            189,
            44,
            113,
            132,
            245,
            279,
            47,
            236,
            133,
            76,
            201
        ]
    },
    {
        "query": "Returns the week in which this game took place. 18 is WC round, 19\n        is Div round, 20 is CC round, 21 is SB.\n        :returns: Integer from 1 to 21.",
        "positive_code": "def week(self):\n        \n        doc = self.get_doc()\n        raw = doc().attr[]\n        match = re.match(\n            r.format(self.season()), raw\n        )\n        if match:\n            return int(match.group(1))\n        else:\n            return 21",
        "hard_negative_ids": [
            462,
            146,
            414,
            73,
            211,
            47,
            149,
            189,
            360,
            48,
            197,
            131,
            466,
            181,
            171,
            291,
            423,
            275,
            90,
            193,
            99,
            368,
            136,
            289,
            7,
            26,
            429,
            44,
            367,
            413,
            69,
            11,
            185,
            66,
            23,
            224,
            345,
            67,
            109,
            269,
            25,
            192,
            157,
            153,
            376,
            295,
            76,
            264,
            141,
            328
        ]
    },
    {
        "query": "Wrapper for ``_write``",
        "positive_code": "def write(self, image, options, thumbnail):\n        \n        format_ = options[]\n        quality = options[]\n        image_info = options.get(, {})\n        \n        progressive = options.get(, settings.THUMBNAIL_PROGRESSIVE)\n        raw_data = self._get_raw_data(\n            image, format_, quality,\n            image_info=image_info,\n            progressive=progressive\n        )\n        thumbnail.write(raw_data)",
        "hard_negative_ids": [
            112,
            297,
            41,
            330,
            425,
            324,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190,
            443,
            145,
            103,
            4,
            344,
            122,
            387,
            246,
            411,
            477,
            15,
            85,
            215,
            209,
            40,
            388,
            226,
            10,
            64,
            169
        ]
    },
    {
        "query": "Process method request and return json with results\n\n        :param method: str: specifies the method, example: \"users.get\"\n        :param method_kwargs: dict: method parameters,\n        example: \"users_id=1\", \"fields='city, contacts'\"",
        "positive_code": "def request_method(self, method: str,\n                       **method_kwargs: Union[str, int]) -> dict:\n        \n        response = self.session.send_method_request(method, method_kwargs)\n        self.check_for_errors(method, method_kwargs, response)\n        return response",
        "hard_negative_ids": [
            323,
            139,
            10,
            402,
            41,
            434,
            70,
            81,
            428,
            69,
            491,
            131,
            103,
            2,
            411,
            265,
            127,
            222,
            44,
            415,
            204,
            452,
            300,
            344,
            32,
            425,
            414,
            360,
            129,
            438,
            291,
            345,
            421,
            201,
            369,
            178,
            8,
            223,
            285,
            23,
            331,
            52,
            187,
            493,
            463,
            326,
            429,
            382,
            151,
            466
        ]
    },
    {
        "query": "For a given script solution, iterate yield its sec blobs",
        "positive_code": "def extract_secs(self, tx, tx_in_idx):\n        \n        sc = tx.SolutionChecker(tx)\n        tx_context = sc.tx_context_for_idx(tx_in_idx)\n        \n        solution_stack = []\n        for puzzle_script, solution_stack, flags, sighash_f in sc.puzzle_and_solution_iterator(tx_context):\n            for opcode, data, pc, new_pc in self._script_tools.get_opcodes(puzzle_script):\n                if data and is_sec(data):\n                    yield data\n            for data in solution_stack:\n                if is_sec(data):\n                    yield data",
        "hard_negative_ids": [
            360,
            29,
            441,
            73,
            106,
            304,
            144,
            246,
            391,
            477,
            301,
            99,
            317,
            24,
            453,
            288,
            291,
            178,
            195,
            311,
            425,
            15,
            384,
            171,
            120,
            69,
            470,
            375,
            256,
            298,
            382,
            222,
            462,
            319,
            149,
            76,
            349,
            472,
            179,
            272,
            466,
            180,
            23,
            135,
            489,
            321,
            35,
            363,
            234,
            223
        ]
    },
    {
        "query": "Publish an amqp message to a rmq juju unit.\n\n        :param sentry_unit: sentry unit pointer\n        :param message: amqp message string\n        :param queue: message queue, default to test\n        :param username: amqp user name, default to testuser1\n        :param password: amqp user password\n        :param ssl: boolean, default to False\n        :param port: amqp port, use defaults if None\n        :returns: None.  Raises exception if publish failed.",
        "positive_code": "def publish_amqp_message_by_unit(self, sentry_unit, message,\n                                     queue=\"test\", ssl=False,\n                                     username=\"testuser1\",\n                                     password=\"changeme\",\n                                     port=None):\n        \n        self.log.debug(.format(queue,\n                                                                    message))\n        connection = self.connect_amqp_by_unit(sentry_unit, ssl=ssl,\n                                               port=port,\n                                               username=username,\n                                               password=password)\n\n        \n        \n        \n        self.log.debug()\n        channel = connection.channel()\n        self.log.debug()\n        channel.queue_declare(queue=queue, auto_delete=False, durable=True)\n        self.log.debug()\n        channel.basic_publish(exchange=, routing_key=queue, body=message)\n        self.log.debug()\n        channel.close()\n        self.log.debug()\n        connection.close()",
        "hard_negative_ids": [
            55,
            425,
            488,
            168,
            52,
            81,
            262,
            424,
            301,
            264,
            13,
            327,
            306,
            37,
            84,
            405,
            210,
            412,
            76,
            228,
            251,
            204,
            413,
            50,
            131,
            227,
            344,
            187,
            429,
            99,
            40,
            360,
            73,
            342,
            293,
            414,
            97,
            147,
            300,
            201,
            189,
            498,
            47,
            171,
            128,
            176,
            103,
            122,
            275,
            66
        ]
    },
    {
        "query": "Make an update of the internal status by gathering the variational posteriors for all the individual models.",
        "positive_code": "def _update_inernal(self, varp_list):\n        \n        \n        self._b_prob_all = 1.-param_to_array(varp_list[0].gamma_group)\n        [np.multiply(self._b_prob_all, 1.-vp.gamma_group, self._b_prob_all) for vp in varp_list[1:]]",
        "hard_negative_ids": [
            291,
            161,
            136,
            466,
            85,
            360,
            376,
            197,
            414,
            152,
            73,
            295,
            429,
            23,
            489,
            89,
            333,
            25,
            193,
            76,
            189,
            198,
            116,
            97,
            351,
            476,
            105,
            427,
            232,
            349,
            45,
            44,
            395,
            142,
            470,
            273,
            412,
            88,
            467,
            186,
            64,
            420,
            47,
            201,
            402,
            90,
            237,
            67,
            318,
            157
        ]
    },
    {
        "query": "Workaround for bug in Python 3. See more info at:\n        https://bugs.python.org/issue16308\n        https://github.com/iterative/dvc/issues/769\n\n        Args:\n            subparsers: subparsers to fix.",
        "positive_code": "def fix_subparsers(subparsers):\n    \n    from dvc.utils.compat import is_py3\n\n    if is_py3:  \n        subparsers.required = True\n        subparsers.dest = \"cmd\"",
        "hard_negative_ids": [
            207,
            500,
            265,
            159,
            457,
            47,
            269,
            429,
            77,
            287,
            488,
            361,
            41,
            275,
            295,
            391,
            219,
            322,
            162,
            95,
            147,
            69,
            388,
            71,
            414,
            88,
            112,
            349,
            326,
            177,
            324,
            385,
            296,
            316,
            350,
            179,
            54,
            368,
            73,
            317,
            472,
            50,
            234,
            487,
            387,
            228,
            297,
            464,
            240,
            160
        ]
    },
    {
        "query": "Generates the Metrics for a given InferenceType\n\n  Parameters:\n  -------------------------------------------------------------------------\n  options: ExpGenerator options\n  retval: (metricsList, optimizeMetricLabel)\n            metricsList: list of metric string names\n            optimizeMetricLabel: Name of the metric which to optimize over",
        "positive_code": "def _generateMetricSpecs(options):\n  \n  inferenceType = options[]\n  inferenceArgs = options[]\n  predictionSteps = inferenceArgs[]\n  metricWindow = options[]\n  if metricWindow is None:\n    metricWindow = int(Configuration.get(\"nupic.opf.metricWindow\"))\n\n  metricSpecStrings = []\n  optimizeMetricLabel = \"\"\n\n  \n  \n  metricSpecStrings.extend(_generateExtraMetricSpecs(options))\n\n  \n\n  optimizeMetricSpec = None\n  \n  \n  \n  \n  if options[]:\n    assert len(predictionSteps) == 1\n    predictionSteps = []\n\n  \n  \n  if inferenceType in (InferenceType.TemporalNextStep,\n                       InferenceType.TemporalAnomaly,\n                       InferenceType.TemporalMultiStep,\n                       InferenceType.NontemporalMultiStep,\n                       InferenceType.NontemporalClassification,\n                       ):\n\n    predictedFieldName, predictedFieldType = _getPredictedField(options)\n    isCategory = _isCategory(predictedFieldType)\n    metricNames = (,) if isCategory else (, )\n    trivialErrorMetric =  if isCategory else \n    oneGramErrorMetric =  if isCategory else \n    movingAverageBaselineName =  if isCategory else \n\n    \n    for metricName in metricNames:\n      metricSpec, metricLabel = \\\n        _generateMetricSpecString(field=predictedFieldName,\n                 inferenceElement=InferenceElement.multiStepBestPredictions,\n                 metric=,\n                 params={: metricName,\n                               :metricWindow,\n                               : predictionSteps},\n                 returnLabel=True)\n      metricSpecStrings.append(metricSpec)\n\n    \n    if options[\"customErrorMetric\"] is not None :\n      metricParams = dict(options[\"customErrorMetric\"])\n      metricParams[] = \n      metricParams[] = predictionSteps\n      \n      if not \"errorWindow\" in metricParams:\n        metricParams[\"errorWindow\"] = metricWindow\n      metricSpec, metricLabel =_generateMetricSpecString(field=predictedFieldName,\n                   inferenceElement=InferenceElement.multiStepPredictions,\n                   metric=\"multiStep\",\n                   params=metricParams,\n                   returnLabel=True)\n      metricSpecStrings.append(metricSpec)\n\n    \n    \n    optimizeMetricSpec = metricSpec\n    metricLabel = metricLabel.replace(, )\n    metricLabel = metricLabel.replace(, )\n    optimizeMetricLabel = metricLabel\n\n    if options[\"customErrorMetric\"] is not None :\n      optimizeMetricLabel = \".*custom_error_metric.*\"\n\n    \n    if options[\"runBaselines\"] \\\n          and inferenceType != InferenceType.NontemporalClassification:\n      for steps in predictionSteps:\n        metricSpecStrings.append(\n          _generateMetricSpecString(field=predictedFieldName,\n                                    inferenceElement=InferenceElement.prediction,\n                                    metric=\"trivial\",\n                                    params={:metricWindow,\n                                                  \"errorMetric\":trivialErrorMetric,\n                                                  : steps})\n          )\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        if isCategory:\n          metricSpecStrings.append(\n            _generateMetricSpecString(field=predictedFieldName,\n                                      inferenceElement=InferenceElement.prediction,\n                                      metric=movingAverageBaselineName,\n                                      params={:metricWindow\n                                                    ,\"errorMetric\":\"avg_err\",\n                                                    \"mode_window\":200,\n                                                    \"steps\": steps})\n            )\n        else :\n          metricSpecStrings.append(\n            _generateMetricSpecString(field=predictedFieldName,\n                                      inferenceElement=InferenceElement.prediction,\n                                      metric=movingAverageBaselineName,\n                                      params={:metricWindow\n                                                    ,\"errorMetric\":\"altMAPE\",\n                                                    \"mean_window\":200,\n                                                    \"steps\": steps})\n            )\n\n\n\n\n  \n  \n  elif inferenceType in (InferenceType.TemporalClassification):\n\n    metricName = \n    trivialErrorMetric = \n    oneGramErrorMetric = \n    movingAverageBaselineName = \n\n    optimizeMetricSpec, optimizeMetricLabel = \\\n      _generateMetricSpecString(inferenceElement=InferenceElement.classification,\n                               metric=metricName,\n                               params={:metricWindow},\n                               returnLabel=True)\n\n    metricSpecStrings.append(optimizeMetricSpec)\n\n    if options[\"runBaselines\"]:\n      \n      if inferenceType == InferenceType.TemporalClassification:\n        metricSpecStrings.append(\n          _generateMetricSpecString(inferenceElement=InferenceElement.classification,\n                                    metric=\"trivial\",\n                                    params={:metricWindow,\n                                                  \"errorMetric\":trivialErrorMetric})\n          )\n        metricSpecStrings.append(\n          _generateMetricSpecString(inferenceElement=InferenceElement.classification,\n                                    metric=\"two_gram\",\n                                    params={:metricWindow,\n                                                  \"errorMetric\":oneGramErrorMetric})\n          )\n        metricSpecStrings.append(\n          _generateMetricSpecString(inferenceElement=InferenceElement.classification,\n                                    metric=movingAverageBaselineName,\n                                    params={:metricWindow\n                                                  ,\"errorMetric\":\"avg_err\",\n                                                  \"mode_window\":200})\n          )\n\n\n    \n    if not options[\"customErrorMetric\"] == None :\n      \n      if not \"errorWindow\" in options[\"customErrorMetric\"]:\n        options[\"customErrorMetric\"][\"errorWindow\"] = metricWindow\n      optimizeMetricSpec = _generateMetricSpecString(\n                                inferenceElement=InferenceElement.classification,\n                                metric=\"custom\",\n                                params=options[\"customErrorMetric\"])\n      optimizeMetricLabel = \".*custom_error_metric.*\"\n\n      metricSpecStrings.append(optimizeMetricSpec)\n\n\n  \n  \n  \n  if options[]:\n    for i in range(len(metricSpecStrings)):\n      metricSpecStrings[i] = metricSpecStrings[i].replace(\n          \"\", \"predictionSteps\")\n    optimizeMetricLabel = optimizeMetricLabel.replace(\n        \"\", \".*\")\n  return metricSpecStrings, optimizeMetricLabel",
        "hard_negative_ids": [
            122,
            130,
            492,
            210,
            73,
            182,
            466,
            414,
            385,
            413,
            429,
            40,
            349,
            360,
            391,
            62,
            303,
            64,
            498,
            342,
            146,
            76,
            197,
            445,
            388,
            77,
            470,
            176,
            412,
            109,
            496,
            23,
            157,
            472,
            25,
            171,
            2,
            53,
            272,
            65,
            291,
            232,
            395,
            260,
            106,
            217,
            95,
            142,
            268,
            175
        ]
    },
    {
        "query": "Print out self.json in a nice way.",
        "positive_code": "def json_as_html(self):\n        \n\n        \n        from cspreports import utils\n\n        formatted_json = utils.format_report(self.json)\n        return mark_safe(\"<pre>\\n%s</pre>\" % escape(formatted_json))",
        "hard_negative_ids": [
            428,
            135,
            171,
            435,
            269,
            376,
            163,
            76,
            106,
            434,
            304,
            472,
            391,
            131,
            439,
            178,
            317,
            377,
            453,
            234,
            484,
            467,
            239,
            425,
            414,
            23,
            15,
            360,
            52,
            463,
            265,
            207,
            188,
            470,
            429,
            490,
            230,
            382,
            157,
            256,
            182,
            47,
            266,
            222,
            173,
            462,
            349,
            138,
            343,
            289
        ]
    },
    {
        "query": "Get basic block size.",
        "positive_code": "def size(self):\n        \n        if self._instrs is []:\n            return None\n\n        return sum([instr.size for instr in self._instrs])",
        "hard_negative_ids": [
            186,
            326,
            69,
            421,
            179,
            471,
            327,
            448,
            498,
            163,
            82,
            280,
            389,
            324,
            114,
            6,
            295,
            382,
            452,
            463,
            373,
            315,
            402,
            442,
            285,
            72,
            369,
            113,
            432,
            180,
            371,
            383,
            254,
            50,
            420,
            20,
            191,
            153,
            130,
            73,
            426,
            331,
            4,
            105,
            265,
            9,
            353,
            230,
            61,
            15
        ]
    },
    {
        "query": "Writes out data to binary format.\n\n    Parameters\n    ----------\n    series : Series\n        The data to write\n\n    path : string path or URI to directory to be created\n        Output files will be written underneath path.\n        Directory will be created as a result of this call.\n\n    prefix : str, optional, default = 'series'\n        String prefix for files.\n\n    overwrite : bool\n        If true, path and all its contents will be deleted and\n        recreated as partof this call.",
        "positive_code": "def tobinary(series, path, prefix=, overwrite=False, credentials=None):\n    \n    from six import BytesIO\n    from thunder.utils import check_path\n    from thunder.writers import get_parallel_writer\n\n    if not overwrite:\n        check_path(path, credentials=credentials)\n        overwrite = True\n\n    def tobuffer(kv):\n        firstkey = None\n        buf = BytesIO()\n        for k, v in kv:\n            if firstkey is None:\n                firstkey = k\n            buf.write(v.tostring())\n        val = buf.getvalue()\n        buf.close()\n        if firstkey is None:\n            return iter([])\n        else:\n            label = prefix +  + getlabel(firstkey) + \".bin\"\n            return iter([(label, val)])\n\n    writer = get_parallel_writer(path)(path, overwrite=overwrite, credentials=credentials)\n\n    if series.mode == :\n        binary = series.values.tordd().sortByKey().mapPartitions(tobuffer)\n        binary.foreach(writer.write)\n\n    else:\n        basedims = [series.shape[d] for d in series.baseaxes]\n\n        def split(k):\n            ind = unravel_index(k, basedims)\n            return ind, series.values[ind]\n\n        buf = tobuffer([split(i) for i in range(prod(basedims))])\n        [writer.write(b) for b in buf]\n\n    shape = series.shape\n    dtype = series.dtype\n\n    write_config(path, shape=shape, dtype=dtype, overwrite=overwrite, credentials=credentials)",
        "hard_negative_ids": [
            363,
            38,
            435,
            210,
            275,
            44,
            163,
            170,
            223,
            424,
            414,
            16,
            413,
            277,
            40,
            405,
            76,
            171,
            376,
            360,
            341,
            232,
            260,
            466,
            342,
            329,
            1,
            421,
            168,
            470,
            23,
            349,
            460,
            34,
            73,
            306,
            402,
            456,
            269,
            462,
            165,
            295,
            85,
            252,
            429,
            136,
            131,
            254,
            144,
            84
        ]
    },
    {
        "query": "Remove pool.",
        "positive_code": "def remove(self, id):\n        \n\n        p = Pool.get(int(id))\n        p.remove()\n        redirect(url(controller = , action = ))",
        "hard_negative_ids": [
            69,
            500,
            332,
            74,
            96,
            38,
            374,
            183,
            34,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453
        ]
    },
    {
        "query": "Returns list of matching hardware IDs for a given hostname.",
        "positive_code": "def _get_ids_from_hostname(self, hostname):\n        \n        results = self.list_hardware(hostname=hostname, mask=\"id\")\n        return [result[] for result in results]",
        "hard_negative_ids": [
            376,
            470,
            61,
            73,
            349,
            106,
            197,
            304,
            256,
            79,
            466,
            391,
            8,
            232,
            317,
            395,
            453,
            99,
            178,
            425,
            77,
            293,
            15,
            2,
            272,
            360,
            267,
            489,
            171,
            459,
            429,
            328,
            477,
            76,
            410,
            318,
            183,
            382,
            332,
            187,
            42,
            260,
            52,
            222,
            53,
            157,
            142,
            344,
            462,
            81
        ]
    },
    {
        "query": "Convolve an array with this PSF\n\n        Parameters\n        ----------\n        image : ndarray\n            An array representing the image the PSF is convolved with.\n\n        Returns\n        -------\n        convolved_image : ndarray\n            An array representing the image after convolution.\n\n        Raises\n        ------\n        KernelException if either PSF psf dimension is odd",
        "positive_code": "def convolve(self, array):\n        \n        if self.shape[0] % 2 == 0 or self.shape[1] % 2 == 0:\n            raise exc.KernelException(\"PSF Kernel must be odd\")\n\n        return scipy.signal.convolve2d(array, self, mode=)",
        "hard_negative_ids": [
            12,
            360,
            414,
            263,
            88,
            291,
            276,
            264,
            189,
            286,
            73,
            466,
            197,
            100,
            496,
            152,
            1,
            439,
            429,
            81,
            427,
            192,
            391,
            256,
            25,
            23,
            96,
            404,
            47,
            136,
            299,
            44,
            349,
            170,
            365,
            268,
            95,
            90,
            128,
            435,
            245,
            269,
            56,
            292,
            109,
            17,
            233,
            76,
            472,
            345
        ]
    },
    {
        "query": "Create a node from arguments and return it",
        "positive_code": "def get_node(obj, args, kwargs):\n    \n\n    if args is None and kwargs is None:\n        return (obj,)\n\n    if kwargs is None:\n        kwargs = {}\n    return obj, _bind_args(obj, args, kwargs)",
        "hard_negative_ids": [
            325,
            305,
            174,
            126,
            459,
            215,
            170,
            18,
            69,
            311,
            379,
            39,
            366,
            203,
            106,
            304,
            391,
            272,
            269,
            131,
            31,
            193,
            375,
            453,
            178,
            7,
            26,
            149,
            425,
            317,
            185,
            367,
            99,
            360,
            179,
            11,
            464,
            171,
            15,
            349,
            462,
            153,
            67,
            208,
            470,
            329,
            256,
            382,
            24,
            147
        ]
    },
    {
        "query": "Remove an object from the definition.",
        "positive_code": "def remove_object(self, obj):\n        \n        self._objects.remove(obj)\n        self._pairs.difference_update((obj, p) for p in self._properties)",
        "hard_negative_ids": [
            79,
            69,
            360,
            500,
            73,
            414,
            332,
            260,
            470,
            297,
            74,
            189,
            96,
            197,
            193,
            291,
            7,
            466,
            26,
            38,
            374,
            113,
            367,
            81,
            131,
            136,
            11,
            427,
            153,
            67,
            429,
            44,
            185,
            147,
            23,
            231,
            25,
            183,
            208,
            343,
            34,
            99,
            109,
            471,
            469,
            468,
            467,
            465,
            464,
            463
        ]
    },
    {
        "query": "Value of the holdings in exchange currency.\n        Value = Quantity * Price",
        "positive_code": "def value(self) -> Decimal:\n        \n        assert isinstance(self.price, Decimal)\n        \n        return self.quantity * self.price",
        "hard_negative_ids": [
            56,
            349,
            267,
            332,
            481,
            166,
            232,
            441,
            466,
            366,
            197,
            362,
            91,
            424,
            11,
            382,
            242,
            19,
            429,
            199,
            182,
            222,
            280,
            360,
            15,
            375,
            414,
            291,
            272,
            253,
            142,
            103,
            395,
            470,
            287,
            16,
            192,
            136,
            488,
            73,
            318,
            311,
            123,
            5,
            85,
            195,
            212,
            384,
            44,
            23
        ]
    },
    {
        "query": "Check whether the user has permission to view the page. If the user has\n    any of the page's permissions, they have permission. If the page has no set\n    permissions, they have permission.",
        "positive_code": "def has_permission_to_view(page, user):\n    \n    if page.permissions.count() == 0:\n        return True\n    for perm in page.permissions.all():\n        perm_label =  % (perm.content_type.app_label, perm.codename)\n        if user.has_perm(perm_label):\n            return True\n    return False",
        "hard_negative_ids": [
            193,
            306,
            197,
            482,
            273,
            201,
            291,
            425,
            189,
            187,
            466,
            55,
            360,
            414,
            185,
            268,
            73,
            269,
            131,
            404,
            103,
            429,
            157,
            415,
            25,
            109,
            173,
            464,
            203,
            136,
            44,
            90,
            174,
            386,
            23,
            228,
            349,
            395,
            368,
            272,
            470,
            275,
            232,
            366,
            264,
            496,
            293,
            77,
            97,
            477
        ]
    },
    {
        "query": "Return a location point by address\n\n        :param str query: The address or query you wish to geocode.\n\n        :param bool exactly_one: Return one result or a list of results, if\n            available.\n\n        :param int timeout: Time, in seconds, to wait for the geocoding service\n            to respond before raising a :class:`geopy.exc.GeocoderTimedOut`\n            exception. Set this only if you wish to override, on this call\n            only, the value set during the geocoder's initialization.\n\n        :param proximity: A coordinate to bias local results based on a provided\n            location.\n        :type proximity: :class:`geopy.point.Point`, list or tuple of ``(latitude,\n            longitude)``, or string as ``\"%(latitude)s, %(longitude)s\"``.\n\n        :param country: Country to filter result in form of\n            ISO 3166-1 alpha-2 country code (e.g. ``FR``).\n            Might be a Python list of strings.\n\n            .. versionchanged:: 1.19.0\n                Previously only a single string could be specified.\n                Now a Python list of individual countries is supported.\n\n        :type country: str or list\n\n        :param bbox: The bounding box of the viewport within which\n            to bias geocode results more prominently.\n            Example: ``[Point(22, 180), Point(-22, -180)]``.\n        :type bbox: list or tuple of 2 items of :class:`geopy.point.Point` or\n            ``(latitude, longitude)`` or ``\"%(latitude)s, %(longitude)s\"``.\n\n        :rtype: ``None``, :class:`geopy.location.Location` or a list of them, if\n            ``exactly_one=False``.",
        "positive_code": "def geocode(\n            self,\n            query,\n            exactly_one=True,\n            timeout=DEFAULT_SENTINEL,\n            proximity=None,\n            country=None,\n            bbox=None,\n    ):\n        \n        params = {}\n\n        params[] = self.api_key\n        query = self.format_string % query\n        if bbox:\n            params[] = self._format_bounding_box(\n                bbox, \"%(lon1)s,%(lat1)s,%(lon2)s,%(lat2)s\")\n\n        if not country:\n            country = []\n        if isinstance(country, string_compare):\n            country = [country]\n        if country:\n            params[] = \",\".join(country)\n\n        if proximity:\n            p = Point(proximity)\n            params[] = \"%s,%s\" % (p.longitude, p.latitude)\n\n        quoted_query = quote(query.encode())\n        url = \"?\".join((self.api % dict(query=quoted_query),\n                        urlencode(params)))\n        logger.debug(\"%s.geocode: %s\", self.__class__.__name__, url)\n\n        return self._parse_json(\n            self._call_geocoder(url, timeout=timeout)\n        )",
        "hard_negative_ids": [
            360,
            232,
            201,
            386,
            466,
            17,
            47,
            462,
            76,
            73,
            202,
            291,
            264,
            222,
            197,
            330,
            470,
            204,
            90,
            81,
            210,
            77,
            414,
            25,
            413,
            349,
            329,
            499,
            69,
            275,
            477,
            266,
            267,
            32,
            189,
            23,
            178,
            375,
            40,
            15,
            136,
            109,
            424,
            277,
            429,
            182,
            366,
            192,
            230,
            2
        ]
    },
    {
        "query": "NOTE: VERY SLOW!\n        Get a dictionary relating key:dataset to value:[tokens] that rely\n        on that dataset.\n\n        Arguments:\n            None\n\n        Returns:\n            dict: relating key:dataset to value:[tokens]",
        "positive_code": "def get_public_datasets_and_tokens(self):\n        \n        datasets = {}\n        tokens = self.get_public_tokens()\n        for t in tokens:\n            dataset = self.get_token_dataset(t)\n            if dataset in datasets:\n                datasets[dataset].append(t)\n            else:\n                datasets[dataset] = [t]\n        return datasets",
        "hard_negative_ids": [
            382,
            94,
            360,
            343,
            196,
            424,
            171,
            203,
            178,
            15,
            51,
            11,
            189,
            349,
            45,
            308,
            323,
            387,
            56,
            442,
            476,
            130,
            222,
            66,
            332,
            267,
            269,
            481,
            265,
            166,
            48,
            105,
            441,
            280,
            113,
            91,
            366,
            362,
            47,
            2,
            499,
            185,
            314,
            242,
            19,
            345,
            421,
            199,
            436,
            295
        ]
    },
    {
        "query": "Run a simple GPG-agent server.",
        "positive_code": "def run_agent(device_type):\n    \n    p = argparse.ArgumentParser()\n    p.add_argument(, default=os.environ.get())\n    p.add_argument(, , default=0, action=)\n    p.add_argument(, default=False, action=,\n                   help=)\n\n    p.add_argument(, type=str, default=,\n                   help=)\n    p.add_argument(, type=str, default=,\n                   help=)\n    p.add_argument(, type=float, default=float(),\n                   help=)\n\n    args, _ = p.parse_known_args()\n\n    assert args.homedir\n\n    log_file = os.path.join(args.homedir, )\n    util.setup_logging(verbosity=args.verbose, filename=log_file)\n\n    log.debug(, sys.argv)\n    log.debug(, os.environ)\n    log.debug(, os.getpid(), os.getppid())\n    try:\n        env = {: args.homedir, : os.environ[]}\n        pubkey_bytes = keyring.export_public_keys(env=env)\n        device_type.ui = device.ui.UI(device_type=device_type,\n                                      config=vars(args))\n        device_type.ui.cached_passphrase_ack = util.ExpiringCache(\n            seconds=float(args.cache_expiry_seconds))\n        handler = agent.Handler(device=device_type(),\n                                pubkey_bytes=pubkey_bytes)\n\n        sock_server = _server_from_assuan_fd(os.environ)\n        if sock_server is None:\n            sock_server = _server_from_sock_path(env)\n\n        with sock_server as sock:\n            for conn in agent.yield_connections(sock):\n                with contextlib.closing(conn):\n                    try:\n                        handler.handle(conn)\n                    except agent.AgentStop:\n                        log.info()\n                        return\n                    except IOError as e:\n                        log.info(, e)\n                        return\n                    except Exception as e:  \n                        log.exception(, e)\n\n    except Exception as e:  \n        log.exception(, e)",
        "hard_negative_ids": [
            370,
            376,
            35,
            391,
            451,
            228,
            106,
            304,
            216,
            181,
            453,
            178,
            157,
            317,
            425,
            438,
            322,
            360,
            171,
            256,
            15,
            462,
            349,
            9,
            472,
            201,
            76,
            470,
            236,
            277,
            382,
            466,
            222,
            289,
            95,
            268,
            435,
            1,
            245,
            56,
            17,
            416,
            77,
            361,
            175,
            240,
            379,
            292,
            439,
            272
        ]
    },
    {
        "query": "Add a type 3 segment to a C-kernel.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckw03_c.html\n\n    :param handle: Handle of an open CK file.\n    :type handle: int\n    :param begtim: The beginning encoded SCLK of the segment.\n    :type begtim: float\n    :param endtim: The ending encoded SCLK of the segment.\n    :type endtim: float\n    :param inst: The NAIF instrument ID code.\n    :type inst: int\n    :param ref: The reference frame of the segment.\n    :type ref: str\n    :param avflag: True if the segment will contain angular velocity.\n    :type avflag: bool\n    :param segid: Segment identifier.\n    :type segid: str\n    :param nrec: Number of pointing records.\n    :type nrec: int\n    :param sclkdp: Encoded SCLK times.\n    :type sclkdp: Array of floats\n    :param quats: Quaternions representing instrument pointing.\n    :type quats: Nx4-Element Array of floats\n    :param avvs: Angular velocity vectors.\n    :type avvs: Nx3-Element Array of floats\n    :param nints: Number of intervals.\n    :type nints: int\n    :param starts: Encoded SCLK interval start times.\n    :type starts: Array of floats",
        "positive_code": "def ckw03(handle, begtim, endtim, inst, ref, avflag, segid, nrec, sclkdp, quats,\n          avvs, nints, starts):\n    \n    handle = ctypes.c_int(handle)\n    begtim = ctypes.c_double(begtim)\n    endtim = ctypes.c_double(endtim)\n    inst = ctypes.c_int(inst)\n    ref = stypes.stringToCharP(ref)\n    avflag = ctypes.c_int(avflag)\n    segid = stypes.stringToCharP(segid)\n    sclkdp = stypes.toDoubleVector(sclkdp)\n    quats = stypes.toDoubleMatrix(quats)\n    avvs = stypes.toDoubleMatrix(avvs)\n    nrec = ctypes.c_int(nrec)\n    starts = stypes.toDoubleVector(starts)\n    nints = ctypes.c_int(nints)\n    libspice.ckw03_c(handle, begtim, endtim, inst, ref, avflag, segid, nrec,\n                     sclkdp, quats, avvs, nints, starts)",
        "hard_negative_ids": [
            348,
            165,
            81,
            429,
            232,
            256,
            403,
            490,
            500,
            88,
            197,
            360,
            414,
            466,
            137,
            117,
            12,
            433,
            300,
            349,
            171,
            56,
            296,
            97,
            461,
            391,
            142,
            252,
            204,
            23,
            268,
            450,
            361,
            318,
            344,
            210,
            222,
            264,
            339,
            105,
            69,
            470,
            100,
            275,
            73,
            279,
            291,
            202,
            207,
            17
        ]
    },
    {
        "query": "Gets a query from the data pipeline, which contains a request for multiple objects.\n\n        1) Extracts the query the sequence of data sources.\n        2) Inserts the results into the data sinks (if appropriate).\n        3) Transforms the results into the requested type if it wasn't already.\n        4) Inserts the transformed result into any data sinks.\n\n        Args:\n            query: The query being requested (contains a request for multiple objects).\n            context: The context for the extraction (mutable).\n            streaming: Specifies whether the results should be returned as a generator (default False).\n\n        Returns:\n            The requested objects or a generator of the objects if streaming is True.",
        "positive_code": "def get_many(self, type: Type[T], query: Mapping[str, Any], streaming: bool = False) -> Iterable[T]:\n        \n        LOGGER.info(\"Getting SourceHandlers for \\\"{type}\\\"\".format(type=type.__name__))\n        try:\n            handlers = self._get_types[type]\n        except KeyError:\n            try:\n                LOGGER.info(\"Building new SourceHandlers for \\\"{type}\\\"\".format(type=type.__name__))\n                handlers = self._get_handlers(type)\n            except NoConversionError:\n                handlers = None\n            self._get_types[type] = handlers\n\n        if handlers is None:\n            raise NoConversionError(\"No source can provide \\\"{type}\\\"\".format(type=type.__name__))\n\n        LOGGER.info(\"Creating new PipelineContext\")\n        context = self._new_context()\n\n        LOGGER.info(\"Querying SourceHandlers for \\\"{type}\\\"\".format(type=type.__name__))\n        for handler in handlers:\n            try:\n                return handler.get_many(query, context, streaming)\n            except NotFoundError:\n                pass\n\n        raise NotFoundError(\"No source returned a query result!\")",
        "hard_negative_ids": [
            360,
            223,
            79,
            269,
            383,
            421,
            466,
            423,
            280,
            129,
            470,
            232,
            243,
            424,
            222,
            197,
            297,
            5,
            291,
            73,
            185,
            179,
            414,
            201,
            330,
            491,
            244,
            33,
            452,
            113,
            139,
            32,
            462,
            77,
            324,
            147,
            182,
            438,
            425,
            226,
            402,
            151,
            168,
            329,
            174,
            193,
            41,
            429,
            178,
            498
        ]
    },
    {
        "query": "Register Generic Netlink family and associated commands.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/mngt.c#L164\n\n    Registers the specified Generic Netlink family definition together with all associated commands. After registration,\n    received Generic Netlink messages can be passed to genl_handle_msg() which will validate the messages, look for a\n    matching command and call the respective callback function automatically.\n\n    Positional arguments:\n    ops -- Generic Netlink family definition (genl_ops class instance).\n\n    Returns:\n    0 on success or a negative error code.",
        "positive_code": "def genl_register_family(ops):\n    \n    if not ops.o_name or (ops.o_cmds and ops.o_ncmds <= 0):\n        return -NLE_INVAL\n\n    if ops.o_id and lookup_family(ops.o_id):\n        return -NLE_EXIST\n\n    if lookup_family_by_name(ops.o_name):\n        return -NLE_EXIST\n\n    nl_list_add_tail(ops.o_list, genl_ops_list)\n\n    return 0",
        "hard_negative_ids": [
            207,
            500,
            404,
            444,
            269,
            455,
            391,
            265,
            360,
            291,
            297,
            296,
            453,
            264,
            429,
            73,
            488,
            262,
            359,
            462,
            76,
            42,
            166,
            69,
            16,
            472,
            414,
            256,
            23,
            219,
            146,
            466,
            255,
            361,
            301,
            142,
            457,
            382,
            201,
            376,
            339,
            210,
            275,
            162,
            252,
            88,
            235,
            317,
            197,
            260
        ]
    },
    {
        "query": "Update the entity record in the dictionary",
        "positive_code": "def update(self, model_obj):\n        \n        identifier = model_obj[self.entity_cls.meta_.id_field.field_name]\n        with self.conn[]:\n            \n            if identifier not in self.conn[][self.schema_name]:\n                raise ObjectNotFoundError(\n                    f\n                    f)\n\n            self.conn[][self.schema_name][identifier] = model_obj\n        return model_obj",
        "hard_negative_ids": [
            209,
            322,
            308,
            354,
            97,
            384,
            466,
            85,
            360,
            414,
            197,
            291,
            178,
            382,
            376,
            374,
            351,
            136,
            476,
            73,
            295,
            45,
            329,
            44,
            429,
            412,
            23,
            25,
            186,
            420,
            64,
            402,
            90,
            67,
            365,
            336,
            327,
            76,
            109,
            427,
            180,
            305,
            135,
            321,
            215,
            489,
            35,
            363,
            234,
            155
        ]
    },
    {
        "query": "Return a tuple of offsets of an ArrayRef object in all dimensions.\n\n        The index order is right to left (c-code order).\n        e.g. c[i+1][j-2] -> (-2, +1)\n\n        If aref is actually a c_ast.ID, None will be returned.",
        "positive_code": "def _get_offsets(self, aref, dim=0):\n        \n        if isinstance(aref, c_ast.ID):\n            return None\n\n        \n        assert type(aref.name) in [c_ast.ArrayRef, c_ast.ID], \\\n            \"array references must only be used with variables or other array references\"\n        assert type(aref.subscript) in [c_ast.ID, c_ast.Constant, c_ast.BinaryOp], \\\n            \n\n        \n        idxs = [self.conv_ast_to_sym(aref.subscript)]\n\n        \n        if type(aref.name) is c_ast.ArrayRef:\n            idxs += self._get_offsets(aref.name, dim=dim+1)\n\n        \n        if dim == 0:\n            idxs.reverse()\n\n        return tuple(idxs)",
        "hard_negative_ids": [
            79,
            256,
            462,
            470,
            296,
            210,
            464,
            149,
            245,
            88,
            360,
            197,
            466,
            77,
            162,
            232,
            317,
            347,
            160,
            349,
            18,
            414,
            339,
            78,
            490,
            300,
            307,
            472,
            391,
            429,
            99,
            182,
            413,
            374,
            58,
            12,
            73,
            230,
            493,
            76,
            4,
            240,
            105,
            304,
            53,
            279,
            101,
            165,
            450,
            272
        ]
    },
    {
        "query": "Smooth data with a moving average.",
        "positive_code": "def smooth(data, fw):\r\n    \r\n    if fw == 0:\r\n        fdata = data\r\n    else:\r\n        fdata = lfilter(np.ones(fw)/fw, 1, data)\r\n    return fdata",
        "hard_negative_ids": [
            83,
            279,
            421,
            223,
            391,
            498,
            256,
            106,
            33,
            195,
            357,
            304,
            85,
            424,
            154,
            440,
            163,
            283,
            492,
            453,
            484,
            393,
            178,
            78,
            324,
            317,
            425,
            252,
            360,
            170,
            171,
            15,
            22,
            141,
            466,
            96,
            470,
            434,
            74,
            269,
            59,
            382,
            439,
            468,
            397,
            383,
            128,
            285,
            404,
            462
        ]
    },
    {
        "query": "Encode the given value as JSON.\n\n        Args:\n          field: a messages.Field for the field we're encoding.\n          value: a value for field.\n\n        Returns:\n          A python value suitable for json.dumps.",
        "positive_code": "def encode_field(self, field, value):\n        \n        for encoder in _GetFieldCodecs(field, ):\n            result = encoder(field, value)\n            value = result.value\n            if result.complete:\n                return value\n        if isinstance(field, messages.EnumField):\n            if field.repeated:\n                remapped_value = [GetCustomJsonEnumMapping(\n                    field.type, python_name=e.name) or e.name for e in value]\n            else:\n                remapped_value = GetCustomJsonEnumMapping(\n                    field.type, python_name=value.name)\n            if remapped_value:\n                return remapped_value\n        if (isinstance(field, messages.MessageField) and\n                not isinstance(field, message_types.DateTimeField)):\n            value = json.loads(self.encode_message(value))\n        return super(_ProtoJsonApiTools, self).encode_field(field, value)",
        "hard_negative_ids": [
            441,
            287,
            8,
            428,
            262,
            488,
            91,
            56,
            278,
            73,
            267,
            19,
            242,
            360,
            382,
            332,
            481,
            15,
            349,
            166,
            429,
            247,
            106,
            377,
            304,
            366,
            362,
            434,
            414,
            413,
            1,
            216,
            222,
            11,
            484,
            391,
            424,
            41,
            269,
            199,
            466,
            342,
            376,
            317,
            219,
            392,
            453,
            407,
            182,
            178
        ]
    },
    {
        "query": "Sends and receives a message to/from the server",
        "positive_code": "def issue_command(self, cmd, *args):\n    \n    self._writeline(cmd)\n    self._writeline(str(len(args)))\n    for arg in args:\n      arg = str(arg)\n      self._writeline(str(len(arg)))\n      self._sock.sendall(arg.encode(\"utf-8\"))\n\n    return self._read_response()",
        "hard_negative_ids": [
            376,
            488,
            262,
            301,
            360,
            264,
            37,
            391,
            131,
            73,
            414,
            327,
            429,
            171,
            291,
            466,
            69,
            228,
            106,
            207,
            317,
            304,
            457,
            462,
            500,
            197,
            275,
            193,
            382,
            453,
            178,
            7,
            26,
            265,
            23,
            159,
            295,
            425,
            361,
            185,
            76,
            367,
            296,
            136,
            11,
            269,
            15,
            349,
            222,
            162
        ]
    },
    {
        "query": "Parse color syntax from a formatted string.",
        "positive_code": "def parse(self, format_string):\n        \n        txt, state = , 0\n        colorstack = [(None, None)]\n        itokens = self.tokenize(format_string)\n\n        for token, escaped in itokens:\n            if token == self._START_TOKEN and not escaped:\n                if txt:\n                    yield txt, colorstack[-1]\n                    txt = \n\n                state += 1\n                colors = self.extract_syntax(colorise.compat.next(itokens)[0])\n                colorstack.append(tuple(b or a\n                                        for a, b in zip(colorstack[-1],\n                                                        colors)))\n            elif token == self._FMT_TOKEN and not escaped:\n                \n                \n                \n\n                if state % 2 != 0:\n                    state += 1\n                else:\n                    txt += token\n            elif token == self._STOP_TOKEN and not escaped:\n                if state < 2:\n                    raise ColorSyntaxError(\"Missing  or \"\n                                           .format(self._STOP_TOKEN,\n                                                   self._FMT_TOKEN))\n\n                if txt:\n                    yield txt, colorstack[-1]\n                    txt = \n\n                state -= 2\n                colorstack.pop()\n            else:\n                txt += token\n\n        if state != 0:\n            raise ColorSyntaxError(\"Invalid color format\")\n\n        if txt:\n            yield txt, colorstack[-1]",
        "hard_negative_ids": [
            210,
            413,
            40,
            342,
            480,
            178,
            310,
            47,
            106,
            304,
            391,
            73,
            193,
            453,
            7,
            26,
            317,
            425,
            311,
            367,
            360,
            131,
            11,
            171,
            15,
            69,
            300,
            153,
            67,
            470,
            185,
            256,
            382,
            147,
            231,
            462,
            208,
            343,
            222,
            349,
            472,
            76,
            99,
            466,
            180,
            272,
            23,
            474,
            473,
            471
        ]
    },
    {
        "query": "Construct the input file of the calculation.",
        "positive_code": "def make_input(self, with_header=False):\n        \n        s = str(self.input)\n        if with_header: s = str(self) + \"\\n\" + s\n        return s",
        "hard_negative_ids": [
            429,
            496,
            197,
            466,
            414,
            360,
            171,
            363,
            44,
            291,
            185,
            23,
            136,
            73,
            349,
            395,
            470,
            232,
            467,
            376,
            25,
            1,
            144,
            169,
            318,
            277,
            275,
            157,
            264,
            109,
            272,
            289,
            99,
            20,
            19,
            18,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            469,
            468,
            465,
            464
        ]
    },
    {
        "query": "Update routine for the Firewall.\n\n        Check if FW is already cfgd using the below function\n        if self.fwid_attr[tenant_id].is_fw_complete() or\n        is_fw_drvr_create_needed():\n        The above two functions will take care of whether FW is already\n        cfgd or about to be cfgd in case of error.\n        If yes, this may be a change in policies attached to FW.\n        If no, do a check, create after storing the parameters like\n        rtr_id.",
        "positive_code": "def _fw_update(self, drvr_name, data):\n        \n        fw = data.get()\n        tenant_id = fw.get()\n        if self.fwid_attr[tenant_id].is_fw_complete() or \\\n           self.fwid_attr[tenant_id].is_fw_drvr_create_needed():\n            prev_info_complete = True\n        else:\n            prev_info_complete = False\n\n        tenant_obj = self.fwid_attr[tenant_id]\n        if  in fw and len(fw.get()) != 0:\n            rtr_id = fw.get()[0]\n            name = dfa_dbm.DfaDBMixin.get_project_name(self, tenant_id)\n            rtr_name = .join([fw_constants.TENANT_EDGE_RTR, name])\n\n            fw_rtr_name = self.os_helper.get_rtr_name(rtr_id)\n            fw_type = None\n            if fw_rtr_name == rtr_name:\n                fw_type = fw_constants.FW_TENANT_EDGE\n            tenant_obj.update_fw_params(rtr_id, fw_type)\n\n        if not prev_info_complete:\n            self._check_create_fw(tenant_id, drvr_name)",
        "hard_negative_ids": [
            197,
            360,
            425,
            291,
            201,
            466,
            73,
            235,
            328,
            42,
            232,
            189,
            136,
            185,
            166,
            439,
            470,
            414,
            325,
            472,
            23,
            349,
            329,
            171,
            295,
            429,
            304,
            89,
            382,
            196,
            459,
            462,
            109,
            391,
            170,
            106,
            142,
            44,
            275,
            47,
            199,
            85,
            264,
            266,
            386,
            76,
            90,
            192,
            203,
            182
        ]
    },
    {
        "query": "Pass through to provider AssetRepositorySession.use_plenary_repository_view",
        "positive_code": "def use_plenary_repository_view(self):\n        \n        self._repository_view = PLENARY\n        \n        for session in self._get_provider_sessions():\n            try:\n                session.use_plenary_repository_view()\n            except AttributeError:\n                pass",
        "hard_negative_ids": [
            331,
            126,
            269,
            93,
            275,
            171,
            131,
            368,
            376,
            295,
            370,
            414,
            264,
            189,
            73,
            74,
            360,
            324,
            47,
            297,
            378,
            41,
            76,
            266,
            157,
            121,
            329,
            291,
            162,
            466,
            97,
            99,
            283,
            64,
            109,
            239,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469
        ]
    },
    {
        "query": "Updates a suite of hypotheses based on new data.\n\n        Modifies the suite directly; if you want to keep the original, make\n        a copy.\n\n        Note: unlike Update, LogUpdate does not normalize.\n\n        Args:\n            data: any representation of the data",
        "positive_code": "def LogUpdate(self, data):\n        \n        for hypo in self.Values():\n            like = self.LogLikelihood(data, hypo)\n            self.Incr(hypo, like)",
        "hard_negative_ids": [
            466,
            269,
            136,
            360,
            82,
            421,
            85,
            324,
            197,
            223,
            256,
            498,
            414,
            470,
            349,
            287,
            429,
            295,
            33,
            195,
            404,
            488,
            424,
            357,
            41,
            76,
            171,
            73,
            420,
            154,
            189,
            440,
            219,
            106,
            283,
            304,
            391,
            291,
            492,
            147,
            499,
            484,
            393,
            112,
            23,
            351,
            78,
            174,
            178,
            232
        ]
    },
    {
        "query": "Wait until the approval is valid (i.e. - approved).\n\n    Args:\n      timeout: timeout in seconds. None means default timeout (1 hour).\n               0 means no timeout (wait forever).\n    Returns:\n      Operation object with refreshed target_file.\n    Raises:\n      PollTimeoutError: if timeout is reached.",
        "positive_code": "def WaitUntilValid(self, timeout=None):\n    \n\n    return utils.Poll(\n        generator=self.Get,\n        condition=lambda f: f.data.is_valid,\n        timeout=timeout)",
        "hard_negative_ids": [
            230,
            473,
            348,
            248,
            79,
            37,
            168,
            433,
            330,
            405,
            147,
            424,
            324,
            297,
            84,
            306,
            197,
            245,
            269,
            291,
            41,
            29,
            287,
            434,
            320,
            203,
            429,
            488,
            266,
            413,
            112,
            414,
            219,
            47,
            222,
            316,
            179,
            135,
            327,
            76,
            53,
            109,
            68,
            307,
            466,
            254,
            81,
            385,
            317,
            88
        ]
    },
    {
        "query": "Emit the signal.",
        "positive_code": "def emit(self, object, *args):\n\t\t\n\t\tfor cb in self.map.get(object, []):\n\t\t\tcb(*args)",
        "hard_negative_ids": [
            372,
            10,
            314,
            360,
            197,
            414,
            291,
            466,
            136,
            73,
            429,
            44,
            23,
            25,
            109,
            30,
            29,
            28,
            27,
            26,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457
        ]
    },
    {
        "query": "Service triggered each time an item is iterated in folderitems.\n\n        The use of this service prevents the extra-loops in child objects.\n\n        :obj: the instance of the class to be foldered\n        :item: dict containing the properties of the object to be used by\n            the template\n        :index: current index of the item",
        "positive_code": "def folderitem(self, obj, item, index):\n        \n        \n        obj = api.get_object(obj)\n        uid = api.get_uid(obj)\n        url = api.get_url(obj)\n        title = api.get_title(obj)\n\n        \n        if self.show_categories_enabled():\n            category = obj.getCategoryTitle()\n            if category not in self.categories:\n                self.categories.append(category)\n            item[\"category\"] = category\n\n        item[\"replace\"][\"Title\"] = get_link(url, value=title)\n        item[\"selected\"] = False\n        item[\"selected\"] = uid in self.selected_services_uids\n\n        \n        methods = obj.getMethods()\n        if methods:\n            links = map(\n                lambda m: get_link(\n                    m.absolute_url(), value=m.Title(), css_class=\"link\"),\n                methods)\n            item[\"replace\"][\"Methods\"] = \", \".join(links)\n        else:\n            item[\"methods\"] = \"\"\n\n        calculation = obj.getCalculation()\n        if calculation:\n            title = calculation.Title()\n            url = calculation.absolute_url()\n            item[\"Calculation\"] = title\n            item[\"replace\"][\"Calculation\"] = get_link(url, value=title)\n        else:\n            item[\"Calculation\"] = \"\"\n\n        \n        after_icons = \"\"\n        if obj.getAccredited():\n            after_icons += get_image(\n                \"accredited.png\", title=_(\"Accredited\"))\n        if obj.getAttachmentOption() == \"r\":\n            after_icons += get_image(\n                \"attach_reqd.png\", title=_(\"Attachment required\"))\n        if obj.getAttachmentOption() == \"n\":\n            after_icons += get_image(\n                \"attach_no.png\", title=_(\"Attachment not permitted\"))\n        if after_icons:\n            item[\"after\"][\"Title\"] = after_icons\n\n        return item",
        "hard_negative_ids": [
            79,
            470,
            466,
            414,
            291,
            78,
            360,
            23,
            85,
            25,
            232,
            197,
            47,
            269,
            287,
            76,
            493,
            133,
            388,
            325,
            73,
            305,
            8,
            189,
            383,
            429,
            222,
            192,
            202,
            31,
            236,
            333,
            439,
            297,
            329,
            347,
            59,
            349,
            118,
            277,
            199,
            233,
            113,
            279,
            122,
            219,
            272,
            2,
            382,
            198
        ]
    },
    {
        "query": "stop subscriber",
        "positive_code": "def on_stop(self):\n        \n        LOGGER.debug(\"zeromq.Subscriber.on_stop\")\n        self.running = False\n        while self.is_started:\n            time.sleep(0.1)\n        self.zmqsocket.close()\n        self.zmqcontext.destroy()",
        "hard_negative_ids": [
            175,
            10,
            16,
            17,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453,
            452,
            451
        ]
    },
    {
        "query": "Populate the ``595`` MARC key.\n\n    Also populates the `595_H` MARC key through side effects.",
        "positive_code": "def _private_notes2marc(self, key, value):\n    \n    def _is_from_hal(value):\n        return value.get() == \n\n    if not _is_from_hal(value):\n        return {\n            : value.get(),\n            : value.get(),\n        }\n\n    self.setdefault(, []).append({: value.get()})",
        "hard_negative_ids": [
            196,
            45,
            476,
            387,
            442,
            48,
            360,
            197,
            414,
            436,
            11,
            113,
            291,
            466,
            15,
            136,
            73,
            124,
            179,
            105,
            222,
            429,
            44,
            345,
            96,
            382,
            384,
            23,
            25,
            64,
            490,
            36,
            353,
            327,
            230,
            76,
            109,
            477,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464,
            463
        ]
    },
    {
        "query": "Construct end-of-rib (EOR) Update instance.",
        "positive_code": "def create_end_of_rib_update():\n    \n    mpunreach_attr = BGPPathAttributeMpUnreachNLRI(RF_IPv4_VPN.afi,\n                                                   RF_IPv4_VPN.safi,\n                                                   [])\n    eor = BGPUpdate(path_attributes=[mpunreach_attr])\n    return eor",
        "hard_negative_ids": [
            493,
            269,
            268,
            278,
            349,
            80,
            82,
            219,
            485,
            466,
            85,
            333,
            351,
            412,
            295,
            45,
            476,
            395,
            470,
            67,
            232,
            429,
            64,
            186,
            76,
            318,
            420,
            197,
            157,
            90,
            402,
            95,
            336,
            435,
            1,
            245,
            56,
            472,
            17,
            327,
            416,
            77,
            361,
            391,
            175,
            272,
            240,
            379,
            292,
            439
        ]
    },
    {
        "query": "Login to Todoist.\n\n    :param email: A Todoist user's email address.\n    :type email: str\n    :param password: A Todoist user's password.\n    :type password: str\n    :return: The Todoist user.\n    :rtype: :class:`pytodoist.todoist.User`\n\n    >>> from pytodoist import todoist\n    >>> user = todoist.login('john.doe@gmail.com', 'password')\n    >>> print(user.full_name)\n    John Doe",
        "positive_code": "def login(email, password):\n    \n    user = _login(API.login, email, password)\n    user.password = password\n    return user",
        "hard_negative_ids": [
            55,
            425,
            200,
            52,
            131,
            187,
            76,
            251,
            171,
            173,
            103,
            81,
            360,
            415,
            293,
            112,
            178,
            159,
            232,
            189,
            197,
            135,
            265,
            379,
            393,
            367,
            239,
            23,
            222,
            204,
            279,
            143,
            73,
            15,
            77,
            386,
            193,
            106,
            344,
            275,
            7,
            300,
            490,
            304,
            266,
            26,
            185,
            391,
            414,
            429
        ]
    },
    {
        "query": "Perform the reciprocal space summation. Calculates the quantity\n        E_recip = 1/(2PiV) sum_{G < Gmax} exp(-(G.G/4/eta))/(G.G) S(G)S(-G)\n        where\n        S(G) = sum_{k=1,N} q_k exp(-i G.r_k)\n        S(G)S(-G) = |S(G)|**2\n\n        This method is heavily vectorized to utilize numpy's C backend for\n        speed.",
        "positive_code": "def _calc_recip(self):\n        \n        numsites = self._s.num_sites\n        prefactor = 2 * pi / self._vol\n        erecip = np.zeros((numsites, numsites), dtype=np.float)\n        forces = np.zeros((numsites, 3), dtype=np.float)\n        coords = self._coords\n        rcp_latt = self._s.lattice.reciprocal_lattice\n        recip_nn = rcp_latt.get_points_in_sphere([[0, 0, 0]], [0, 0, 0],\n                                                 self._gmax)\n\n        frac_coords = [fcoords for (fcoords, dist, i, img) in recip_nn if dist != 0]\n\n        gs = rcp_latt.get_cartesian_coords(frac_coords)\n        g2s = np.sum(gs ** 2, 1)\n        expvals = np.exp(-g2s / (4 * self._eta))\n        grs = np.sum(gs[:, None] * coords[None, :], 2)\n\n        oxistates = np.array(self._oxi_states)\n\n        \n        qiqj = oxistates[None, :] * oxistates[:, None]\n\n        \n        sreals = np.sum(oxistates[None, :] * np.cos(grs), 1)\n        simags = np.sum(oxistates[None, :] * np.sin(grs), 1)\n\n        for g, g2, gr, expval, sreal, simag in zip(gs, g2s, grs, expvals,\n                                                   sreals, simags):\n\n            \n            m = (gr[None, :] + pi / 4) - gr[:, None]\n            np.sin(m, m)\n            m *= expval / g2\n\n            erecip += m\n\n            if self._compute_forces:\n                pref = 2 * expval / g2 * oxistates\n                factor = prefactor * pref * (\n                    sreal * np.sin(gr) - simag * np.cos(gr))\n\n                forces += factor[:, None] * g[None, :]\n\n        forces *= EwaldSummation.CONV_FACT\n        erecip *= prefactor * EwaldSummation.CONV_FACT * qiqj * 2 ** 0.5\n        return erecip, forces",
        "hard_negative_ids": [
            462,
            18,
            4,
            429,
            149,
            440,
            296,
            159,
            41,
            77,
            90,
            391,
            472,
            414,
            350,
            53,
            197,
            386,
            500,
            256,
            466,
            160,
            162,
            323,
            487,
            368,
            245,
            109,
            190,
            201,
            133,
            207,
            210,
            88,
            361,
            17,
            450,
            182,
            44,
            275,
            152,
            328,
            70,
            101,
            464,
            107,
            240,
            271,
            95,
            139
        ]
    },
    {
        "query": "Creates a new :class:`ConstantDouble`, adding it to the pool and\n        returning it.\n\n        :param value: The value of the new Double.",
        "positive_code": "def create_double(self, value: float) -> Double:\n        \n        self.append((6, value))\n        self.append(None)\n        return self.get(self.raw_count - 2)",
        "hard_negative_ids": [
            82,
            349,
            360,
            466,
            56,
            177,
            368,
            375,
            197,
            414,
            81,
            332,
            267,
            481,
            382,
            166,
            232,
            441,
            424,
            73,
            291,
            15,
            366,
            429,
            362,
            91,
            76,
            69,
            11,
            470,
            242,
            19,
            171,
            58,
            204,
            222,
            199,
            106,
            136,
            344,
            182,
            304,
            272,
            280,
            391,
            149,
            300,
            23,
            179,
            253
        ]
    },
    {
        "query": "report current export state status",
        "positive_code": "def status(config, group, accounts=(), region=None):\n    \n    config = validate.callback(config)\n    destination = config.get()\n    client = boto3.Session().client()\n\n    for account in config.get(, ()):\n        if accounts and account[] not in accounts:\n            continue\n\n        session = get_session(account[], region)\n        account_id = session.client().get_caller_identity()[]\n        prefix = destination.get(, ).rstrip() +  % account_id\n        prefix = \"%s/flow-log\" % prefix\n\n        role = account.pop()\n        if isinstance(role, six.string_types):\n            account[] = role.split()[4]\n        else:\n            account[] = role[-1].split()[4]\n\n        account.pop()\n\n        try:\n            tag_set = client.get_object_tagging(\n                Bucket=destination[], Key=prefix).get(, [])\n        except ClientError:\n            account[] = \n            continue\n        tags = {t[]: t[] for t in tag_set}\n\n        if  not in tags:\n            account[] = \n        else:\n            last_export = parse(tags[])\n            account[] = last_export.strftime()\n\n    accounts = [a for a in config.get() if a in accounts or not accounts]\n    accounts.sort(key=operator.itemgetter(), reverse=True)\n    print(tabulate(accounts, headers=))",
        "hard_negative_ids": [
            161,
            376,
            325,
            217,
            202,
            410,
            465,
            360,
            466,
            185,
            285,
            336,
            105,
            352,
            179,
            97,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457
        ]
    },
    {
        "query": "Read a specified object, using a struct format string.",
        "positive_code": "def readfmt(self, fmt):\n        \n        size = struct.calcsize(fmt)\n        blob = self.read(size)\n        obj, = struct.unpack(fmt, blob)\n        return obj",
        "hard_negative_ids": [
            166,
            210,
            413,
            79,
            40,
            48,
            342,
            470,
            449,
            360,
            141,
            228,
            106,
            304,
            300,
            391,
            73,
            459,
            453,
            356,
            478,
            178,
            317,
            425,
            297,
            15,
            81,
            171,
            318,
            256,
            291,
            222,
            58,
            113,
            349,
            479,
            169,
            382,
            23,
            466,
            264,
            462,
            163,
            206,
            472,
            45,
            353,
            327,
            326,
            275
        ]
    },
    {
        "query": "In systems without a UTF8 locale configured, Python will default to\n    ASCII mode for stdout and stderr. This causes our fancy display to fail\n    with encoding errors. In particular, you run into this if you try to run\n    peru inside of Docker. This is a hack to force emitting UTF8 in that case.\n    Hopefully it doesn't break anything important.",
        "positive_code": "def force_utf8_in_ascii_mode_hack():\n    t break anything important.ANSI_X3.4-1968wutf8wutf8', buffering=1)",
        "hard_negative_ids": [
            431,
            360,
            269,
            275,
            189,
            181,
            262,
            413,
            47,
            368,
            466,
            216,
            280,
            90,
            168,
            424,
            69,
            173,
            349,
            435,
            141,
            76,
            171,
            38,
            306,
            84,
            414,
            1,
            252,
            304,
            370,
            405,
            391,
            106,
            451,
            236,
            470,
            201,
            174,
            264,
            291,
            392,
            136,
            237,
            407,
            185,
            297,
            462,
            97,
            131
        ]
    },
    {
        "query": "Add a sample to this series.",
        "positive_code": "def add_sample(self, **data):\n        \n        missing_dimensions = set(data).difference(self.dimensions)\n\n        if missing_dimensions:\n            raise KeyError(\n                           % .join(missing_dimensions))\n\n        for dim in self.dimensions:\n            getattr(self, dim).append(data.get(dim))",
        "hard_negative_ids": [
            453,
            218,
            215,
            189,
            171,
            360,
            47,
            106,
            44,
            304,
            391,
            414,
            90,
            272,
            289,
            275,
            178,
            317,
            425,
            269,
            15,
            239,
            131,
            76,
            127,
            368,
            376,
            470,
            295,
            264,
            256,
            73,
            382,
            466,
            192,
            462,
            222,
            349,
            472,
            266,
            157,
            329,
            99,
            180,
            109,
            23,
            478,
            477,
            476,
            475
        ]
    },
    {
        "query": "Determine what the field link should be for the given field, object pair",
        "positive_code": "def get_field_link(context, field, obj=None):\n    \n    view = context[]\n    return view.lookup_field_link(context, field, obj)",
        "hard_negative_ids": [
            92,
            21,
            8,
            79,
            291,
            73,
            278,
            213,
            470,
            466,
            360,
            462,
            232,
            414,
            192,
            197,
            182,
            297,
            386,
            136,
            109,
            23,
            113,
            429,
            44,
            81,
            382,
            99,
            25,
            97,
            180,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            133
        ]
    },
    {
        "query": "Simple wrapper of model.fit.\n\n        :param inputs: Inputs.\n        :param outputs: List of forward and backward outputs.\n        :param epochs: Number of epoch.\n\n        :return: None",
        "positive_code": "def fit(self, inputs, outputs, epochs=1):\n        \n        self.model.fit(inputs, outputs, epochs=epochs)",
        "hard_negative_ids": [
            252,
            81,
            152,
            419,
            142,
            89,
            333,
            112,
            344,
            204,
            489,
            496,
            430,
            198,
            429,
            349,
            297,
            425,
            41,
            300,
            330,
            376,
            324,
            395,
            232,
            136,
            470,
            227,
            273,
            185,
            466,
            9,
            318,
            467,
            197,
            34,
            343,
            490,
            328,
            477,
            327,
            157,
            77,
            272,
            2,
            410,
            275,
            24,
            424,
            267
        ]
    },
    {
        "query": "Output a voltage from the pin\n\n        :arg value: Uses value as a boolean if the pin is in output mode, or\n            expects a float from 0 to 1 if the pin is in PWM mode. If the pin\n            is in SERVO the value should be in degrees.",
        "positive_code": "def write(self, value):\n        \n        if self.mode is UNAVAILABLE:\n            raise IOError(\"{0} can not be used through Firmata\".format(self))\n        if self.mode is INPUT:\n            raise IOError(\"{0} is set up as an INPUT and can therefore not be written to\"\n                          .format(self))\n        if value is not self.value:\n            self.value = value\n            if self.mode is OUTPUT:\n                if self.port:\n                    self.port.write()\n                else:\n                    msg = bytearray([DIGITAL_MESSAGE, self.pin_number, value])\n                    self.board.sp.write(msg)\n            elif self.mode is PWM:\n                value = int(round(value * 255))\n                msg = bytearray([ANALOG_MESSAGE + self.pin_number, value % 128, value >> 7])\n                self.board.sp.write(msg)\n            elif self.mode is SERVO:\n                value = int(value)\n                msg = bytearray([ANALOG_MESSAGE + self.pin_number, value % 128, value >> 7])\n                self.board.sp.write(msg)",
        "hard_negative_ids": [
            56,
            368,
            136,
            360,
            382,
            291,
            182,
            414,
            38,
            349,
            466,
            11,
            232,
            73,
            376,
            462,
            332,
            23,
            267,
            15,
            91,
            275,
            304,
            481,
            197,
            171,
            109,
            222,
            391,
            192,
            166,
            245,
            75,
            106,
            441,
            425,
            227,
            34,
            252,
            19,
            242,
            424,
            366,
            9,
            362,
            470,
            386,
            317,
            131,
            178
        ]
    },
    {
        "query": "Makes forecast with the estimated model\n\n        Parameters\n        ----------\n        h : int (default : 5)\n            How many steps ahead would you like to forecast?\n\n        past_values : int (default : 20)\n            How many past observations to show on the forecast graph?\n\n        intervals : Boolean\n            Would you like to show 95% prediction intervals for the forecast?\n\n        Returns\n        ----------\n        - Plot of the forecast",
        "positive_code": "def plot_predict(self,h=5,past_values=20,intervals=True,**kwargs):      \n        \n        import matplotlib.pyplot as plt\n        import seaborn as sns\n\n        figsize = kwargs.get(,(10,7))\n\n        if self.latent_variables.estimated is False:\n            raise Exception(\"No latent variables estimated!\")\n        else:\n            \n            scale, shape, skewness = self._get_scale_and_shape(self.latent_variables.get_z_values(transformed=True))\n            previous_value = self.data[-1]  \n            forecasted_values = np.ones(h)*self.states[-1]  \n            date_index = self.shift_dates(h)\n            simulations = 10000\n            sim_vector = np.zeros([simulations,h])\n            t_params = self.transform_z()\n\n            for n in range(0,simulations):  \n                rnd_q = np.random.normal(0,np.sqrt(self.latent_variables.get_z_values(transformed=True)[0]),h) \n                exp = forecasted_values.copy()\n\n                for t in range(0,h):\n                    if t == 0:\n                        exp[t] = forecasted_values[t] + rnd_q[t]\n                    else:\n                        exp[t] = exp[t-1] + rnd_q[t]\n\n                sim_vector[n] = self.family.draw_variable(loc=self.link(exp),shape=shape,scale=scale,skewness=skewness,nsims=exp.shape[0])\n\n            sim_vector = np.transpose(sim_vector)\n\n            forecasted_values = self.link(forecasted_values)\n\n            if self.model_name2 == :\n                forecasted_values = forecasted_values + ((t_params[-3] - (1.0/t_params[-3]))*t_params[-2]*gas.SkewtScore.tv_variate_exp(t_params[-1]))\n\n            plt.figure(figsize=figsize) \n\n            if intervals == True:\n                plt.fill_between(date_index[-h-1:], np.insert([np.percentile(i,5) for i in sim_vector],0,previous_value), \n                    np.insert([np.percentile(i,95) for i in sim_vector],0,previous_value), alpha=0.2,label=\"95 C.I.\")   \n\n            plot_values = np.append(self.data[-past_values:],forecasted_values)\n            plot_index = date_index[-h-past_values:]\n\n            plt.plot(plot_index,plot_values,label=self.data_name)\n            plt.title(\"Forecast for \" + self.data_name)\n            plt.xlabel(\"Time\")\n            plt.ylabel(self.data_name)\n            plt.show()",
        "hard_negative_ids": [
            466,
            168,
            414,
            360,
            424,
            460,
            136,
            269,
            76,
            489,
            306,
            47,
            260,
            84,
            89,
            197,
            383,
            198,
            416,
            405,
            189,
            73,
            333,
            386,
            285,
            429,
            291,
            175,
            239,
            499,
            467,
            101,
            58,
            228,
            349,
            33,
            268,
            1,
            235,
            183,
            361,
            173,
            329,
            275,
            25,
            17,
            130,
            252,
            109,
            152
        ]
    },
    {
        "query": "Creates a network of the objects found by all tags in _tags_, each node is marked by which tag spawned it making the resultant graph n-partite.\n\n        A **networkMultiMode()** looks are each item in the collection and extracts its values for the tags given by _tags_. Then for all objects returned an edge is created between them, regardless of their type. Each node will have an attribute call `'type'` that gives the tag that created it or both if both created it, e.g. if `'LA'` were in _tags_ node `'English'` would have the type attribute be `'LA'`.\n\n        For example if _tags_ was set to `['CR', 'UT', 'LA']`, a three mode network would be created, composed of a co-citation network from the `'CR'` tag. Then each citation would also have edges to all the languages of Records that cited it and to the WOS number of the those Records.\n\n        The number of times each object occurs is count if _nodeCount_ is `True` and the edges count the number of co-occurrences if _edgeWeight_ is `True`. Both are`True` by default.\n\n        # Parameters\n\n        _tags_ : `str`, `str`, `str`, ... or `list [str]`\n\n        > Any number of tags, or a list of tags\n\n        _nodeCount_ : `optional [bool]`\n\n        > Default `True`, if `True` each node will have an attribute called `'count'` that contains an int giving the number of time the object occurred.\n\n        _edgeWeight_ : `optional [bool]`\n\n        > Default `True`, if `True` each edge will have an attribute called `'weight'` that contains an int giving the number of time the two objects co-occurrenced.\n\n        _stemmer_ : `optional [func]`\n\n        > Default `None`, If _stemmer_ is a callable object, basically a function or possibly a class, it will be called for the ID of every node in the graph, note that all IDs are strings.\n\n        > For example: the function `f = lambda x: x[0]` if given as the stemmer will cause all IDs to be the first character of their unstemmed IDs. e.g. the title `'Goos-Hanchen and Imbert-Fedorov shifts for leaky guided modes'` will create the node `'G'`.\n\n        # Returns\n\n        `networkx Graph`\n\n        > A networkx Graph with the objects of the tags _tags_ as nodes and their co-occurrences as edges",
        "positive_code": "def networkMultiMode(self, *tags, recordType = True, nodeCount = True, edgeWeight = True, stemmer = None, edgeAttribute = None):\n        \n        if len(tags) == 1:\n            if not isinstance(tags[0], str):\n                try:\n                    tags = list(tags[0])\n                except TypeError:\n                    raise TagError(\" is not a string it cannot be a tag.\".format(tags[0]))\n        for t in (i for i in tags if not isinstance(i, str)):\n            raise TagError(\"{} is not a string it cannot be a tag.\".format(t))\n        stemCheck = False\n        if stemmer is not None:\n            if isinstance(stemmer, collections.abc.Callable):\n                stemCheck = True\n            else:\n                raise TagError(\"stemmer must be Callable, e.g. a function or class with a __call__ method.\")\n        count = 0\n        progArgs = (0, \"Starting to make a \" + str(len(tags)) + \"-mode network of: \" + .join(tags))\n        if metaknowledge.VERBOSE_MODE:\n            progKwargs = { : False}\n        else:\n            progKwargs = { : True}\n        with _ProgressBar(*progArgs, **progKwargs) as PBar:\n            if edgeAttribute is not None:\n                grph = nx.MultiGraph()\n            else:\n                grph = nx.Graph()\n            for R in self:\n                if PBar:\n                    count += 1\n                    PBar.updateVal(count / len(self), \"Analyzing: \" + str(R))\n                contents = []\n                for t in tags:\n                    tmpVal = R.get(t)\n                    if stemCheck:\n                        if tmpVal:\n                            if isinstance(tmpVal, list):\n                                contents.append((t, [stemmer(str(v)) for v in tmpVal]))\n                            else:\n                                contents.append((t, [stemmer(str(tmpVal))]))\n                    else:\n                        if tmpVal:\n                            if isinstance(tmpVal, list):\n                                contents.append((t, [str(v) for v in tmpVal]))\n                            else:\n                                contents.append((t, [str(tmpVal)]))\n                for i, vlst1 in enumerate(contents):\n                    for node1 in vlst1[1]:\n                        for vlst2 in contents[i + 1:]:\n                            for node2 in vlst2[1]:\n                                if edgeAttribute:\n                                    for edgeVal in edgeVals:\n                                        if grph.has_edge(node1, node2, key = edgeVal):\n                                            if edgeWeight:\n                                                for i, a in grph.edges[node1, node2].items():\n                                                    if a[] == edgeVal:\n                                                        grph[node1][node2][i][] += 1\n                                                        break\n                                        else:\n                                            if edgeWeight:\n                                                attrDict = { : edgeVal,  : 1}\n                                            else:\n                                                attrDict = { : edgeVal}\n                                            grph.add_edge(node1, node2, **attrDict)\n                                elif edgeWeight:\n                                    try:\n                                        grph.edges[node1, node2][] += 1\n                                    except KeyError:\n                                        grph.add_edge(node1, node2, weight = 1)\n                                else:\n                                    if not grph.has_edge(node1, node2):\n                                        grph.add_edge(node1, node2)\n                        if nodeCount:\n                            try:\n                                grph.node[node1][] += 1\n                            except KeyError:\n                                try:\n                                    grph.node[node1][] = 1\n                                    if recordType:\n                                        grph.node[node1][] = vlst1[0]\n                                except KeyError:\n                                    if recordType:\n                                        grph.add_node(node1, type = vlst1[0])\n                                    else:\n                                        grph.add_node(node1)\n                        else:\n                            if not grph.has_node(node1):\n                                if recordType:\n                                    grph.add_node(node1, type = vlst1[0])\n                                else:\n                                    grph.add_node(node1)\n                            elif recordType:\n                                try:\n                                    grph.node[node1][] += vlst1[0]\n                                except KeyError:\n                                    grph.node[node1][] = vlst1[0]\n            if PBar:\n                PBar.finish(\"Done making a {}-mode network of: {}\".format(len(tags), .join(tags)))\n        return grph",
        "hard_negative_ids": [
            379,
            291,
            91,
            360,
            142,
            149,
            311,
            76,
            424,
            23,
            462,
            235,
            18,
            73,
            287,
            25,
            232,
            105,
            466,
            429,
            252,
            79,
            119,
            414,
            475,
            217,
            197,
            42,
            470,
            349,
            297,
            109,
            189,
            8,
            174,
            268,
            39,
            85,
            69,
            435,
            1,
            113,
            329,
            222,
            490,
            272,
            168,
            460,
            293,
            404
        ]
    },
    {
        "query": "/",
        "positive_code": "def QA_fetch_stock_xdxr(code, format=, collections=DATABASE.stock_xdxr):\n    \n    code = QA_util_code_tolist(code)\n    data = pd.DataFrame([item for item in collections.find(\n        {:  {: code}}, batch_size=10000)]).drop([], axis=1)\n    data[] = pd.to_datetime(data[])\n    return data.set_index(, drop=False)",
        "hard_negative_ids": [
            207,
            457,
            500,
            429,
            265,
            159,
            361,
            391,
            162,
            69,
            177,
            388,
            296,
            88,
            350,
            95,
            160,
            382,
            464,
            317,
            387,
            462,
            206,
            71,
            426,
            12,
            222,
            291,
            275,
            472,
            345,
            100,
            181,
            109,
            23,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471,
            470,
            469,
            468
        ]
    },
    {
        "query": "Constructs a version string of the form:\n\n           day[.<commit-number-in-day>][+<branch-name-if-not-master>]\n\n       Master is understood to be always buildable and thus untagged\n       versions are treated as patch levels. Branches not master are treated\n       as PEP-440 \"local version identifiers\".",
        "positive_code": "def git_day():\n    \n    vec = [, , , , , ]\n    day = cmd(*(vec + [, ])).split()[0]\n    commits = cmd(*(vec + [, day + ])).strip()\n    n = len(commits.split())\n    day = day.replace(, )\n    if n > 1:\n        day +=  % n\n    \n    \n    branch = get_git_branch()\n    if branch != :\n        day +=  + s(branch)\n    return day",
        "hard_negative_ids": [
            429,
            466,
            73,
            210,
            360,
            386,
            252,
            142,
            159,
            413,
            288,
            335,
            136,
            415,
            349,
            391,
            197,
            291,
            40,
            232,
            470,
            245,
            342,
            237,
            485,
            318,
            76,
            1,
            414,
            462,
            17,
            157,
            149,
            499,
            171,
            498,
            26,
            25,
            32,
            475,
            162,
            304,
            137,
            382,
            268,
            106,
            47,
            412,
            23,
            109
        ]
    },
    {
        "query": "Return alias for device name if found.\n\n        :param argin: The device name\n        :type: tango.DevString\n        :return: The alias found\n        :rtype: tango.DevString",
        "positive_code": "def DbGetDeviceAlias(self, argin):\n        \n        self._log.debug(\"In DbGetDeviceAlias()\")\n        ret, dev_name, dfm = check_device_name(argin)\n        if not ret:\n            th_exc(DB_IncorrectDeviceName,\n                  \"device name (\" + argin + \") syntax error (should be [tango:][//instance/]domain/family/member)\",\n                  \"DataBase::DbGetDeviceAlias()\")\n\n        return self.db.get_device_alias(dev_name)",
        "hard_negative_ids": [
            321,
            259,
            498,
            291,
            176,
            81,
            44,
            232,
            258,
            349,
            65,
            360,
            204,
            414,
            197,
            353,
            344,
            424,
            150,
            66,
            23,
            466,
            412,
            454,
            429,
            76,
            300,
            496,
            366,
            136,
            279,
            73,
            133,
            280,
            386,
            293,
            115,
            91,
            20,
            109,
            411,
            226,
            105,
            191,
            324,
            62,
            25,
            273,
            113,
            500
        ]
    },
    {
        "query": "Synchronous FIFO\n\n        Input  interface: full,  we, din\n        Output interface: empty, re, dout\n            It s possible to set din and dout to None. Then the fifo width will be 0 and the fifo will contain no storage.\n\n        Extra interface:\n        afull     (o) - almost full flag, asserted when the number of empty cells <= afull_th\n        aempty    (o) - almost empty flag, asserted when the number of full cells <= aempty_th\n\n        afull_th  (i) - almost full threshold, in terms of fifo cells; signal or constant; Optional, default depth/2\n        aempty_th (i) - almost empty threshold, in terms of fifo cells; signal or constant; Optional, default depth/2\n\n        count     (o) - number of occupied fifo cells\n\n        count_max (o) - max number of occupied fifo cells reached since the last reset\n        ovf       (o) - overflow flag, set at the first write in a full fifo, cleared at reset\n        udf       (o) - underflow flag, set at the first read from an empty fifo, cleared at reset\n\n        Parameters:\n        depth         - fifo depth, must be >= 1; if not set or set to `None` default value 2 is used\n        width         - data width in bits, must be >= 0; if not set or set to `None` the `din` width is used",
        "positive_code": "def fifo(rst, clk, full, we, din, empty, re, dout, afull=None, aempty=None, afull_th=None, aempty_th=None, ovf=None, udf=None, count=None, count_max=None, depth=None, width=None):\n    \n\n    if (width == None):\n        width = 0\n        if din is not None:\n            width = len(din)\n    if (depth == None):\n        depth = 2\n\n    full_flg        = Signal(bool(1))\n    empty_flg       = Signal(bool(1))\n    we_safe         = Signal(bool(0))\n    re_safe         = Signal(bool(0))\n\n    rd_ptr          = Signal(intbv(0, min=0, max=depth))\n    rd_ptr_new      = Signal(intbv(0, min=0, max=depth))\n    wr_ptr          = Signal(intbv(0, min=0, max=depth))\n    wr_ptr_new      = Signal(intbv(0, min=0, max=depth))\n\n    @always_comb\n    def safe_read_write():\n        full.next       = full_flg\n        empty.next      = empty_flg\n        we_safe.next    = we and not full_flg\n        re_safe.next    = re and not empty_flg\n\n\n    \n    \n    \n    @always_comb\n    def ptrs_new():\n        rd_ptr_new.next     = ((rd_ptr + 1) % depth)\n        wr_ptr_new.next     = ((wr_ptr + 1) % depth)\n\n    @always(clk.posedge)\n    def state_main():\n        if (rst):\n            wr_ptr.next     = 0\n            rd_ptr.next     = 0\n            full_flg.next   = 0\n            empty_flg.next  = 1\n        else:\n            \n            if (we_safe): wr_ptr.next = wr_ptr_new\n            \n            if (re_safe): rd_ptr.next = rd_ptr_new\n            \n            if (we_safe):\n                empty_flg.next  = 0\n            elif (re_safe and (rd_ptr_new == wr_ptr)):\n                empty_flg.next  = 1\n            \n            if (re_safe):\n                full_flg.next   = 0\n            elif (we_safe and (wr_ptr_new == rd_ptr)):\n                full_flg.next   = 1\n\n\n    \n    \n    \n    \n    if (count != None) or (count_max != None) or (afull != None) or (aempty != None):\n        count_r = Signal(intbv(0, min=0, max=depth+1))\n        count_new  = Signal(intbv(0, min=-1, max=depth+2))\n\n        if (count != None):\n            assert count.max > depth\n            @always_comb\n            def count_out():\n                count.next = count_r\n\n        @always_comb\n        def count_comb():\n            if   (we_safe and not re_safe):\n                    count_new.next = count_r + 1\n            elif (not we_safe and re_safe):\n                    count_new.next = count_r - 1\n            else:\n                    count_new.next = count_r\n\n        @always(clk.posedge)\n        def count_proc():\n            if (rst):\n                count_r.next = 0\n            else:\n                count_r.next = count_new\n\n    \n    if (count_max != None):\n        assert count_max.max > depth\n        count_max_r = Signal(intbv(0, min=0,max=count_max.max))\n        @always(clk.posedge)\n        def count_max_proc():\n            if (rst):\n                count_max_r.next = 0\n            else:\n                if (count_max_r < count_new):\n                    count_max_r.next = count_new\n\n        @always_comb\n        def count_max_out():\n            count_max.next = count_max_r\n\n    \n    \n    \n    \n    if (afull != None):\n        if (afull_th == None):\n            afull_th = depth//2\n        @always(clk.posedge)\n        def afull_proc():\n            if (rst):\n                afull.next = 0\n            else:\n                afull.next = (count_new >= depth-afull_th)\n\n    \n    if (aempty != None):\n        if (aempty_th == None):\n            aempty_th = depth//2\n        @always(clk.posedge)\n        def aempty_proc():\n            if (rst):\n                aempty.next = 1\n            else:\n                aempty.next = (count_new <=  aempty_th)\n\n\n    \n    \n    \n    \n    if (ovf != None):\n        @always(clk.posedge)\n        def ovf_proc():\n            if (rst):\n                ovf.next = 0\n            else:\n                if (we and full_flg ):\n                    ovf.next = 1\n\n    \n    if (udf != None):\n        @always(clk.posedge)\n        def udf_proc():\n            if (rst):\n                udf.next = 0\n            else:\n                if (re and empty_flg):\n                    udf.next = 1\n\n    if width>0:\n        \n        \n        \n        mem_we      = Signal(bool(0))\n        mem_addrw   = Signal(intbv(0, min=0, max=depth))\n        mem_addrr   = Signal(intbv(0, min=0, max=depth))\n        mem_di      = Signal(intbv(0)[width:0])\n        mem_do      = Signal(intbv(0)[width:0])\n\n        \n        mem = ram_sdp_ar(   clk     = clk,\n                            we      = mem_we,\n                            addrw   = mem_addrw,\n                            addrr   = mem_addrr,\n                            di      = mem_di,\n                            do      = mem_do )\n\n        @always_comb\n        def mem_connect():\n            mem_we.next         = we_safe\n            mem_addrw.next      = wr_ptr\n            mem_addrr.next      = rd_ptr\n            mem_di.next         = din\n            dout.next           = mem_do\n\n    return instances()",
        "hard_negative_ids": [
            429,
            349,
            232,
            498,
            252,
            285,
            424,
            22,
            76,
            149,
            109,
            142,
            44,
            135,
            73,
            386,
            414,
            353,
            23,
            97,
            240,
            295,
            466,
            315,
            197,
            25,
            182,
            462,
            382,
            168,
            470,
            360,
            359,
            179,
            268,
            291,
            53,
            368,
            306,
            413,
            162,
            460,
            464,
            496,
            11,
            136,
            12,
            441,
            84,
            275
        ]
    },
    {
        "query": "Check the specified projects for Python 3 compatibility.",
        "positive_code": "def check(projects):\n    \n    log = logging.getLogger()\n    log.info(.format(len(projects)))\n    print()\n    blockers = dependencies.blockers(projects)\n\n    print()\n    for line in message(blockers):\n        print(line)\n\n    print()\n    for line in pprint_blockers(blockers):\n        print(, line)\n\n    return len(blockers) == 0",
        "hard_negative_ids": [
            185,
            107,
            201,
            77,
            197,
            425,
            73,
            284,
            189,
            414,
            47,
            54,
            260,
            360,
            291,
            318,
            240,
            234,
            243,
            466,
            198,
            221,
            136,
            23,
            149,
            316,
            109,
            95,
            429,
            44,
            137,
            239,
            25,
            298,
            48,
            238,
            101,
            275,
            179,
            182,
            135,
            489,
            321,
            35,
            363,
            223,
            377,
            142,
            29,
            247
        ]
    },
    {
        "query": "This method optionally takes the following extra\n        keyword arguments:\n        to_date: a datetime object representing the date the filter should end with\n        from_date: a datetime object representing the date the filter should start from\n        txn_ref: the transaction reference of a particular transaction\n        from_account_id: the account id for the account to filter transactions by (you will\n        need to get this information from `get_account_details` method)\n        If you specify txn_ref, then it's not necessary to specify to_date and from_date.",
        "positive_code": "def get_transactions(self, **kwargs):\n        \n        kw_map = {\n            : ,\n            : ,\n            : ,\n            : }\n\n        if not self.TRANSACTIONS_FORM:\n            try:\n                self.get_url(self.TRANSACTIONS_URL)\n            except AuthRequiredException:\n                self._auth()\n                self.get_url(self.TRANSACTIONS_URL)\n            self.br.select_form(\"accountHistoryForm\")\n            self.br.form.method = \n            self.br.form.action = self.TRANSACTIONS_EXPORT_URL\n            self.TRANSACTIONS_FORM = self.br.form\n            _form = deepcopy(self.TRANSACTIONS_FORM)\n        else:\n            _form = deepcopy(self.TRANSACTIONS_FORM)\n\n        \n        _form.set_all_readonly(False)\n\n        for key, field_name in kw_map.items():\n            if key in kwargs:\n                \n                if key.endswith():\n                    _form[field_name] = kwargs.get(key).strftime()\n                else:\n                    _form[field_name] = kwargs.get(key)\n\n        try:\n            r = self.post_url(self.TRANSACTIONS_EXPORT_URL, form=_form)\n            return self._parse_transactions(r)\n        except AuthRequiredException:\n            self._auth()\n            r = self.post_url(self.TRANSACTIONS_EXPORT_URL, form=_form)\n            return self._parse_transactions(r)",
        "hard_negative_ids": [
            460,
            466,
            360,
            474,
            291,
            79,
            414,
            269,
            493,
            197,
            136,
            191,
            323,
            189,
            246,
            82,
            295,
            278,
            383,
            57,
            73,
            470,
            80,
            485,
            268,
            349,
            382,
            47,
            462,
            203,
            390,
            44,
            41,
            192,
            165,
            23,
            434,
            87,
            171,
            212,
            131,
            402,
            275,
            113,
            90,
            391,
            70,
            149,
            106,
            15
        ]
    },
    {
        "query": "update the threat state",
        "positive_code": "def update(self, state, tnow):\n        \n        self.state = state\n        self.update_time = tnow",
        "hard_negative_ids": [
            360,
            325,
            217,
            202,
            410,
            465,
            185,
            336,
            85,
            466,
            351,
            295,
            197,
            414,
            45,
            476,
            352,
            291,
            179,
            412,
            136,
            73,
            420,
            186,
            429,
            44,
            90,
            67,
            64,
            97,
            402,
            23,
            25,
            327,
            427,
            76,
            329,
            180,
            109,
            480,
            479,
            478,
            477,
            475,
            474,
            473,
            472,
            471,
            470,
            469
        ]
    },
    {
        "query": "Creators.\n\n        Creators are not the authors. These are usually editors, translators,\n        narrators, etc.\n\n        :return:\n            Returns a list of creators where each is a tuple containing:\n\n                1. The creators name (string).\n                2. The creators role (string).",
        "positive_code": "def creators(self):\n        \n        \n        result = []\n        creators = self._safe_get_element()\n        if creators is not None:\n            for creator in creators:\n                role = creator.attrib[] if \\\n                     in creator.attrib else None\n                result.append((creator.text, role))\n        return result",
        "hard_negative_ids": [
            413,
            210,
            360,
            40,
            466,
            429,
            287,
            342,
            487,
            197,
            136,
            291,
            73,
            77,
            267,
            391,
            498,
            499,
            414,
            349,
            304,
            90,
            293,
            23,
            237,
            106,
            470,
            25,
            176,
            15,
            256,
            318,
            257,
            424,
            66,
            44,
            425,
            178,
            453,
            171,
            232,
            317,
            182,
            450,
            184,
            386,
            272,
            76,
            240,
            84
        ]
    },
    {
        "query": "Cancels the specified firewall.\n\n        :param int firewall_id: Firewall ID to be cancelled.\n        :param bool dedicated: If true, the firewall instance is dedicated,\n                               otherwise, the firewall instance is shared.",
        "positive_code": "def cancel_firewall(self, firewall_id, dedicated=False):\n        \n\n        fwl_billing = self._get_fwl_billing_item(firewall_id, dedicated)\n        billing_item_service = self.client[]\n        return billing_item_service.cancelService(id=fwl_billing[])",
        "hard_negative_ids": [
            269,
            81,
            197,
            73,
            219,
            386,
            360,
            414,
            333,
            291,
            204,
            344,
            300,
            466,
            23,
            232,
            489,
            256,
            136,
            318,
            429,
            44,
            52,
            192,
            331,
            79,
            459,
            12,
            211,
            462,
            171,
            109,
            382,
            97,
            105,
            179,
            295,
            25,
            187,
            42,
            260,
            147,
            368,
            252,
            470,
            423,
            329,
            307,
            113,
            141
        ]
    },
    {
        "query": "Return a formatted version, using substitutions from args and kwargs.\n\n        The substitutions are identified by braces ('{' and '}').",
        "positive_code": "def format(self, *args, **kwargs):\n        \n        return self.__class__(super(ColorStr, self).format(*args, **kwargs), keep_tags=True)",
        "hard_negative_ids": [
            291,
            166,
            360,
            287,
            488,
            147,
            466,
            219,
            73,
            269,
            41,
            112,
            136,
            478,
            316,
            324,
            385,
            23,
            7,
            212,
            16,
            179,
            396,
            228,
            123,
            5,
            45,
            429,
            295,
            106,
            424,
            67,
            131,
            304,
            222,
            386,
            25,
            391,
            226,
            137,
            487,
            159,
            499,
            197,
            414,
            139,
            191,
            193,
            453,
            264
        ]
    },
    {
        "query": " cmd \n        :return:",
        "positive_code": "def _validate_cmds(self):\n        \n\n        cmd_list = list(self.rule_map.keys())\n\n        for bp in self.blueprints:\n            cmd_list.extend(bp.rule_map.keys())\n\n        duplicate_cmds = (Counter(cmd_list) - Counter(set(cmd_list))).keys()\n\n        assert not duplicate_cmds,  % duplicate_cmds",
        "hard_negative_ids": [
            146,
            438,
            407,
            69,
            275,
            176,
            150,
            380,
            328,
            460,
            485,
            498,
            487,
            478,
            435,
            481,
            94,
            441,
            390,
            21,
            134,
            386,
            5,
            250,
            193,
            454,
            226,
            112,
            86,
            128,
            210,
            42,
            3,
            56,
            433,
            141,
            425,
            55,
            304,
            118,
            424,
            453,
            48,
            406,
            166,
            84,
            223,
            37,
            280,
            287
        ]
    },
    {
        "query": "Encode Async options for JSON encoding.",
        "positive_code": "def encode_async_options(async):\n    \n    options = copy.deepcopy(async._options)\n\n    options[] = reference_to_path(async.__class__)\n\n    \n\n    return options",
        "hard_negative_ids": [
            130,
            434,
            407,
            428,
            153,
            262,
            413,
            216,
            1,
            385,
            182,
            342,
            370,
            392,
            303,
            91,
            50,
            64,
            62,
            242,
            19,
            377,
            484,
            275,
            52,
            376,
            300,
            463,
            265,
            207,
            311,
            188,
            237,
            230,
            429,
            138,
            109,
            414,
            179,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            142,
            29,
            247,
            317
        ]
    },
    {
        "query": "Show list of identifiers for this prefix.\n\n    Handles both the case of local file based identifiers and\n    also image generators.\n\n    Arguments:\n        config - configuration object in which:\n            config.klass_name - 'gen' if a generator function\n            config.generator_dir - directory for generator code\n            config.image_dir - directory for images\n\n    Returns:\n        ids - a list of ids",
        "positive_code": "def identifiers(config):\n    \n    ids = []\n    if (config.klass_name == ):\n        for generator in os.listdir(config.generator_dir):\n            if (generator == ):\n                continue\n            (gid, ext) = os.path.splitext(generator)\n            if (ext ==  and\n                    os.path.isfile(os.path.join(config.generator_dir, generator))):\n                ids.append(gid)\n    else:\n        for image_file in os.listdir(config.image_dir):\n            (iid, ext) = os.path.splitext(image_file)\n            if (ext in [, , ] and\n                    os.path.isfile(os.path.join(config.image_dir, image_file))):\n                ids.append(iid)\n    return ids",
        "hard_negative_ids": [
            454,
            228,
            79,
            178,
            42,
            405,
            470,
            130,
            264,
            349,
            197,
            38,
            466,
            227,
            9,
            12,
            146,
            188,
            341,
            171,
            61,
            339,
            47,
            142,
            25,
            414,
            235,
            256,
            360,
            200,
            391,
            276,
            286,
            106,
            429,
            113,
            8,
            363,
            304,
            77,
            232,
            165,
            23,
            76,
            81,
            2,
            395,
            317,
            275,
            272
        ]
    },
    {
        "query": "Check worker status route",
        "positive_code": "def check_worker_status():\n    \n    if  not in request.args:\n        resp = {\"status\": \"bad request\"}\n        return jsonify(**resp)\n    else:\n        worker_id = request.args[]\n        assignment_id = request.args[]\n        allow_repeats = CONFIG.getboolean(, )\n        if allow_repeats: \n            try:\n                part = Participant.query.\\\n                    filter(Participant.workerid == worker_id).\\\n                    filter(Participant.assignmentid == assignment_id).one()\n                status = part.status\n            except exc.SQLAlchemyError:\n                status = NOT_ACCEPTED\n        else: \n            try:\n                matches = Participant.query.\\\n                    filter(Participant.workerid == worker_id).all()\n                numrecs = len(matches)\n                if numrecs==0: \n                    status = NOT_ACCEPTED\n                else:\n                    status = max([record.status for record in matches])\n            except exc.SQLAlchemyError:\n                status = NOT_ACCEPTED\n        resp = {\"status\" : status}\n        return jsonify(**resp)",
        "hard_negative_ids": [
            161,
            66,
            458,
            376,
            185,
            201,
            425,
            105,
            197,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            457,
            456,
            455,
            454,
            453,
            452
        ]
    },
    {
        "query": "save(self, filename, garbage=0, clean=0, deflate=0, incremental=0, ascii=0, expand=0, linear=0, pretty=0, decrypt=1) -> PyObject *",
        "positive_code": "def save(self, filename, garbage=0, clean=0, deflate=0, incremental=0, ascii=0, expand=0, linear=0, pretty=0, decrypt=1):\n        \n\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n        if type(filename) == str:\n            pass\n        elif type(filename) == unicode:\n            filename = filename.encode()\n        else:\n            raise TypeError(\"filename must be a string\")\n        if filename == self.name and not incremental:\n            raise ValueError(\"save to original must be incremental\")\n        if self.pageCount < 1:\n            raise ValueError(\"cannot save with zero pages\")\n        if incremental:\n            if self.name != filename or self.stream:\n                raise ValueError(\"incremental needs original file\")\n\n\n        return _fitz.Document_save(self, filename, garbage, clean, deflate, incremental, ascii, expand, linear, pretty, decrypt)",
        "hard_negative_ids": [
            267,
            262,
            312,
            424,
            373,
            364,
            386,
            38,
            100,
            169,
            452,
            240,
            245,
            361,
            467,
            329,
            117,
            409,
            256,
            14,
            95,
            272,
            155,
            67,
            85,
            148,
            162,
            17,
            260,
            412,
            175,
            53,
            347,
            202,
            77,
            350,
            56,
            346,
            273,
            426,
            88,
            254,
            163,
            490,
            287,
            16,
            41,
            203,
            486,
            488
        ]
    },
    {
        "query": "Return the zipcodes mapping as a list of ``{zipcode: location}`` dicts.\n        The zipcodes file will be downloaded if necessary.",
        "positive_code": "def get_locations(self):\n        \n        if not self.zipcode_mapping:\n            self.download(overwrite=False)\n\n            zipcode_mapping = {}\n            with UnicodeReader(self.file_path, delimiter=, encoding=) as csv_reader:\n                \n                next(csv_reader)\n                for line in csv_reader:\n                    zipcode_mapping[int(line[1])] = Location(\n                        official_name=line[0],\n                        canton=line[5],\n                        municipality=line[3]\n                    )\n            self.zipcode_mapping = zipcode_mapping\n\n        return self.zipcode_mapping",
        "hard_negative_ids": [
            360,
            470,
            466,
            171,
            232,
            197,
            277,
            291,
            414,
            161,
            23,
            429,
            106,
            349,
            363,
            192,
            304,
            382,
            44,
            391,
            237,
            462,
            386,
            453,
            178,
            101,
            113,
            264,
            136,
            425,
            73,
            317,
            144,
            395,
            15,
            25,
            182,
            1,
            467,
            272,
            169,
            2,
            77,
            376,
            256,
            328,
            180,
            267,
            109,
            76
        ]
    },
    {
        "query": "Retrieves device-specific grains.",
        "positive_code": "def _get_device_grain(name, proxy=None):\n    \n    device = _retrieve_device_cache(proxy=proxy)\n    return device.get(name.upper())",
        "hard_negative_ids": [
            95,
            268,
            435,
            1,
            245,
            56,
            472,
            17,
            416,
            77,
            361,
            391,
            175,
            240,
            379,
            292,
            439,
            349,
            460,
            76,
            404,
            53,
            486,
            67,
            347,
            155,
            149,
            217,
            162,
            177,
            497,
            462,
            412,
            340,
            279,
            210,
            46,
            234,
            2,
            474,
            450,
            393,
            202,
            426,
            110,
            96,
            298,
            64,
            414,
            346
        ]
    },
    {
        "query": "Expand all items.",
        "positive_code": "def expand_all(self):\n        \n\n        def aux(item):\n            self.item(item, open=True)\n            children = self.get_children(item)\n            for c in children:\n                aux(c)\n\n        children = self.get_children(\"\")\n        for c in children:\n            aux(c)",
        "hard_negative_ids": [
            85,
            116,
            222,
            78,
            23,
            192,
            250,
            31,
            236,
            295,
            76,
            142,
            329,
            88,
            47,
            190,
            201,
            411,
            237,
            25,
            261,
            377,
            205,
            15,
            384,
            169,
            272,
            344,
            293,
            109,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460
        ]
    },
    {
        "query": "Remove the *checked*-attribute of all input elements with\n        a *name*-attribute given by ``name``.",
        "positive_code": "def uncheck_all(self, name):\n        \n        for option in self.form.find_all(\"input\", {\"name\": name}):\n            if \"checked\" in option.attrs:\n                del option.attrs[\"checked\"]",
        "hard_negative_ids": [
            91,
            429,
            291,
            498,
            391,
            412,
            466,
            500,
            85,
            496,
            73,
            166,
            176,
            76,
            69,
            96,
            360,
            433,
            349,
            74,
            453,
            197,
            461,
            348,
            269,
            227,
            425,
            287,
            16,
            470,
            414,
            488,
            23,
            324,
            65,
            191,
            295,
            332,
            116,
            66,
            142,
            150,
            123,
            201,
            179,
            374,
            95,
            106,
            212,
            34
        ]
    },
    {
        "query": "https://developers.coinbase.com/api/v2#show-a-deposit",
        "positive_code": "def get_deposit(self, deposit_id, **params):\n        \n        return self.api_client.get_deposit(self.id, deposit_id, **params)",
        "hard_negative_ids": [
            207,
            265,
            500,
            429,
            391,
            457,
            361,
            162,
            159,
            317,
            69,
            462,
            177,
            228,
            382,
            95,
            472,
            106,
            296,
            304,
            47,
            350,
            388,
            88,
            160,
            222,
            453,
            178,
            464,
            322,
            425,
            426,
            349,
            360,
            206,
            256,
            12,
            171,
            15,
            76,
            387,
            71,
            470,
            275,
            100,
            291,
            345,
            268,
            435,
            1
        ]
    },
    {
        "query": "For memory actions, get a list of addresses it operates on.\n\n        :param SimAction action: The action object to work with.\n        :return:                 A list of addresses that are accessed with that action.\n        :rtype:                  list",
        "positive_code": "def _get_actual_addrs(action, state):\n        \n\n        if action.actual_addrs is None:\n            \n                addr_list = {0x60000000}  \n        else:\n            addr_list = set(action.actual_addrs)\n\n        return addr_list",
        "hard_negative_ids": [
            360,
            132,
            209,
            466,
            255,
            79,
            81,
            470,
            329,
            451,
            204,
            499,
            429,
            391,
            260,
            291,
            349,
            414,
            331,
            197,
            344,
            106,
            171,
            304,
            47,
            236,
            266,
            185,
            73,
            136,
            269,
            264,
            130,
            421,
            183,
            424,
            179,
            232,
            395,
            25,
            317,
            23,
            453,
            293,
            77,
            15,
            113,
            382,
            318,
            2
        ]
    },
    {
        "query": "Move the cursor to a new position.\n            Default: line 1, column 1",
        "positive_code": "def move_pos(self, line=1, column=1):\n        \n        return self.chained(move.pos(line=line, column=column))",
        "hard_negative_ids": [
            125,
            424,
            82,
            168,
            452,
            171,
            20,
            360,
            306,
            84,
            142,
            407,
            472,
            44,
            405,
            414,
            76,
            438,
            359,
            466,
            64,
            73,
            391,
            252,
            106,
            9,
            275,
            304,
            186,
            58,
            197,
            317,
            69,
            291,
            453,
            136,
            178,
            425,
            256,
            269,
            23,
            15,
            462,
            131,
            109,
            429,
            368,
            376,
            470,
            349
        ]
    },
    {
        "query": "Either the the data from a model as\n    X the inputs,\n    X_variance the variance of the inputs ([default: None])\n    and Y the outputs\n\n    If (X, X_variance, Y) is given, this just returns.\n\n    :returns: (X, X_variance, Y)",
        "positive_code": "def get_x_y_var(model):\n    \n    \n    if hasattr(model, ) and model.has_uncertain_inputs():\n        X = model.X.mean.values\n        X_variance = model.X.variance.values\n    else:\n        try:\n            X = model.X.values\n        except AttributeError:\n            X = model.X\n        X_variance = None\n    try:\n        Y = model.Y.values\n    except AttributeError:\n        Y = model.Y\n\n    if isinstance(model, WarpedGP) and not model.predict_in_warped_space:\n        Y = model.Y_normalized\n    \n    if sparse.issparse(Y): Y = Y.todense().view(np.ndarray)\n    return X, X_variance, Y",
        "hard_negative_ids": [
            263,
            3,
            240,
            496,
            360,
            495,
            333,
            245,
            424,
            321,
            73,
            185,
            466,
            168,
            291,
            429,
            197,
            419,
            296,
            414,
            464,
            89,
            318,
            152,
            136,
            76,
            156,
            23,
            306,
            472,
            25,
            290,
            489,
            421,
            198,
            405,
            67,
            252,
            84,
            267,
            349,
            304,
            46,
            470,
            223,
            106,
            490,
            391,
            273,
            256
        ]
    },
    {
        "query": "Get a summary of this ResultLists contents as dictionary.\n\n        :return: dictionary",
        "positive_code": "def get_summary(self):\n        \n        return {\n            \"count\": self.count(),\n            \"pass\": self.success_count(),\n            \"fail\": self.failure_count(),\n            \"skip\": self.skip_count(),\n            \"inconclusive\": self.inconclusive_count(),\n            \"retries\": self.retry_count(),\n            \"duration\": self.total_duration()\n        }",
        "hard_negative_ids": [
            308,
            382,
            178,
            273,
            470,
            62,
            106,
            349,
            304,
            421,
            391,
            99,
            453,
            466,
            275,
            15,
            425,
            317,
            189,
            90,
            395,
            360,
            498,
            326,
            171,
            232,
            47,
            272,
            256,
            180,
            429,
            197,
            82,
            280,
            389,
            157,
            254,
            414,
            114,
            462,
            6,
            369,
            318,
            295,
            452,
            463,
            222,
            192,
            373,
            315
        ]
    },
    {
        "query": "Remove all empty fields in a nested dict",
        "positive_code": "def clean_dict(d):\n    \n\n    if not isinstance(d, (dict, list)):\n        return d\n    if isinstance(d, list):\n        return [v for v in (clean_dict(v) for v in d) if v]\n    return OrderedDict(\n        [(k, v) for k, v in ((k, clean_dict(v)) for k, v in list(d.items())) if v]\n    )",
        "hard_negative_ids": [
            411,
            49,
            178,
            500,
            69,
            2,
            127,
            332,
            8,
            106,
            97,
            85,
            304,
            76,
            382,
            74,
            116,
            391,
            381,
            278,
            96,
            489,
            265,
            317,
            453,
            44,
            38,
            327,
            425,
            142,
            374,
            295,
            15,
            360,
            88,
            20,
            171,
            345,
            387,
            47,
            201,
            331,
            470,
            256,
            443,
            239,
            237,
            25,
            99,
            260
        ]
    },
    {
        "query": "Convert Python value to database value for SAVING.\n        We save with full timezone information.",
        "positive_code": "def get_db_prep_save(self, value, connection, prepared=False):\n        \n        log.debug(\"get_db_prep_save: {}, {}\", value, type(value))\n        if not value:\n            return \n            \n            \n            \n        return python_localized_datetime_to_human_iso(value)",
        "hard_negative_ids": [
            382,
            56,
            267,
            332,
            481,
            166,
            441,
            47,
            452,
            366,
            362,
            91,
            11,
            9,
            424,
            349,
            242,
            19,
            199,
            467,
            269,
            496,
            409,
            182,
            232,
            280,
            15,
            142,
            163,
            103,
            375,
            253,
            222,
            273,
            260,
            414,
            264,
            109,
            275,
            171,
            170,
            195,
            311,
            384,
            272,
            131,
            59,
            74,
            96,
            189
        ]
    },
    {
        "query": "Generate newer-style type checks out of JSON-type-name-to-type mappings.\n\n    Arguments:\n\n        types (dict):\n\n            A mapping of type names to their Python types\n\n    Returns:\n\n        A dictionary of definitions to pass to `TypeChecker`",
        "positive_code": "def _generate_legacy_type_checks(types=()):\n    \n    types = dict(types)\n\n    def gen_type_check(pytypes):\n        pytypes = _utils.flatten(pytypes)\n\n        def type_check(checker, instance):\n            if isinstance(instance, bool):\n                if bool not in pytypes:\n                    return False\n            return isinstance(instance, pytypes)\n\n        return type_check\n\n    definitions = {}\n    for typename, pytypes in iteritems(types):\n        definitions[typename] = gen_type_check(pytypes)\n\n    return definitions",
        "hard_negative_ids": [
            47,
            232,
            178,
            269,
            157,
            76,
            428,
            349,
            113,
            435,
            308,
            382,
            15,
            131,
            391,
            429,
            498,
            466,
            171,
            470,
            425,
            279,
            353,
            445,
            414,
            360,
            2,
            280,
            260,
            265,
            388,
            201,
            176,
            376,
            106,
            133,
            115,
            345,
            20,
            304,
            197,
            17,
            439,
            324,
            395,
            464,
            393,
            412,
            411,
            273
        ]
    },
    {
        "query": "NAME:\n           _ELtowRRapRperi\n        PURPOSE:\n           calculate the radial frequency based on E,L, also return rap and \n           rperi\n        INPUT:\n           E - energy\n           L - angular momentum\n        OUTPUT:\n           wR(E.L)\n        HISTORY:\n           2010-07-11 - Written - Bovy (NYU)",
        "positive_code": "def _ELtowRRapRperi(self,E,L):\n        \n        if self._beta == 0.:\n            xE= sc.exp(E-.5)\n        else: \n            xE= (2.*E/(1.+1./self._beta))**(1./2./self._beta)\n        rperi,rap= self._aA.calcRapRperi(xE,0.,L/xE,0.,0.)\n        \n        aA= actionAngleAxi(xE,0.,L/xE,\n                           pot=PowerSphericalPotential(normalize=1.,\n                                                       alpha=2.-2.*self._beta).toPlanar())\n        TR= aA.TR()\n        return (2.*math.pi/TR,rap,rperi)",
        "hard_negative_ids": [
            135,
            53,
            345,
            320,
            109,
            179,
            230,
            237,
            440,
            136,
            68,
            496,
            429,
            498,
            260,
            369,
            307,
            227,
            499,
            169,
            462,
            376,
            275,
            34,
            427,
            176,
            185,
            252,
            124,
            130,
            254,
            414,
            9,
            412,
            204,
            266,
            466,
            291,
            360,
            76,
            391,
            197,
            65,
            66,
            150,
            25,
            349,
            217,
            47,
            454
        ]
    },
    {
        "query": "Create a file from a template if it doesn't already exist.",
        "positive_code": "def mk_tmpl(self, path, tmpl, ctx, mode=None):\n        \n\n        path = os.path.abspath(path)\n\n        if os.path.isfile(path):\n            logger.warning(\"File %s already exists, not creating it.\", tmpl)\n\n        with open(path, ) as fd:\n            fd.write(\n                tmpl.format(**ctx)\n            )\n            if mode:\n                os.chmod(path, mode)",
        "hard_negative_ids": [
            325,
            280,
            171,
            69,
            329,
            459,
            170,
            198,
            106,
            71,
            90,
            304,
            391,
            174,
            363,
            89,
            39,
            462,
            453,
            178,
            472,
            343,
            425,
            317,
            73,
            230,
            360,
            99,
            15,
            297,
            269,
            375,
            193,
            292,
            239,
            7,
            26,
            467,
            470,
            237,
            367,
            256,
            382,
            131,
            11,
            376,
            293,
            315,
            23,
            144
        ]
    },
    {
        "query": "Add a key bundle and bind it to an identifier\n        \n        :param issuer: Owner of the keys in the key bundle\n        :param kb: A :py:class:`oidcmsg.key_bundle.KeyBundle` instance",
        "positive_code": "def add_kb(self, issuer, kb):\n        \n        try:\n            self.issuer_keys[issuer].append(kb)\n        except KeyError:\n            self.issuer_keys[issuer] = [kb]",
        "hard_negative_ids": [
            196,
            491,
            360,
            269,
            45,
            235,
            81,
            476,
            466,
            134,
            414,
            233,
            453,
            387,
            15,
            219,
            48,
            442,
            76,
            73,
            197,
            204,
            349,
            291,
            179,
            106,
            344,
            215,
            171,
            470,
            113,
            304,
            189,
            222,
            391,
            300,
            382,
            429,
            436,
            11,
            272,
            333,
            23,
            345,
            178,
            317,
            425,
            490,
            25,
            289
        ]
    },
    {
        "query": "Read an image from bytes.\n\n    Args:\n        content (bytes): Image bytes got from files or other streams.\n        flag (str): Same as :func:`imread`.\n\n    Returns:\n        ndarray: Loaded image array.",
        "positive_code": "def imfrombytes(content, flag=):\n    \n    img_np = np.frombuffer(content, np.uint8)\n    flag = imread_flags[flag] if is_str(flag) else flag\n    img = cv2.imdecode(img_np, flag)\n    return img",
        "hard_negative_ids": [
            342,
            250,
            485,
            112,
            264,
            12,
            494,
            273,
            353,
            269,
            276,
            217,
            286,
            337,
            62,
            297,
            275,
            453,
            425,
            263,
            147,
            119,
            414,
            363,
            29,
            88,
            287,
            42,
            488,
            449,
            405,
            41,
            163,
            219,
            427,
            367,
            300,
            402,
            26,
            407,
            73,
            360,
            11,
            193,
            459,
            385,
            171,
            356,
            7,
            316
        ]
    },
    {
        "query": "This function will perform a FileMaker action.",
        "positive_code": "def _doAction(self, action):\n\t\t\n\n\t\tif self._db == :\n\t\t\traise FMError, \n\n\t\tresult = \n\n\t\ttry:\n\t\t\trequest = [\n\t\t\t\tuu({: self._db })\n\t\t\t]\n\n\t\t\tif self._layout != :\n\t\t\t\trequest.append(uu({: self._layout }))\n\n\t\t\tif action ==  and self._lop != :\n\t\t\t\trequest.append(uu({: self._lop }))\n\n\t\t\tif action in [, ]:\n\n\t\t\t\tif self._skipRecords != 0:\n\t\t\t\t\trequest.append(uu({ : self._skipRecords }))\n\n\t\t\t\tif self._maxRecords != 0:\n\t\t\t\t\trequest.append(uu({ : self._maxRecords }))\n\n\t\t\t\tfor i in range(0, len(self._sortParams)):\n\t\t\t\t\tsort = self._sortParams[i]\n\t\t\t\t\trequest.append(uu({ +str(i+1): sort[0] }))\n\n\t\t\t\t\tif sort[1] != :\n\t\t\t\t\t\trequest.append(uu({ +str(i+1): sort[1] }))\n\n\t\t\tfor dbParam in self._dbParams:\n\n\t\t\t\tif dbParam[0] == :\n\t\t\t\t\trequest.append(uu({ : dbParam[1] }))\n\n\t\t\t\telif dbParam[0] == :\n\t\t\t\t\trequest.append(uu({ : dbParam[1] }))\n\n\t\t\t\telif hasattr(dbParam[1], ):\n\t\t\t\t\td = dbParam[1]\n\t\t\t\t\tif (not hasattr(d, )):\n\t\t\t\t\t\trequest.append(uu({ dbParam[0]: d.strftime() }))\n\t\t\t\t\telse:\n\t\t\t\t\t\trequest.append(uu({ dbParam[0]: d.strftime() }))\n\t\t\t\t\tdel(d)\n\t\t\t\telse:\n\t\t\t\t\trequest.append(uu({ dbParam[0]: dbParam[1] }))\n\t\t\trequest.append(action)\n\n\t\t\tif self._extra_script:\n\t\t\t\trequest += self._extra_script\n\t\t\t\tself._extra_script = None\n\n\t\t\tresult = self._doRequest(request)\n\n\t\t\ttry:\n\t\t\t\tresult = FMResultset.FMResultset(result)\n\t\t\texcept FMFieldError, value:\n\t\t\t\trealfields = FMServer(self._buildUrl(), self._db, self._layout).doView()\n\n\t\t\t\tl = []\n\t\t\t\tfor k, v in self._dbParams:\n\t\t\t\t\tif k[-3:] !=  and k[0] != :\n\t\t\t\t\t\tl.append((\"\" % k.replace(,)).encode())\n\t\t\t\traise FMError, \"Field(s) %s not found on layout \" % (.join(l), self._layout)\n\n\t\t\tif action == :\n\t\t\t\tresult = result.fieldNames\n\n\t\tfinally:\n\t\t\tself._dbParams = []\n\t\t\tself._sortParams = []\n\t\t\tself._skipRecords = 0\n\t\t\tself._maxRecords = 0\n\t\t\tself._lop = \n\n\t\treturn result",
        "hard_negative_ids": [
            42,
            132,
            209,
            255,
            235,
            451,
            329,
            201,
            142,
            106,
            304,
            391,
            189,
            90,
            453,
            178,
            185,
            317,
            425,
            47,
            360,
            260,
            171,
            15,
            470,
            256,
            382,
            414,
            192,
            462,
            275,
            222,
            349,
            472,
            76,
            466,
            180,
            272,
            23,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471
        ]
    },
    {
        "query": "Easy object-oriented representation of contributor info.\n\n    :param str name: The contributors name.\n    :param str contact: The contributors email address or contact\n                        information, if given.\n    :param str public_key: The contributors public keyid, if given.",
        "positive_code": "def author_info(name, contact=None, public_key=None):\n    \n    return Storage(name=name, contact=contact, public_key=public_key)",
        "hard_negative_ids": [
            73,
            200,
            81,
            197,
            386,
            326,
            498,
            79,
            124,
            366,
            466,
            201,
            204,
            412,
            470,
            176,
            429,
            344,
            414,
            360,
            300,
            291,
            382,
            293,
            407,
            340,
            50,
            127,
            77,
            109,
            91,
            136,
            349,
            159,
            266,
            379,
            65,
            76,
            275,
            165,
            167,
            99,
            44,
            462,
            66,
            150,
            23,
            52,
            477,
            315
        ]
    },
    {
        "query": "Reads notifications scheduled for a user within a given timerange.",
        "positive_code": "def ReadUserNotifications(self,\n                            username,\n                            state=None,\n                            timerange=None,\n                            cursor=None):\n    \n\n    query = (\"SELECT UNIX_TIMESTAMP(timestamp), \"\n             \"       notification_state, notification \"\n             \"FROM user_notification \"\n             \"WHERE username_hash = %s \")\n    args = [mysql_utils.Hash(username)]\n\n    if state is not None:\n      query += \"AND notification_state = %s \"\n      args.append(int(state))\n\n    if timerange is not None:\n      time_from, time_to = timerange  \n\n      if time_from is not None:\n        query += \"AND timestamp >= FROM_UNIXTIME(%s) \"\n        args.append(mysql_utils.RDFDatetimeToTimestamp(time_from))\n\n      if time_to is not None:\n        query += \"AND timestamp <= FROM_UNIXTIME(%s) \"\n        args.append(mysql_utils.RDFDatetimeToTimestamp(time_to))\n\n    query += \"ORDER BY timestamp DESC \"\n\n    ret = []\n    cursor.execute(query, args)\n\n    for timestamp, state, notification_ser in cursor.fetchall():\n      n = rdf_objects.UserNotification.FromSerializedString(notification_ser)\n      n.timestamp = mysql_utils.TimestampToRDFDatetime(timestamp)\n      n.state = state\n      ret.append(n)\n\n    return ret",
        "hard_negative_ids": [
            425,
            187,
            55,
            106,
            304,
            391,
            103,
            73,
            317,
            453,
            178,
            415,
            449,
            15,
            360,
            131,
            171,
            470,
            459,
            256,
            356,
            382,
            228,
            99,
            173,
            222,
            462,
            293,
            76,
            349,
            472,
            169,
            479,
            206,
            466,
            272,
            275,
            353,
            163,
            180,
            327,
            319,
            23,
            138,
            135,
            365,
            489,
            321,
            35,
            363
        ]
    },
    {
        "query": "Display information about an ip.\n\n    Resource can be an ip or id.",
        "positive_code": "def info(gandi, resource):\n    \n    output_keys = [, , , , , ]\n\n    datacenters = gandi.datacenter.list()\n\n    ip = gandi.ip.info(resource)\n    iface = gandi.iface.info(ip[])\n    vms = None\n    if iface.get():\n        vm = gandi.iaas.info(iface[])\n        vms = {vm[]: vm}\n\n    output_ip(gandi, ip, datacenters, vms, {iface[]: iface},\n              output_keys)\n\n    return ip",
        "hard_negative_ids": [
            431,
            171,
            255,
            382,
            439,
            472,
            189,
            97,
            254,
            232,
            360,
            459,
            73,
            79,
            256,
            386,
            52,
            315,
            197,
            427,
            182,
            462,
            489,
            187,
            42,
            264,
            470,
            291,
            293,
            414,
            113,
            153,
            463,
            192,
            326,
            289,
            240,
            434,
            141,
            425,
            105,
            270,
            5,
            284,
            215,
            112,
            72,
            306,
            179,
            127
        ]
    },
    {
        "query": "Property for accessing :class:`AgentManager` instance, which is used to manage agents.\n\n        :rtype: yagocd.resources.agent.AgentManager",
        "positive_code": "def agents(self):\n        \n        if self._agent_manager is None:\n            self._agent_manager = AgentManager(session=self._session)\n        return self._agent_manager",
        "hard_negative_ids": [
            35,
            370,
            269,
            171,
            146,
            219,
            113,
            333,
            157,
            76,
            264,
            277,
            297,
            368,
            73,
            131,
            47,
            189,
            414,
            376,
            295,
            275,
            423,
            99,
            23,
            360,
            266,
            224,
            466,
            329,
            66,
            222,
            345,
            413,
            388,
            109,
            232,
            304,
            92,
            328,
            212,
            243,
            398,
            263,
            251,
            324,
            233,
            197,
            151,
            51
        ]
    },
    {
        "query": "Convert a LiPD format to NOAA format\n\n    :param dict D: Metadata\n    :return dict D: Metadata",
        "positive_code": "def lpd_to_noaa(D, wds_url, lpd_url, version, path=\"\"):\n    \n    logger_noaa.info(\"enter process_lpd\")\n    d = D\n    try:\n        dsn = get_dsn(D)\n        \n        \n        _convert_obj = LPD_NOAA(D, dsn, wds_url, lpd_url, version, path)\n        _convert_obj.main()\n        \n        d = _convert_obj.get_master()\n        noaas = _convert_obj.get_noaa_texts()\n        __write_noaas(noaas, path)\n        \n        d = __rm_wdc_url(d)\n\n    except Exception as e:\n        logger_noaa.error(\"lpd_to_noaa: {}\".format(e))\n        print(\"Error: lpd_to_noaa: {}\".format(e))\n\n    \n    return d",
        "hard_negative_ids": [
            2,
            190,
            500,
            178,
            81,
            73,
            329,
            478,
            204,
            265,
            275,
            171,
            382,
            486,
            57,
            300,
            360,
            490,
            106,
            489,
            344,
            201,
            252,
            345,
            304,
            391,
            376,
            472,
            466,
            453,
            15,
            45,
            425,
            317,
            127,
            331,
            414,
            387,
            222,
            349,
            264,
            256,
            157,
            165,
            326,
            269,
            260,
            131,
            443,
            56
        ]
    },
    {
        "query": "Import the JSON data from target file.\n    :param str filename: Target File\n    :return dict: JSON data",
        "positive_code": "def read_json_from_file(filename):\n    \n    logger_jsons.info(\"enter read_json_from_file\")\n    d = OrderedDict()\n    try:\n        \n        d = demjson.decode_file(filename, decode_float=float)\n        logger_jsons.info(\"successful read from json file\")\n    except FileNotFoundError:\n        \n        try:\n            d = demjson.decode_file(os.path.splitext(filename)[0] + , decode_float=float)\n        except FileNotFoundError as e:\n            \n            print(\"Error: jsonld file not found: {}\".format(filename))\n            logger_jsons.debug(\"read_json_from_file: FileNotFound: {}, {}\".format(filename, e))\n        except Exception:\n            print(\"Error: unable to read jsonld file\")\n\n    if d:\n        d = rm_empty_fields(d)\n    logger_jsons.info(\"exit read_json_from_file\")\n    return d",
        "hard_negative_ids": [
            134,
            428,
            421,
            373,
            169,
            484,
            364,
            218,
            265,
            223,
            171,
            363,
            376,
            81,
            414,
            367,
            498,
            38,
            109,
            434,
            193,
            393,
            33,
            195,
            7,
            357,
            26,
            2,
            85,
            324,
            424,
            440,
            154,
            131,
            283,
            429,
            204,
            11,
            52,
            44,
            492,
            23,
            117,
            300,
            344,
            386,
            100,
            78,
            467,
            231
        ]
    },
    {
        "query": "Disassociates a hosting_device with a config agent.",
        "positive_code": "def disassociate_hosting_device_with_config_agent(\n            self, client, config_agent_id, hosting_device_id):\n        \n        return client.delete((ConfigAgentHandlingHostingDevice.resource_path +\n                              CFG_AGENT_HOSTING_DEVICES + \"/%s\") % (\n            config_agent_id, hosting_device_id))",
        "hard_negative_ids": [
            370,
            35,
            178,
            454,
            405,
            391,
            228,
            106,
            130,
            304,
            227,
            9,
            453,
            188,
            200,
            317,
            425,
            360,
            171,
            15,
            470,
            256,
            382,
            170,
            157,
            462,
            96,
            434,
            74,
            466,
            222,
            269,
            59,
            349,
            439,
            468,
            397,
            128,
            25,
            472,
            404,
            76,
            374,
            1,
            179,
            34,
            180,
            291,
            272,
            163
        ]
    },
    {
        "query": "Decorator used for adding exceptions to :class:`SanicException`.",
        "positive_code": "def add_status_code(code):\n    \n\n    def class_decorator(cls):\n        cls.status_code = code\n        _sanic_exceptions[code] = cls\n        return cls\n\n    return class_decorator",
        "hard_negative_ids": [
            42,
            368,
            425,
            76,
            277,
            297,
            171,
            266,
            264,
            269,
            275,
            131,
            189,
            414,
            376,
            295,
            85,
            446,
            73,
            360,
            307,
            496,
            370,
            47,
            57,
            435,
            66,
            201,
            431,
            130,
            157,
            99,
            185,
            91,
            30,
            281,
            466,
            329,
            186,
            109,
            375,
            23,
            135,
            48,
            124,
            87,
            489,
            321,
            35,
            363
        ]
    },
    {
        "query": "Try to find user and project name from git remote output\n\n        @param [String] output of git remote command\n        @return [Array] user and project",
        "positive_code": "def user_project_from_remote(remote):\n        \n\n        \n        \n        \n        regex1 = br\".*(?:[:/])(?P<user>(-|\\w|\\.)*)/\" \\\n                 br\"(?P<project>(-|\\w|\\.)*)(\\.git).*\"\n        match = re.match(regex1, remote)\n        if match:\n            return match.group(\"user\"), match.group(\"project\")\n\n        \n        \n        \n        regex2 = r\".*/((?:-|\\w|\\.)*)/((?:-|\\w|\\.)*).*\"\n        match = re.match(regex2, remote)\n        if match:\n            return match.group(\"user\"), match.group(\"project\")\n\n        return None, None",
        "hard_negative_ids": [
            107,
            189,
            210,
            284,
            131,
            444,
            376,
            260,
            81,
            413,
            187,
            40,
            55,
            335,
            204,
            342,
            425,
            227,
            243,
            136,
            166,
            88,
            498,
            103,
            34,
            9,
            415,
            73,
            252,
            316,
            275,
            394,
            176,
            349,
            236,
            86,
            344,
            385,
            173,
            193,
            197,
            180,
            122,
            327,
            274,
            353,
            201,
            466,
            109,
            60
        ]
    },
    {
        "query": "list[VolumeExtent]: sections.",
        "positive_code": "def sections(self):\n    \n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return self._sections",
        "hard_negative_ids": [
            418,
            467,
            130,
            169,
            77,
            2,
            328,
            267,
            332,
            477,
            183,
            410,
            260,
            98,
            290,
            110,
            81,
            79,
            53,
            424,
            344,
            264,
            182,
            144,
            127,
            142,
            120,
            18,
            402,
            47,
            443,
            236,
            61,
            58,
            25,
            76,
            235,
            23,
            179,
            192,
            239,
            99,
            490,
            272,
            181,
            293,
            469,
            468,
            466,
            465
        ]
    },
    {
        "query": "Return comment count for main thread and all reply threads for one url.",
        "positive_code": "def reply_count(self, url, mode=5, after=0):\n        \n\n        sql = [,\n               ,\n               ,\n               ,\n               ,\n               ]\n\n        return dict(self.db.execute(sql, [url, mode, mode, after]).fetchall())",
        "hard_negative_ids": [
            316,
            69,
            295,
            389,
            43,
            358,
            38,
            461,
            294,
            322,
            232,
            161,
            85,
            187,
            205,
            357,
            26,
            149,
            252,
            339,
            116,
            361,
            364,
            402,
            76,
            249,
            9,
            451,
            142,
            201,
            429,
            463,
            12,
            369,
            105,
            88,
            245,
            230,
            25,
            237,
            147,
            231,
            99,
            47,
            138,
            477,
            458,
            222,
            73,
            24
        ]
    },
    {
        "query": "Initialize the configured backend for use with BigchainDB.\n\n    Creates a database with :attr:`dbname` with any required tables\n    and supporting indexes.\n\n    Args:\n        connection (:class:`~bigchaindb.backend.connection.Connection`): an\n            existing connection to use to initialize the database.\n            Creates one if not given.\n        dbname (str): the name of the database to create.\n            Defaults to the database name given in the BigchainDB\n            configuration.",
        "positive_code": "def init_database(connection=None, dbname=None):\n    \n\n    connection = connection or connect()\n    dbname = dbname or bigchaindb.config[][]\n\n    create_database(connection, dbname)\n    create_tables(connection, dbname)",
        "hard_negative_ids": [
            168,
            414,
            269,
            73,
            360,
            450,
            291,
            249,
            412,
            84,
            340,
            466,
            76,
            170,
            325,
            266,
            498,
            9,
            122,
            197,
            404,
            15,
            295,
            232,
            189,
            391,
            99,
            429,
            179,
            204,
            176,
            324,
            272,
            47,
            219,
            171,
            329,
            274,
            287,
            459,
            488,
            247,
            131,
            424,
            201,
            349,
            41,
            297,
            405,
            275
        ]
    },
    {
        "query": "Run fit_cont, dealing with spectrum in regions or chunks\n\n    This is useful if a spectrum has gaps.\n\n    Parameters\n    ----------\n    fluxes: ndarray of shape (nstars, npixels)\n        training set or test set pixel intensities\n\n    ivars: numpy ndarray of shape (nstars, npixels)\n        inverse variances, parallel to fluxes\n\n    contmask: numpy ndarray of length (npixels)\n        boolean pixel mask, True indicates that pixel is continuum \n\n    deg: int\n        degree of fitting function\n\n    ffunc: str\n        type of fitting function, chebyshev or sinusoid\n\n    Returns\n    -------\n    cont: numpy ndarray of shape (nstars, npixels)\n        the continuum, parallel to fluxes",
        "positive_code": "def _find_cont_fitfunc_regions(fluxes, ivars, contmask, deg, ranges, ffunc,\n                               n_proc=1):\n    \n    nstars = fluxes.shape[0]\n    npixels = fluxes.shape[1]\n    cont = np.zeros(fluxes.shape)\n    for chunk in ranges:\n        start = chunk[0]\n        stop = chunk[1]\n        if ffunc==\"chebyshev\":\n            output = _find_cont_fitfunc(fluxes[:,start:stop],\n                                        ivars[:,start:stop],\n                                        contmask[start:stop],\n                                        deg=deg, ffunc=\"chebyshev\",\n                                        n_proc=n_proc)\n        elif ffunc==\"sinusoid\":\n            output = _find_cont_fitfunc(fluxes[:,start:stop],\n                                        ivars[:,start:stop],\n                                        contmask[start:stop],\n                                        deg=deg, ffunc=\"sinusoid\",\n                                        n_proc=n_proc)\n        cont[:, start:stop] = output\n\n    return cont",
        "hard_negative_ids": [
            263,
            240,
            42,
            299,
            360,
            466,
            349,
            232,
            235,
            12,
            81,
            271,
            317,
            449,
            23,
            414,
            99,
            197,
            391,
            256,
            429,
            239,
            268,
            318,
            470,
            157,
            142,
            76,
            149,
            25,
            73,
            345,
            179,
            275,
            171,
            152,
            496,
            395,
            272,
            222,
            90,
            462,
            11,
            425,
            17,
            97,
            127,
            189,
            109,
            47
        ]
    },
    {
        "query": "Return image series in Olympus SIS file.",
        "positive_code": "def _series_sis(self):\n        \n        pages = self.pages._getlist(validate=False)\n        page = pages[0]\n        lenpages = len(pages)\n        md = self.sis_metadata\n        if  in md and  in md:\n            shape = md[] + page.shape\n            axes = md[] + page.axes\n        elif lenpages == 1:\n            shape = page.shape\n            axes = page.axes\n        else:\n            shape = (lenpages,) + page.shape\n            axes =  + page.axes\n        self.is_uniform = True\n        return [TiffPageSeries(pages, shape, page.dtype, axes, kind=)]",
        "hard_negative_ids": [
            264,
            12,
            44,
            276,
            286,
            363,
            171,
            467,
            376,
            144,
            239,
            1,
            169,
            275,
            23,
            277,
            289,
            414,
            99,
            305,
            135,
            321,
            209,
            489,
            215,
            35,
            155,
            223,
            387,
            234,
            247,
            377,
            345,
            4,
            36,
            317,
            267,
            500,
            133,
            104,
            424,
            29,
            61,
            205,
            53,
            413,
            190,
            65,
            344,
            5
        ]
    },
    {
        "query": "wp.newCategory(blog_id, username, password, category)\n    => category_id",
        "positive_code": "def new_category(blog_id, username, password, category_struct):\n    \n    authenticate(username, password, )\n    category_dict = {: category_struct[],\n                     : category_struct[],\n                     : category_struct[]}\n    if int(category_struct[]):\n        category_dict[] = Category.objects.get(\n            pk=category_struct[])\n    category = Category.objects.create(**category_dict)\n\n    return category.pk",
        "hard_negative_ids": [
            52,
            276,
            288,
            55,
            228,
            251,
            425,
            198,
            159,
            245,
            56,
            379,
            460,
            485,
            404,
            429,
            314,
            217,
            203,
            48,
            206,
            412,
            210,
            340,
            435,
            252,
            77,
            2,
            202,
            450,
            393,
            110,
            254,
            341,
            53,
            256,
            154,
            142,
            331,
            120,
            265,
            155,
            365,
            185,
            490,
            143,
            156,
            426,
            197,
            260
        ]
    },
    {
        "query": "Access to bigtable.viewer role memebers\n\n        For example:\n\n        .. literalinclude:: snippets.py\n            :start-after: [START bigtable_viewers_policy]\n            :end-before: [END bigtable_viewers_policy]",
        "positive_code": "def bigtable_viewers(self):\n        \n        result = set()\n        for member in self._bindings.get(BIGTABLE_VIEWER_ROLE, ()):\n            result.add(member)\n        return frozenset(result)",
        "hard_negative_ids": [
            493,
            278,
            268,
            80,
            82,
            485,
            174,
            310,
            189,
            349,
            69,
            175,
            293,
            324,
            425,
            283,
            385,
            490,
            238,
            149,
            414,
            76,
            171,
            269,
            131,
            275,
            368,
            376,
            295,
            264,
            157,
            73,
            77,
            245,
            466,
            95,
            53,
            360,
            435,
            1,
            109,
            56,
            472,
            17,
            47,
            416,
            234,
            361,
            391,
            240
        ]
    },
    {
        "query": "Configurable high level options for bowtie.",
        "positive_code": "def _bowtie_args_from_config(data):\n    \n    config = data[]\n    qual_format = config[\"algorithm\"].get(\"quality_format\", \"\")\n    if qual_format.lower() == \"illumina\":\n        qual_flags = [\"--phred64-quals\"]\n    else:\n        qual_flags = []\n    multi_mappers = config[\"algorithm\"].get(\"multiple_mappers\", True)\n    multi_flags = [\"-M\", 1] if multi_mappers else [\"-m\", 1]\n    multi_flags = [] if data[\"analysis\"].lower().startswith(\"smallrna-seq\") else multi_flags\n    cores = config.get(\"resources\", {}).get(\"bowtie\", {}).get(\"cores\", None)\n    num_cores = config[\"algorithm\"].get(\"num_cores\", 1)\n    core_flags = [\"-p\", str(num_cores)] if num_cores > 1 else []\n    return core_flags + qual_flags + multi_flags",
        "hard_negative_ids": [
            130,
            32,
            162,
            26,
            17,
            338,
            385,
            182,
            303,
            13,
            64,
            62,
            109,
            179,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190,
            443,
            145,
            103,
            4,
            344,
            122,
            387,
            246,
            411,
            477,
            15,
            85
        ]
    },
    {
        "query": "Stop tracing mode for all threads in the given process.\n\n        @type  pid: int\n        @param pid: Global ID of process to stop tracing.",
        "positive_code": "def stop_tracing_process(self, pid):\n        \n        for thread in self.system.get_process(pid).iter_threads():\n            self.__stop_tracing(thread)",
        "hard_negative_ids": [
            10,
            102,
            175,
            368,
            197,
            73,
            232,
            81,
            397,
            38,
            466,
            489,
            76,
            414,
            360,
            353,
            204,
            300,
            275,
            256,
            344,
            295,
            245,
            85,
            105,
            79,
            429,
            113,
            461,
            459,
            386,
            116,
            279,
            109,
            133,
            47,
            330,
            291,
            349,
            25,
            99,
            23,
            280,
            142,
            17,
            395,
            411,
            115,
            71,
            496
        ]
    },
    {
        "query": "a private method to read part of an open file into a pandas.DataFrame.\n\n        Parameters\n        ----------\n        f : file object\n        nrows : int\n            number of rows to read\n        names : list\n            names to set the columns of the dataframe with\n        converters : dict\n            dictionary of lambda functions to convert strings\n            to numerical format\n        defaults : dict\n            dictionary of default values to assign columns.\n            Default is None\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame",
        "positive_code": "def _read_df(f,nrows,names,converters,defaults=None):\n        \n        seek_point = f.tell()\n        line = f.readline()\n        raw = line.strip().split()\n        if raw[0].lower() == \"external\":\n            filename = raw[1]\n            assert os.path.exists(filename),\"Pst._read_df() error: external file  not found\".format(filename)\n            df = pd.read_csv(filename,index_col=False,comment=)\n            df.columns = df.columns.str.lower()\n            for name in names:\n                assert name in df.columns,\"Pst._read_df() error: name\" +\\\n                \" not in external file  columns\".format(name,filename)\n                if name in converters:\n                    df.loc[:,name] = df.loc[:,name].apply(converters[name])\n            if defaults is not None:\n                for name in names:\n                    df.loc[:, name] = df.loc[:, name].fillna(defaults[name])\n        else:\n            if nrows is None:\n                raise Exception(\"Pst._read_df() error: non-external sections require nrows\")\n            f.seek(seek_point)\n            df = pd.read_csv(f, header=None,names=names,\n                             nrows=nrows,delim_whitespace=True,\n                             converters=converters, index_col=False,\n                             comment=)\n\n            \n            if df.shape[1] > len(names):\n                df = df.iloc[:,len(names)]\n                df.columns = names\n            isnull = pd.isnull(df)\n            if defaults is not None:\n                for name in names:\n                    df.loc[:,name] = df.loc[:,name].fillna(defaults[name])\n\n            elif np.any(pd.isnull(df).values.flatten()):\n                raise Exception(\"NANs found\")\n            f.seek(seek_point)\n            extras = []\n            for i in range(nrows):\n                line = f.readline()\n                extra = np.NaN\n                if  in line:\n                    raw = line.strip().split()\n                    extra = .join(raw[1:])\n                extras.append(extra)\n\n            df.loc[:,\"extra\"] = extras\n\n        return df",
        "hard_negative_ids": [
            142,
            424,
            239,
            171,
            76,
            168,
            466,
            360,
            178,
            414,
            382,
            349,
            33,
            308,
            412,
            275,
            470,
            23,
            445,
            388,
            235,
            306,
            429,
            2,
            73,
            332,
            103,
            44,
            323,
            391,
            84,
            79,
            405,
            15,
            477,
            425,
            197,
            141,
            449,
            1,
            252,
            41,
            232,
            376,
            402,
            109,
            264,
            56,
            395,
            59
        ]
    },
    {
        "query": "Update the ApplicationInstance\n\n        :param unicode friendly_name: A string to describe the resource\n        :param unicode api_version: The API version to use to start a new TwiML session\n        :param unicode voice_url: The URL to call when the phone number receives a call\n        :param unicode voice_method: The HTTP method to use with the voice_url\n        :param unicode voice_fallback_url: The URL to call when a TwiML error occurs\n        :param unicode voice_fallback_method: The HTTP method to use with voice_fallback_url\n        :param unicode status_callback: The URL to send status information to your application\n        :param unicode status_callback_method: The HTTP method to use to call status_callback\n        :param bool voice_caller_id_lookup: Whether to lookup the caller's name\n        :param unicode sms_url: The URL to call when the phone number receives an incoming SMS message\n        :param unicode sms_method: The HTTP method to use with sms_url\n        :param unicode sms_fallback_url: The URL to call when an error occurs while retrieving or executing the TwiML\n        :param unicode sms_fallback_method: The HTTP method to use with sms_fallback_url\n        :param unicode sms_status_callback: The URL to send status information to your application\n        :param unicode message_status_callback: The URL to send message status information to your application\n\n        :returns: Updated ApplicationInstance\n        :rtype: twilio.rest.api.v2010.account.application.ApplicationInstance",
        "positive_code": "def update(self, friendly_name=values.unset, api_version=values.unset,\n               voice_url=values.unset, voice_method=values.unset,\n               voice_fallback_url=values.unset, voice_fallback_method=values.unset,\n               status_callback=values.unset, status_callback_method=values.unset,\n               voice_caller_id_lookup=values.unset, sms_url=values.unset,\n               sms_method=values.unset, sms_fallback_url=values.unset,\n               sms_fallback_method=values.unset, sms_status_callback=values.unset,\n               message_status_callback=values.unset):\n        \n        return self._proxy.update(\n            friendly_name=friendly_name,\n            api_version=api_version,\n            voice_url=voice_url,\n            voice_method=voice_method,\n            voice_fallback_url=voice_fallback_url,\n            voice_fallback_method=voice_fallback_method,\n            status_callback=status_callback,\n            status_callback_method=status_callback_method,\n            voice_caller_id_lookup=voice_caller_id_lookup,\n            sms_url=sms_url,\n            sms_method=sms_method,\n            sms_fallback_url=sms_fallback_url,\n            sms_fallback_method=sms_fallback_method,\n            sms_status_callback=sms_status_callback,\n            message_status_callback=message_status_callback,\n        )",
        "hard_negative_ids": [
            481,
            360,
            73,
            161,
            414,
            466,
            171,
            16,
            323,
            322,
            264,
            434,
            376,
            429,
            402,
            82,
            81,
            136,
            249,
            207,
            488,
            262,
            44,
            427,
            132,
            389,
            197,
            382,
            122,
            41,
            47,
            191,
            301,
            188,
            204,
            142,
            344,
            327,
            407,
            391,
            291,
            369,
            210,
            9,
            189,
            386,
            70,
            470,
            269,
            38
        ]
    },
    {
        "query": "Confirm that you've done as you were told.  Call this from your control callback to confirm action.\n        Used when you are advertising a control and you want to tell the remote requestor that you have\n        done what they asked you to.\n\n        `Example:` this is a minimal example to show the idea.  Note - no Exception handling and ugly use of globals\n\n            #!python\n            client = None\n\n            def controlreq_cb(args):\n                global client   # the client object you connected with\n\n                # perform your action with the data they sent\n                success = do_control_action(args['data'])\n\n                if args['confirm']:  # you've been asked to confirm\n                    client.confirm_tell(args, success)\n                # else, if you do not confirm_tell() this causes a timeout at the requestor's end.\n\n            client = IOT.Client(config='test.ini')\n            thing = client.create_thing('test321')\n            control = thing.create_control('control', controlreq_cb)\n\n        Raises [IOTException](./Exceptions.m.html#IoticAgent.IOT.Exceptions.IOTException)\n        containing the error if the infrastructure detects a problem\n\n        Raises [LinkException](../Core/AmqpLink.m.html#IoticAgent.Core.AmqpLink.LinkException)\n        if there is a communications problem between you and the infrastructure\n\n        `data` (mandatory) (dictionary)  The `\"args\"` dictionary that your callback was called with\n\n        `success` (mandatory) (boolean)  Whether or not the action you have been asked to do has been\n        sucessful.\n\n        More details on the contents of the `data` dictionary for controls see:\n        [create_control()](./Thing.m.html#IoticAgent.IOT.Thing.Thing.create_control)",
        "positive_code": "def confirm_tell(self, data, success):\n        \n        logger.info(\"confirm_tell(success=%s) [lid=\\\"%s\\\",pid=\\\"%s\\\"]\", success, data[P_ENTITY_LID], data[P_LID])\n        evt = self._request_point_confirm_tell(R_CONTROL, data[P_ENTITY_LID], data[P_LID], success, data[])\n        self._wait_and_except_if_failed(evt)",
        "hard_negative_ids": [
            360,
            189,
            466,
            423,
            291,
            269,
            136,
            47,
            414,
            455,
            73,
            178,
            470,
            349,
            122,
            197,
            329,
            180,
            207,
            23,
            429,
            275,
            421,
            66,
            201,
            391,
            117,
            453,
            382,
            324,
            130,
            308,
            404,
            132,
            69,
            381,
            228,
            147,
            209,
            159,
            219,
            179,
            287,
            424,
            405,
            76,
            488,
            41,
            227,
            499
        ]
    },
    {
        "query": "TODO: rewrite docstring\n        Transform X separately by each transformer, concatenate results.\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features)\n            Input data to be transformed.\n        Returns\n        -------\n        X_t : array-like or sparse matrix, shape (n_samples, sum_n_components)\n            hstack of results of transformers. sum_n_components is the\n            sum of n_components (output dimension) over transformers.",
        "positive_code": "def transform(self, Z):\n        \n        if isinstance(Z, DictRDD):\n            X = Z[:, ]\n        else:\n            X = Z\n\n        Zs = [_transform_one(trans, name, X, self.transformer_weights)\n              for name, trans in self.transformer_list]\n        X_rdd = reduce(lambda x, y: x.zip(y._rdd), Zs)\n        X_rdd = X_rdd.map(flatten)\n        mapper = np.hstack\n        for item in X_rdd.first():\n            if sp.issparse(item):\n                mapper = sp.hstack\n        X_rdd = X_rdd.map(lambda x: mapper(x))\n\n        if isinstance(Z, DictRDD):\n            return DictRDD([X_rdd, Z[:, ]],\n                           columns=Z.columns,\n                           dtype=Z.dtype,\n                           bsize=Z.bsize)\n        else:\n            return X_rdd",
        "hard_negative_ids": [
            46,
            240,
            88,
            263,
            318,
            496,
            32,
            12,
            223,
            256,
            177,
            291,
            287,
            23,
            290,
            466,
            429,
            232,
            349,
            414,
            136,
            152,
            252,
            440,
            185,
            100,
            197,
            462,
            438,
            360,
            470,
            245,
            299,
            376,
            421,
            151,
            452,
            3,
            33,
            317,
            493,
            109,
            201,
            25,
            73,
            2,
            227,
            76,
            267,
            49
        ]
    },
    {
        "query": "Returns the value of the arg (if any) or None.\n        If the arg. is not an integer, an error be triggered.",
        "positive_code": "def argval(self):\n        \n        if self.arg is None or any(x is None for x in self.arg):\n            return None\n\n        for x in self.arg:\n            if not isinstance(x, int):\n                raise InvalidArgError(self.arg)\n\n        return self.arg",
        "hard_negative_ids": [
            360,
            232,
            197,
            73,
            349,
            414,
            466,
            462,
            291,
            23,
            382,
            211,
            404,
            182,
            56,
            429,
            44,
            470,
            189,
            481,
            136,
            267,
            332,
            11,
            269,
            201,
            427,
            91,
            141,
            174,
            386,
            166,
            441,
            32,
            66,
            192,
            222,
            424,
            366,
            423,
            362,
            266,
            52,
            97,
            19,
            242,
            199,
            272,
            254,
            421
        ]
    },
    {
        "query": "Extracts the data from a ModelOutput or ModelGrid object within the bounding box region of the STObject.\n        \n        Args:\n            model_grid: A ModelGrid or ModelOutput Object\n            potential: Extracts from the time before instead of the same time as the object",
        "positive_code": "def extract_attribute_grid(self, model_grid, potential=False, future=False):\n        \n\n        if potential:\n            var_name = model_grid.variable + \"-potential\"\n            timesteps = np.arange(self.start_time - 1, self.end_time)\n        elif future:\n            var_name = model_grid.variable + \"-future\"\n            timesteps = np.arange(self.start_time + 1, self.end_time + 2)\n        else:\n            var_name = model_grid.variable\n            timesteps = np.arange(self.start_time, self.end_time + 1)\n        self.attributes[var_name] = []\n        for ti, t in enumerate(timesteps):\n            self.attributes[var_name].append(\n                model_grid.data[t - model_grid.start_hour, self.i[ti], self.j[ti]])",
        "hard_negative_ids": [
            79,
            470,
            466,
            202,
            360,
            73,
            178,
            414,
            197,
            25,
            297,
            124,
            349,
            147,
            291,
            421,
            429,
            391,
            287,
            112,
            324,
            488,
            425,
            136,
            106,
            269,
            41,
            304,
            201,
            490,
            113,
            219,
            58,
            256,
            223,
            11,
            24,
            26,
            283,
            453,
            23,
            141,
            179,
            395,
            193,
            498,
            385,
            317,
            81,
            7
        ]
    },
    {
        "query": "Removes primitive type tags from an XPATH",
        "positive_code": "def _trim_xpath(self, xpath, prop):\n        \n\n        xroot = self._get_xroot_for(prop)\n\n        if xroot is None and isinstance(xpath, string_types):\n            xtags = xpath.split(XPATH_DELIM)\n\n            if xtags[-1] in _iso_tag_primitives:\n                xroot = XPATH_DELIM.join(xtags[:-1])\n\n        return xroot",
        "hard_negative_ids": [
            475,
            379,
            483,
            69,
            149,
            232,
            147,
            189,
            500,
            311,
            280,
            73,
            279,
            193,
            360,
            133,
            7,
            115,
            26,
            20,
            332,
            367,
            131,
            411,
            11,
            273,
            226,
            353,
            117,
            427,
            74,
            303,
            431,
            153,
            1,
            113,
            67,
            393,
            96,
            185,
            414,
            17,
            38,
            76,
            374,
            178,
            231,
            345,
            199,
            208
        ]
    },
    {
        "query": "Resolves a variable out of context if it's not in quotes",
        "positive_code": "def resolve(self, var, context):\n        \n        if var is None:\n            return var\n        if var[0] in (, \"'\") and var[-1] == var[0]:\n            return var[1:-1]\n        else:\n            return template.Variable(var).resolve(context)",
        "hard_negative_ids": [
            373,
            423,
            244,
            323,
            324,
            269,
            435,
            129,
            330,
            375,
            349,
            179,
            470,
            390,
            15,
            386,
            178,
            163,
            106,
            197,
            304,
            462,
            466,
            391,
            157,
            69,
            232,
            131,
            439,
            383,
            395,
            477,
            360,
            317,
            453,
            425,
            149,
            153,
            366,
            76,
            77,
            407,
            272,
            171,
            201,
            429,
            90,
            326,
            222,
            173
        ]
    },
    {
        "query": "Makes informative labels if variable metadata (attrs) follows\n        CF conventions.",
        "positive_code": "def label_from_attrs(da, extra=):\n    \n\n    if da.attrs.get():\n        name = da.attrs[]\n    elif da.attrs.get():\n        name = da.attrs[]\n    elif da.name is not None:\n        name = da.name\n    else:\n        name = \n\n    if da.attrs.get():\n        units = .format(da.attrs[])\n    else:\n        units = \n\n    return .join(textwrap.wrap(name + extra + units, 30))",
        "hard_negative_ids": [
            84,
            373,
            324,
            171,
            184,
            271,
            500,
            451,
            369,
            136,
            12,
            179,
            100,
            421,
            423,
            498,
            380,
            170,
            441,
            326,
            454,
            371,
            38,
            128,
            146,
            221,
            479,
            481,
            155,
            94,
            185,
            176,
            382,
            402,
            413,
            345,
            48,
            462,
            198,
            150,
            191,
            24,
            301,
            144,
            268,
            174,
            222,
            4,
            230,
            182
        ]
    },
    {
        "query": "D.files() -> List of the files in this directory.\n\n        The elements of the list are Path objects.\n        This does not walk into subdirectories (see :meth:`walkfiles`).\n\n        Accepts parameters to :meth:`listdir`.",
        "positive_code": "def files(self, *args, **kwargs):\n        \n\n        return [p for p in self.listdir(*args, **kwargs) if p.isfile()]",
        "hard_negative_ids": [
            363,
            466,
            414,
            275,
            38,
            144,
            429,
            360,
            2,
            234,
            388,
            136,
            197,
            73,
            402,
            190,
            23,
            291,
            44,
            171,
            25,
            79,
            405,
            189,
            166,
            47,
            470,
            433,
            349,
            329,
            193,
            163,
            77,
            170,
            31,
            456,
            461,
            254,
            348,
            27,
            264,
            424,
            252,
            318,
            232,
            90,
            395,
            490,
            34,
            246
        ]
    },
    {
        "query": "Get the shared widget action for this widget.\n\n        This API is used to support widgets in tool bars and menus.\n\n        Parameters\n        ----------\n        create : bool, optional\n            Whether to create the action if it doesn't already exist.\n            The default is False.\n\n        Returns\n        -------\n        result : QWidgetAction or None\n            The cached widget action or None, depending on arguments.",
        "positive_code": "def get_action(self, create=False):\n        \n        action = self._widget_action\n        if action is None and create:\n            action = self._widget_action = QWidgetAction(None)\n            action.setDefaultWidget(self.widget)\n        return action",
        "hard_negative_ids": [
            329,
            424,
            325,
            132,
            280,
            209,
            429,
            414,
            314,
            73,
            291,
            136,
            255,
            360,
            460,
            90,
            168,
            47,
            459,
            269,
            435,
            306,
            451,
            76,
            452,
            260,
            151,
            170,
            466,
            197,
            179,
            12,
            223,
            69,
            405,
            189,
            84,
            275,
            295,
            130,
            496,
            2,
            326,
            499,
            292,
            462,
            39,
            23,
            345,
            185
        ]
    },
    {
        "query": "The trick for iterable Mambu Objects comes here:\n\n        You iterate over each element of the responded List from Mambu,\n        and create a Mambu Role (or your own itemclass) object for each\n        one, initializing them one at a time, and changing the attrs\n        attribute (which just holds a list of plain dictionaries) with a\n        MambuUser (or your own itemclass) just created.",
        "positive_code": "def convertDict2Attrs(self, *args, **kwargs):\n        \n        for n,u in enumerate(self.attrs):\n            try:\n                params = self.params\n            except AttributeError as aerr:\n                params = {}\n            kwargs.update(params)\n            try:\n                role = self.mamburoleclass(urlfunc=None, entid=None, *args, **kwargs)\n            except AttributeError as ae:\n                self.mamburoleclass = MambuRole\n                role = self.mamburoleclass(urlfunc=None, entid=None, *args, **kwargs)\n            role.init(u, *args, **kwargs)\n            self.attrs[n] = role",
        "hard_negative_ids": [
            91,
            470,
            360,
            466,
            84,
            287,
            77,
            414,
            136,
            349,
            79,
            295,
            291,
            433,
            232,
            325,
            391,
            25,
            461,
            131,
            348,
            197,
            170,
            146,
            202,
            106,
            178,
            304,
            425,
            459,
            73,
            269,
            429,
            293,
            24,
            490,
            193,
            81,
            382,
            317,
            113,
            23,
            453,
            201,
            308,
            462,
            179,
            297,
            58,
            15
        ]
    },
    {
        "query": "aligns epis to anatomy using ``align_epi_anat.py`` script\n\n    :epi_dsets:       can be either a string or list of strings of the epi child datasets\n    :skull_strip_anat:     if ``True``, ``anatomy`` will be skull-stripped using the default method\n\n    The default output suffix is \"_al\"",
        "positive_code": "def align_epi_anat(anatomy,epi_dsets,skull_strip_anat=True):\n    \n\n    if isinstance(epi_dsets,basestring):\n        epi_dsets = [epi_dsets]\n\n    if len(epi_dsets)==0:\n        nl.notify( % anatomy,level=nl.level.warning)\n        return\n\n    if all(os.path.exists(nl.suffix(x,)) for x in epi_dsets):\n        return\n\n    anatomy_use = anatomy\n\n    if skull_strip_anat:\n        nl.skull_strip(anatomy,)\n        anatomy_use = nl.suffix(anatomy,)\n\n    inputs = [anatomy_use] + epi_dsets\n    dset_products = lambda dset: [nl.suffix(dset,), nl.prefix(dset)+, nl.prefix(dset)+]\n    products = nl.flatten([dset_products(dset) for dset in epi_dsets])\n    with nl.run_in_tmp(inputs,products):\n        if nl.is_nifti(anatomy_use):\n            anatomy_use = nl.afni_copy(anatomy_use)\n        epi_dsets_use = []\n        for dset in epi_dsets:\n            if nl.is_nifti(dset):\n                epi_dsets_use.append(nl.afni_copy(dset))\n            else:\n                epi_dsets_use.append(dset)\n        cmd = [\"align_epi_anat.py\", \"-epi2anat\", \"-anat_has_skull\", \"no\", \"-epi_strip\", \"3dAutomask\",\"-anat\", anatomy_use, \"-epi_base\", \"5\", \"-epi\", epi_dsets_use[0]]\n        if len(epi_dsets_use)>1:\n            cmd += [] + epi_dsets_use[1:]\n            out = nl.run(cmd)\n\n        for dset in epi_dsets:\n            if nl.is_nifti(dset):\n                dset_nifti = nl.nifti_copy(nl.prefix(dset)+)\n                if dset_nifti and os.path.exists(dset_nifti) and dset_nifti.endswith() and dset.endswith():\n                    nl.run([,dset_nifti])",
        "hard_negative_ids": [
            360,
            166,
            291,
            168,
            210,
            306,
            424,
            413,
            40,
            466,
            232,
            136,
            388,
            477,
            470,
            342,
            323,
            197,
            84,
            73,
            405,
            99,
            76,
            255,
            349,
            414,
            429,
            376,
            165,
            23,
            97,
            41,
            228,
            44,
            462,
            382,
            144,
            391,
            264,
            402,
            171,
            386,
            70,
            227,
            182,
            254,
            252,
            139,
            425,
            304
        ]
    },
    {
        "query": "r\"\"\"Finds executable `name`.\n\n    Similar to Unix ``which`` command.\n\n    Returns list of zero or more full paths to `name`.",
        "positive_code": "def find_executable(name: str, flags=os.X_OK) -> List[str]:\n    r\n    result = []\n    extensions = [x for x in os.environ.get(\"PATHEXT\", \"\").split(os.pathsep) if x]\n    path = os.environ.get(\"PATH\", None)\n    if path is None:\n        return []\n    for path in os.environ.get(\"PATH\", \"\").split(os.pathsep):\n        path = os.path.join(path, name)\n        if os.access(path, flags):\n            result.append(path)\n        for extension in extensions:\n            path_extension = path + extension\n            if os.access(path_extension, flags):\n                result.append(path_extension)\n    return result",
        "hard_negative_ids": [
            444,
            36,
            261,
            498,
            466,
            368,
            146,
            166,
            176,
            269,
            179,
            394,
            77,
            150,
            386,
            236,
            65,
            131,
            73,
            385,
            66,
            189,
            412,
            349,
            76,
            454,
            144,
            86,
            182,
            295,
            264,
            127,
            366,
            353,
            191,
            171,
            306,
            329,
            143,
            34,
            197,
            280,
            429,
            395,
            456,
            260,
            472,
            230,
            170,
            275
        ]
    },
    {
        "query": "Log an error message and exit.\n\n    Following arguments are keyword-only.\n\n    :param exitcode: Optional exit code to use\n    :param cause: Optional Invoke's Result object, i.e.\n                  result of a subprocess invocation",
        "positive_code": "def fatal(*args, **kwargs):\n    \n    \n    exitcode = None\n    if  in kwargs:\n        exitcode = kwargs.pop()\n    if  in kwargs:\n        cause = kwargs.pop()\n        if not isinstance(cause, Result):\n            raise TypeError(\n                \"invalid cause of fatal error: expected %r, got %r\" % (\n                    Result, type(cause)))\n        exitcode = exitcode or cause.return_code\n\n    logging.error(*args, **kwargs)\n    raise Exit(exitcode or -1)",
        "hard_negative_ids": [
            435,
            264,
            360,
            81,
            460,
            79,
            427,
            173,
            275,
            488,
            300,
            262,
            452,
            223,
            423,
            429,
            201,
            390,
            151,
            307,
            470,
            266,
            34,
            47,
            301,
            69,
            197,
            339,
            329,
            73,
            369,
            226,
            466,
            317,
            462,
            2,
            344,
            349,
            37,
            363,
            204,
            254,
            443,
            124,
            320,
            178,
            391,
            245,
            122,
            414
        ]
    },
    {
        "query": "Returns a list of all the values for the named field. Returns an\n        empty list if the key doesn't exist.",
        "positive_code": "def getlist(self, key):\n        \n        try:\n            vals = _dict_getitem(self, key.lower())\n        except KeyError:\n            return []\n        else:\n            if isinstance(vals, tuple):\n                return [vals[1]]\n            else:\n                return vals[1:]",
        "hard_negative_ids": [
            280,
            332,
            360,
            15,
            196,
            466,
            142,
            90,
            197,
            8,
            414,
            45,
            349,
            267,
            44,
            476,
            73,
            76,
            278,
            382,
            429,
            387,
            25,
            291,
            11,
            174,
            327,
            230,
            23,
            395,
            222,
            239,
            470,
            442,
            232,
            48,
            237,
            106,
            304,
            85,
            97,
            136,
            333,
            189,
            424,
            410,
            116,
            472,
            462,
            56
        ]
    },
    {
        "query": "Get the policy for untranslated content",
        "positive_code": "def untranslated_policy(self, default):\n        \n        return self.generator.settings.get(self.info.get(, None),\n                                           default)",
        "hard_negative_ids": [
            273,
            62,
            421,
            275,
            360,
            414,
            73,
            197,
            291,
            498,
            466,
            326,
            136,
            82,
            280,
            389,
            429,
            44,
            114,
            6,
            23,
            315,
            25,
            295,
            402,
            382,
            452,
            463,
            113,
            373,
            371,
            442,
            285,
            72,
            4,
            369,
            432,
            180,
            105,
            130,
            61,
            383,
            426,
            254,
            50,
            420,
            9,
            109,
            20,
            15
        ]
    },
    {
        "query": "Return the data as 2D numpy.ndarray.\n\n        Parameters\n        ----------\n        chan : int or list\n            index (indices) of the channels to read\n        begsam : int\n            index of the first sample\n        endsam : int\n            index of the last sample\n\n        Returns\n        -------\n        numpy.ndarray\n            A 2d matrix, with dimension chan X samples",
        "positive_code": "def return_dat(self, chan, begsam, endsam):\n        \n        if begsam < 0:\n            begpad = -1 * begsam\n            begsam = 0\n        else:\n            begpad = 0\n\n        if endsam > self.n_smp:\n            endpad = endsam - self.n_smp\n            endsam = self.n_smp\n        else:\n            endpad = 0\n\n        first_sam = DATA_PRECISION * self.n_chan * begsam\n        toread_sam = DATA_PRECISION * self.n_chan * (endsam - begsam)\n\n        with open(join(self.filename, EEG_FILE), ) as f:\n            f.seek(first_sam)\n            x = f.read(toread_sam)\n\n        dat = _read_dat(x)\n        dat = reshape(dat, (self.n_chan, -1), )\n        dat = self.convertion(dat[chan, :])\n        dat = pad(dat, ((0, 0), (begpad, endpad)),\n                  mode=, constant_values=NaN)\n\n        return dat",
        "hard_negative_ids": [
            263,
            268,
            466,
            493,
            79,
            360,
            347,
            403,
            414,
            349,
            23,
            271,
            233,
            197,
            218,
            391,
            177,
            239,
            240,
            279,
            448,
            285,
            429,
            152,
            272,
            496,
            252,
            256,
            291,
            470,
            421,
            73,
            326,
            25,
            76,
            462,
            195,
            449,
            386,
            141,
            245,
            58,
            267,
            82,
            410,
            416,
            472,
            361,
            163,
            136
        ]
    },
    {
        "query": "Plot the directed acyclic graph (dag) to represent operation dependencies\n    in a quantum circuit.\n\n    Note this function leverages\n    `pydot <https://github.com/erocarrera/pydot>`_ (via\n    `nxpd <https://github.com/chebee7i/nxpd`_) to generate the graph, which\n    means that having `Graphviz <https://www.graphviz.org/>`_ installed on your\n    system is required for this to work.\n\n    Args:\n        dag (DAGCircuit): The dag to draw.\n        scale (float): scaling factor\n        filename (str): file path to save image to (format inferred from name)\n        style (str): 'plain': B&W graph\n                     'color' (default): color input/output/op nodes\n\n    Returns:\n        Ipython.display.Image: if in Jupyter notebook and not saving to file,\n            otherwise None.\n\n    Raises:\n        VisualizationError: when style is not recognized.\n        ImportError: when nxpd or pydot not installed.",
        "positive_code": "def dag_drawer(dag, scale=0.7, filename=None, style=):\n    \n    try:\n        import nxpd\n        import pydot  \n    except ImportError:\n        raise ImportError(\"dag_drawer requires nxpd, pydot, and Graphviz. \"\n                          \"Run , and install graphviz\")\n\n    G = dag.to_networkx()\n    G.graph[] = 100 * scale\n\n    if style == :\n        pass\n    elif style == :\n        for node in G.nodes:\n            n = G.nodes[node]\n            n[] = node.name\n            if node.type == :\n                n[] = \n                n[] = \n                n[] = \n            if node.type == :\n                n[] = \n                n[] = \n                n[] = \n            if node.type == :\n                n[] = \n                n[] = \n                n[] = \n        for e in G.edges(data=True):\n            e[2][] = e[2][]\n    else:\n        raise VisualizationError(\"Unrecognized style for the dag_drawer.\")\n\n    if filename:\n        show = False\n    elif ( in sys.modules) and ( not in sys.modules):\n        show = \n    else:\n        show = True\n\n    return nxpd.draw(G, filename=filename, show=show)",
        "hard_negative_ids": [
            391,
            47,
            168,
            171,
            159,
            429,
            500,
            73,
            207,
            265,
            360,
            431,
            414,
            235,
            466,
            363,
            264,
            15,
            12,
            275,
            401,
            136,
            376,
            60,
            276,
            23,
            36,
            254,
            464,
            38,
            169,
            457,
            24,
            106,
            317,
            373,
            269,
            222,
            71,
            291,
            162,
            252,
            345,
            424,
            76,
            197,
            56,
            364,
            405,
            42
        ]
    },
    {
        "query": "Looking for auth in env, cmdline, str\n        :param list_or_file_path:\n        :param source:",
        "positive_code": "def search_auth(self, list_or_file_path, source):\n        \n        _auth = source.args[]\n        if isinstance(_auth, str):\n            if  in _auth:\n                _auth = _auth.split()\n            elif _auth.endswith() and (\n                    _auth.startswith() or  in _auth):  \n                _auth = self.get_auth(list_or_file_path, _auth)\n                _auth = self.split_auth(_auth)\n\n        if isinstance(_auth, list):\n            for i in range(len(_auth)):\n                if _auth[i].endswith() and (\n                        _auth[i].startswith() or  in _auth[i]):  \n                    _auth[i] = self.get_auth(list_or_file_path, _auth[i])\n                    if  in _auth[i]:\n                        _auth = self.split_auth(_auth[i])\n\n        source.args[] = _auth",
        "hard_negative_ids": [
            123,
            81,
            103,
            470,
            204,
            344,
            117,
            5,
            8,
            300,
            293,
            131,
            181,
            425,
            27,
            369,
            222,
            190,
            379,
            59,
            183,
            84,
            127,
            412,
            340,
            345,
            435,
            63,
            481,
            68,
            165,
            339,
            94,
            402,
            450,
            393,
            367,
            91,
            23,
            135,
            239,
            331,
            490,
            265,
            237,
            52,
            57,
            321,
            305,
            489
        ]
    },
    {
        "query": "Delete data by offset to count letters.",
        "positive_code": "def deleteData(self, offset: int, count: int) -> None:\n        \n        self._delete_data(offset, count)",
        "hard_negative_ids": [
            165,
            162,
            105,
            421,
            291,
            43,
            223,
            294,
            187,
            252,
            13,
            329,
            450,
            498,
            33,
            195,
            357,
            361,
            85,
            424,
            154,
            440,
            283,
            492,
            484,
            393,
            429,
            78,
            324,
            171,
            149,
            163,
            256,
            269,
            22,
            12,
            141,
            131,
            368,
            376,
            295,
            414,
            264,
            189,
            73,
            383,
            285,
            275,
            466,
            360
        ]
    },
    {
        "query": "Generates a list of all Tasks.",
        "positive_code": "def tasks(self):\n        \n        tasks_response = self.get_request()\n        return [Task(self, tjson[]) for tjson in tasks_response]",
        "hard_negative_ids": [
            354,
            470,
            349,
            76,
            414,
            106,
            85,
            304,
            116,
            391,
            466,
            142,
            395,
            453,
            178,
            47,
            232,
            317,
            425,
            295,
            360,
            77,
            2,
            171,
            15,
            272,
            25,
            429,
            88,
            197,
            328,
            267,
            201,
            23,
            256,
            318,
            332,
            382,
            477,
            237,
            183,
            410,
            462,
            157,
            260,
            98,
            290,
            222,
            110,
            81
        ]
    },
    {
        "query": "Delete an exchange.",
        "positive_code": "def delete(self, exchange, if_unused=False, nowait=True, ticket=None,\n               cb=None):\n        \n        nowait = nowait and self.allow_nowait() and not cb\n\n        args = Writer()\n        args.write_short(ticket or self.default_ticket).\\\n            write_shortstr(exchange).\\\n            write_bits(if_unused, nowait)\n        self.send_frame(MethodFrame(self.channel_id, 40, 20, args))\n\n        if not nowait:\n            self._delete_cb.append(cb)\n            self.channel.add_synchronous_cb(self._recv_delete_ok)",
        "hard_negative_ids": [
            187,
            13,
            450,
            189,
            360,
            429,
            427,
            73,
            329,
            414,
            17,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458
        ]
    },
    {
        "query": "Return a range of members in a sorted set, by score,\n        with scores ordered from high to low.\n\n        :raises TypeError: if min or max is not float or int\n        :raises TypeError: if both offset and count are not specified\n        :raises TypeError: if offset is not int\n        :raises TypeError: if count is not int",
        "positive_code": "def zrevrangebyscore(self, key, max=float(), min=float(),\n                         *, exclude=None, withscores=False,\n                         offset=None, count=None, encoding=_NOTSET):\n        \n        if not isinstance(min, (int, float)):\n            raise TypeError(\"min argument must be int or float\")\n        if not isinstance(max, (int, float)):\n            raise TypeError(\"max argument must be int or float\")\n\n        if (offset is not None and count is None) or \\\n                (count is not None and offset is None):\n            raise TypeError(\"offset and count must both be specified\")\n        if offset is not None and not isinstance(offset, int):\n            raise TypeError(\"offset argument must be int\")\n        if count is not None and not isinstance(count, int):\n            raise TypeError(\"count argument must be int\")\n\n        min, max = _encode_min_max(exclude, min, max)\n\n        args = []\n        if withscores:\n            args = [b]\n        if offset is not None and count is not None:\n            args.extend([b, offset, count])\n        fut = self.execute(b, key, max, min, *args,\n                           encoding=encoding)\n        if withscores:\n            return wait_convert(fut, pairs_int_or_float)\n        return fut",
        "hard_negative_ids": [
            162,
            105,
            165,
            12,
            179,
            470,
            361,
            17,
            291,
            295,
            141,
            252,
            462,
            349,
            73,
            318,
            382,
            106,
            360,
            386,
            222,
            80,
            43,
            466,
            23,
            307,
            391,
            171,
            211,
            425,
            149,
            294,
            452,
            345,
            304,
            365,
            232,
            272,
            11,
            147,
            499,
            329,
            331,
            25,
            56,
            178,
            490,
            76,
            269,
            192
        ]
    },
    {
        "query": "Schematics serializer override\n\n        If epoch_date is true then convert the `datetime.datetime`\n        object into an epoch `int`.",
        "positive_code": "def to_primitive(self, value, context=None):\n        \n\n        if context and context.get():\n            epoch = dt(1970, 1, 1)\n            value = (value - epoch).total_seconds()\n            return int(value)\n        elif context and context.get():\n            return value\n        else:\n            return super(Type, self).to_primitive(value, context)",
        "hard_negative_ids": [
            221,
            460,
            79,
            360,
            414,
            73,
            81,
            197,
            297,
            470,
            386,
            189,
            113,
            211,
            466,
            291,
            136,
            429,
            44,
            147,
            252,
            307,
            141,
            40,
            427,
            23,
            489,
            345,
            423,
            361,
            416,
            25,
            450,
            268,
            58,
            298,
            380,
            195,
            329,
            105,
            17,
            41,
            37,
            462,
            99,
            50,
            490,
            351,
            421,
            224
        ]
    },
    {
        "query": "Method to query :class:`.models.AlternativeShortlName` objects in database\n\n        :param name: alternative short name(s)\n        :type name: str or tuple(str) or None\n\n        :param entry_name: name(s) in :class:`.models.Entry`\n        :type entry_name: str or tuple(str) or None\n\n        :param limit:\n            - if `isinstance(limit,int)==True` -> limit\n            - if `isinstance(limit,tuple)==True` -> format:= tuple(page_number, results_per_page)\n            - if limit == None -> all results\n        :type limit: int or tuple(int) or None\n\n        :param bool as_df: if `True` results are returned as :class:`pandas.DataFrame`\n\n        :return:\n            - if `as_df == False` -> list(:class:`.models.AlternativeShortName`)\n            - if `as_df == True`  -> :class:`pandas.DataFrame`\n        :rtype: list(:class:`.models.AlternativeShortName`) or :class:`pandas.DataFrame`",
        "positive_code": "def alternative_short_name(self, name=None, entry_name=None, limit=None, as_df=False):\n        \n        q = self.session.query(models.AlternativeShortName)\n\n        model_queries_config = (\n            (name, models.AlternativeShortName.name),\n        )\n        q = self.get_model_queries(q, model_queries_config)\n\n        q = self.get_one_to_many_queries(q, ((entry_name, models.Entry.name),))\n\n        return self._limit_and_df(q, limit, as_df)",
        "hard_negative_ids": [
            76,
            312,
            81,
            152,
            386,
            239,
            360,
            267,
            33,
            89,
            201,
            333,
            489,
            137,
            193,
            84,
            345,
            222,
            498,
            246,
            329,
            182,
            412,
            127,
            198,
            77,
            113,
            32,
            179,
            2,
            402,
            151,
            226,
            199,
            15,
            323,
            344,
            326,
            211,
            462,
            290,
            232,
            273,
            275,
            297,
            450,
            176,
            331,
            20,
            279
        ]
    },
    {
        "query": "stub",
        "positive_code": "def add_zone_condition(self, droppable_id, zone_id, match=True):\n        \n        self.my_osid_object_form._my_map[].append(\n            {: droppable_id, : zone_id, : match})\n        self.my_osid_object_form._my_map[].sort(key=lambda k: k[])",
        "hard_negative_ids": [
            500,
            499,
            498,
            497,
            496,
            495,
            494,
            493,
            492,
            491,
            490,
            489,
            488,
            487,
            486,
            485,
            484,
            483,
            482,
            481,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453,
            452,
            451
        ]
    },
    {
        "query": "Setup logging configuration",
        "positive_code": "def setup_logging(default_json_path=None, default_level=None, env_key=,\n                  custom_log_dir=None):\n    \n\n    if not default_json_path:\n        default_json_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)), \"logging.json\")\n    path = default_json_path\n    value = os.getenv(env_key, None)\n    if value:\n        path = value\n\n    if os.path.exists(path):\n        with open(path, ) as f:\n            config = json.load(f)\n\n        log_dir = os.path.abspath(prms.Paths[\"filelogdir\"])\n\n        if custom_log_dir:\n            log_dir = custom_log_dir\n\n        if not os.path.isdir(log_dir):\n            warning_txt = (\"\\nCould not set custom log-dir - \"\n                           \"non-existing directory\"\n                           f\"\\nDir: {log_dir}\"\n                           \"\\nUsing current directory instead: \"\n                           f\"{os.getcwd()}\")\n            logging.warning(warning_txt)\n            log_dir = os.getcwd()\n\n        for file_handler in [\"error_file_handler\", \"info_file_handler\",\n                             \"debug_file_handler\"]:\n            try:\n                file_name = config[\"handlers\"][file_handler][\"filename\"]\n                logging.debug(\"Setting file handlers for logging.\")\n                logging.debug(f\"Filename: {file_name}\")\n                logging.debug(f\"Full path: {os.path.join(log_dir,file_name)}\")\n                \n                \n                config[\"handlers\"][file_handler][\n                    \"filename\"] = os.path.join(log_dir,\n                                               file_name)\n            except Exception as e:\n                warnings.warn(\"\\nCould not set custom log-dir\" + str(e))\n\n        if default_level:\n            w_txt = \"\\nCould not set custom default level for logger\"\n            if default_level not in [\n                \"INFO\", \"DEBUG\", logging.INFO, logging.DEBUG\n            ]:\n                _txt = \"\\nonly  and  is supported\"\n                _txt += \" as default_level\"\n                warnings.warn(w_txt + _txt)\n\n            else:\n                try:\n                    config[\"handlers\"][\"console\"][\"level\"] = default_level\n                    if default_level in [\"DEBUG\", logging.DEBUG]:\n                        config[\"handlers\"][\"console\"][\"formatter\"] = \"stamped\"\n\n                except Exception as e:\n                    warnings.warn(w_txt + \"\\n\" + str(e))\n\n        logging.config.dictConfig(config)\n    else:\n        if not default_level:\n            default_level = logging.INFO\n        logging.basicConfig(level=default_level)",
        "hard_negative_ids": [
            213,
            488,
            422,
            130,
            427,
            113,
            344,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454
        ]
    },
    {
        "query": "Transform a list of bag features into its bag-of-words representation.\n\n        Parameters\n        ----------\n        X : :class:`skl_groups.features.Features` or list of bag feature arrays\n            New data to transform.\n\n        Returns\n        -------\n        X_new : integer array, shape [len(X), kmeans.n_clusters]\n            X transformed into the new space.",
        "positive_code": "def transform(self, X):\n        \n        self._check_fitted()\n        X = as_features(X, stack=True)\n        assignments = self.kmeans_fit_.predict(X.stacked_features)\n        return self._group_assignments(X, assignments)",
        "hard_negative_ids": [
            212,
            199,
            440,
            240,
            82,
            263,
            88,
            466,
            256,
            313,
            76,
            349,
            318,
            267,
            152,
            120,
            58,
            462,
            25,
            317,
            3,
            245,
            23,
            149,
            12,
            49,
            360,
            499,
            472,
            391,
            77,
            421,
            186,
            197,
            470,
            414,
            429,
            290,
            100,
            299,
            46,
            495,
            81,
            426,
            185,
            211,
            333,
            424,
            395,
            73
        ]
    },
    {
        "query": "The Security event message is used to indicate events that apply to a security. A Security event message will be sent whenever such event occurs\n\n    https://iexcloud.io/docs/api/#deep-security-event\n\n    Args:\n        symbol (string); Ticker to request\n        token (string); Access token\n        version (string); API version\n\n    Returns:\n        DataFrame: result",
        "positive_code": "def securityEventDF(symbol=None, token=, version=):\n    \n    x = securityEvent(symbol, token, version)\n    data = []\n    for key in x:\n        d = x[key]\n        d[] = key\n        data.append(d)\n    df = pd.DataFrame(data)\n    _toDatetime(df)\n    return df",
        "hard_negative_ids": [
            488,
            207,
            314,
            257,
            210,
            189,
            372,
            360,
            327,
            413,
            73,
            40,
            185,
            429,
            147,
            342,
            156,
            323,
            265,
            330,
            237,
            264,
            262,
            466,
            391,
            425,
            112,
            33,
            222,
            301,
            37,
            203,
            269,
            386,
            500,
            159,
            131,
            139,
            491,
            349,
            418,
            382,
            171,
            202,
            462,
            151,
            452,
            223,
            414,
            23
        ]
    },
    {
        "query": "Identify user using Authenticate header with Token auth.",
        "positive_code": "def identify(self, req, resp, resource, uri_kwargs):\n        \n        header = req.get_header(, False)\n        auth = header.split() if header else None\n\n        if auth is None or auth[0].lower() != :\n            return None\n\n        if len(auth) != 2:\n            raise HTTPBadRequest(\n                \"Invalid Authorization header\",\n                \"The Authorization header for Token auth should be in form:\\n\"\n                \"Authorization: Token <token_value>\"\n            )\n\n        return auth[1]",
        "hard_negative_ids": [
            223,
            166,
            123,
            425,
            323,
            131,
            470,
            228,
            189,
            283,
            203,
            187,
            55,
            265,
            185,
            103,
            300,
            415,
            198,
            112,
            236,
            291,
            349,
            174,
            264,
            360,
            170,
            44,
            173,
            293,
            96,
            148,
            68,
            434,
            74,
            269,
            59,
            439,
            468,
            397,
            128,
            404,
            99,
            374,
            1,
            149,
            391,
            179,
            34,
            163
        ]
    },
    {
        "query": "Convert XY positions into sky coordinates using STWCS methods.",
        "positive_code": "def generateRaDec(self):\n        \n        self.prefix = self.PAR_PREFIX\n\n        if not isinstance(self.wcs,pywcs.WCS):\n            print(\n                textutil.textbox(\n                    \n                    \n                    ),\n                file=sys.stderr\n            )\n            raise ValueError\n\n        if self.xypos is None or len(self.xypos[0]) == 0:\n            self.xypos = None\n            warnstr = textutil.textbox(\n                \n                \n            )\n\n            for line in warnstr.split():\n                log.warning(line)\n\n            print(warnstr)\n            return\n\n        if self.radec is None:\n            print(.format(len(self.xypos[0])))\n            if self.wcs is not None:\n                ra, dec = self.wcs.all_pix2world(self.xypos[0], self.xypos[1], self.origin)\n                self.radec = [ra, dec] + copy.deepcopy(self.xypos[2:])\n            else:\n                \n                \n                self.radec = copy.deepcopy(self.xypos)",
        "hard_negative_ids": [
            67,
            166,
            323,
            20,
            228,
            125,
            12,
            41,
            70,
            139,
            360,
            402,
            291,
            264,
            44,
            99,
            434,
            87,
            23,
            25,
            24,
            22,
            21,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457
        ]
    },
    {
        "query": "Get list of collections from kwdb, then add urls necessary for hyperlinks",
        "positive_code": "def get_collections(kwdb, libtype=\"*\"):\n    \n    collections = kwdb.get_collections(libtype=libtype)\n    for result in collections:\n        url = flask.url_for(\".doc_for_library\", collection_id=result[\"collection_id\"])\n        result[\"url\"] = url\n\n    return collections",
        "hard_negative_ids": [
            272,
            71,
            215,
            389,
            118,
            443,
            421,
            402,
            429,
            127,
            453,
            113,
            463,
            232,
            349,
            289,
            395,
            39,
            193,
            153,
            498,
            326,
            470,
            322,
            9,
            7,
            369,
            466,
            26,
            77,
            192,
            38,
            161,
            2,
            367,
            131,
            267,
            11,
            187,
            357,
            230,
            339,
            157,
            73,
            185,
            364,
            197,
            82,
            69,
            328
        ]
    },
    {
        "query": "Set the parameters of this estimator.\n        Modification of the sklearn method to allow unknown kwargs. This allows using\n        the full range of xgboost parameters that are not defined as member variables\n        in sklearn grid search.\n        Returns\n        -------\n        self",
        "positive_code": "def set_params(self, **params):\n        \n        if not params:\n            \n            return self\n\n        for key, value in params.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n            else:\n                self.kwargs[key] = value\n\n        return self",
        "hard_negative_ids": [
            360,
            204,
            466,
            414,
            156,
            166,
            482,
            264,
            429,
            323,
            23,
            291,
            41,
            197,
            349,
            373,
            139,
            25,
            324,
            478,
            189,
            136,
            90,
            269,
            452,
            109,
            44,
            470,
            98,
            73,
            212,
            318,
            47,
            179,
            232,
            228,
            395,
            295,
            53,
            70,
            16,
            157,
            396,
            402,
            77,
            333,
            135,
            272,
            5,
            45
        ]
    },
    {
        "query": "Save a (raw) file to the store.",
        "positive_code": "def save_file(self, srcfile):\n        \n        filehash = digest_file(srcfile)\n        if not os.path.exists(self.object_path(filehash)):\n            \n            \n            tmppath = self.temporary_object_path(filehash)\n            copyfile(srcfile, tmppath)\n            self._move_to_store(tmppath, filehash)\n\n        return filehash",
        "hard_negative_ids": [
            171,
            360,
            467,
            414,
            452,
            363,
            466,
            376,
            73,
            409,
            106,
            304,
            44,
            391,
            23,
            197,
            275,
            264,
            291,
            453,
            273,
            178,
            317,
            425,
            260,
            136,
            269,
            15,
            163,
            131,
            76,
            1,
            144,
            429,
            368,
            470,
            295,
            189,
            169,
            256,
            99,
            382,
            277,
            25,
            462,
            109,
            47,
            222,
            349,
            472
        ]
    },
    {
        "query": "Get html for a form to submit this request to the IDP.\n\n        @param form_tag_attrs: Dictionary of attributes to be added to\n            the form tag. 'accept-charset' and 'enctype' have defaults\n            that can be overridden. If a value is supplied for\n            'action' or 'method', it will be replaced.\n        @type form_tag_attrs: {unicode: unicode}",
        "positive_code": "def formMarkup(self, realm, return_to=None, immediate=False,\n            form_tag_attrs=None):\n        \n        message = self.getMessage(realm, return_to, immediate)\n        return message.toFormMarkup(self.endpoint.server_url,\n                    form_tag_attrs)",
        "hard_negative_ids": [
            481,
            232,
            415,
            382,
            360,
            255,
            91,
            139,
            379,
            414,
            189,
            84,
            475,
            117,
            349,
            429,
            402,
            466,
            470,
            178,
            323,
            131,
            222,
            76,
            424,
            149,
            73,
            291,
            257,
            308,
            132,
            209,
            412,
            171,
            491,
            425,
            280,
            81,
            462,
            113,
            197,
            311,
            339,
            182,
            56,
            329,
            295,
            391,
            15,
            192
        ]
    },
    {
        "query": "Convert a CSV object to a numpy array.\n\n    Args:\n        string_like (str): CSV string.\n        dtype (dtype, optional):  Data type of the resulting array. If None, the dtypes will be determined by the\n                                        contents of each column, individually. This argument can only be used to\n                                        'upcast' the array.  For downcasting, use the .astype(t) method.\n    Returns:\n        (np.array): numpy array",
        "positive_code": "def csv_to_numpy(string_like, dtype=None):  \n    \n    stream = StringIO(string_like)\n    return np.genfromtxt(stream, dtype=dtype, delimiter=)",
        "hard_negative_ids": [
            287,
            88,
            232,
            271,
            256,
            280,
            291,
            470,
            414,
            466,
            360,
            41,
            23,
            239,
            81,
            269,
            297,
            324,
            210,
            177,
            429,
            413,
            12,
            323,
            44,
            197,
            79,
            73,
            40,
            299,
            100,
            381,
            255,
            460,
            440,
            342,
            273,
            47,
            424,
            435,
            318,
            192,
            142,
            462,
            421,
            402,
            275,
            171,
            317,
            349
        ]
    },
    {
        "query": "Add Builders and construction variables for cyglink to an Environment.",
        "positive_code": "def generate(env):\n    \n    gnulink.generate(env)\n\n    env[]   = SCons.Util.CLVar()\n\n    env[] = shlib_action\n    env[] = ldmod_action\n    env.Append(SHLIBEMITTER = [shlib_emitter])\n    env.Append(LDMODULEEMITTER = [ldmod_emitter])\n\n    env[]         = \n    env[]         = \n\n    env[]        = \n    env[]        = \n\n    \n    env[]      = \n    env[]   = \n\n    \n\n    \n    env[] = {\n                  : _versioned_lib_suffix,\n                  : _versioned_lib_suffix,\n                 : _versioned_lib_suffix,\n                    : link._versioned_shlib_name,\n                    : link._versioned_ldmod_name,\n              : lambda *args: _versioned_implib_name(*args, libtype=),\n              : lambda *args: _versioned_implib_name(*args, libtype=),\n          : lambda *args: _versioned_implib_symlinks(*args, libtype=),\n          : lambda *args: _versioned_implib_symlinks(*args, libtype=),\n    }\n\n    \n    try: del env[]\n    except KeyError: pass\n    try: del env[]\n    except KeyError: pass",
        "hard_negative_ids": [
            373,
            215,
            189,
            324,
            360,
            179,
            73,
            414,
            453,
            289,
            19,
            242,
            131,
            109,
            272,
            295,
            275,
            171,
            269,
            293,
            427,
            127,
            368,
            376,
            76,
            51,
            264,
            24,
            477,
            184,
            46,
            345,
            485,
            47,
            149,
            219,
            257,
            371,
            157,
            99,
            347,
            266,
            94,
            118,
            201,
            21,
            473,
            233,
            466,
            349
        ]
    },
    {
        "query": "remove the blank lines in astr",
        "positive_code": "def removeblanklines(astr):\n    \n    lines = astr.splitlines()\n    lines = [line for line in lines if line.strip() != \"\"]\n    return \"\\n\".join(lines)",
        "hard_negative_ids": [
            69,
            500,
            103,
            452,
            341,
            186,
            332,
            407,
            74,
            360,
            414,
            291,
            96,
            197,
            38,
            466,
            438,
            359,
            374,
            136,
            64,
            9,
            252,
            73,
            171,
            44,
            429,
            23,
            183,
            25,
            34,
            109,
            305,
            135,
            321,
            215,
            209,
            489,
            35,
            363,
            234,
            155,
            387,
            223,
            377,
            345,
            104,
            29,
            36,
            247
        ]
    },
    {
        "query": "A particular user's packages (any acl)\n\n    This rule includes messages that relate to packages where the\n    specified user has *either* commit ACLs or the watchcommits flag.",
        "positive_code": "def user_package_filter(config, message, fasnick=None, *args, **kw):\n    \n\n    fasnick = kw.get(, fasnick)\n    if fasnick:\n        msg_packages = fmn.rules.utils.msg2packages(message, **config)\n        if not msg_packages:\n            \n            \n            return False\n        usr_packages = fmn.rules.utils.get_packages_of_user(\n            config, fasnick, all_acls)\n        return usr_packages.intersection(msg_packages)\n\n    return False",
        "hard_negative_ids": [
            36,
            360,
            425,
            89,
            90,
            487,
            488,
            269,
            73,
            295,
            187,
            55,
            291,
            414,
            353,
            415,
            103,
            131,
            264,
            197,
            429,
            404,
            466,
            173,
            189,
            391,
            237,
            29,
            453,
            201,
            256,
            262,
            171,
            275,
            136,
            5,
            15,
            149,
            301,
            174,
            386,
            462,
            112,
            47,
            450,
            106,
            318,
            326,
            287,
            178
        ]
    },
    {
        "query": "Create box plot of some performance metrics of the strategy.\n    The width of the box whiskers is determined by a bootstrap.\n\n    Parameters\n    ----------\n    returns : pd.Series\n        Daily returns of the strategy, noncumulative.\n         - See full explanation in tears.create_full_tear_sheet.\n    factor_returns : pd.Series\n        Daily noncumulative returns of the benchmark factor to which betas are\n        computed. Usually a benchmark such as market returns.\n         - This is in the same style as returns.\n    ax : matplotlib.Axes, optional\n        Axes upon which to plot.\n\n    Returns\n    -------\n    ax : matplotlib.Axes\n        The axes that were plotted on.",
        "positive_code": "def plot_perf_stats(returns, factor_returns, ax=None):\n    \n\n    if ax is None:\n        ax = plt.gca()\n\n    bootstrap_values = timeseries.perf_stats_bootstrap(returns,\n                                                       factor_returns,\n                                                       return_stats=False)\n    bootstrap_values = bootstrap_values.drop(, axis=)\n\n    sns.boxplot(data=bootstrap_values, orient=, ax=ax)\n\n    return ax",
        "hard_negative_ids": [
            360,
            47,
            291,
            100,
            33,
            466,
            44,
            414,
            429,
            122,
            197,
            349,
            23,
            146,
            22,
            460,
            15,
            317,
            325,
            239,
            67,
            470,
            435,
            499,
            464,
            391,
            73,
            171,
            135,
            136,
            170,
            304,
            183,
            106,
            318,
            25,
            459,
            232,
            76,
            157,
            395,
            492,
            189,
            290,
            109,
            425,
            496,
            453,
            178,
            130
        ]
    },
    {
        "query": "Return true iff obj is an instance of one of the types.",
        "positive_code": "def is_one_of(obj, types):\n    \n    for type_ in types:\n        if isinstance(obj, type_):\n            return True\n    return False",
        "hard_negative_ids": [
            133,
            232,
            305,
            333,
            269,
            197,
            118,
            59,
            466,
            76,
            360,
            219,
            383,
            429,
            295,
            349,
            414,
            73,
            395,
            277,
            470,
            189,
            23,
            318,
            29,
            451,
            136,
            291,
            99,
            345,
            44,
            157,
            427,
            113,
            280,
            272,
            279,
            423,
            25,
            115,
            20,
            380,
            222,
            411,
            37,
            273,
            226,
            81,
            224,
            353
        ]
    },
    {
        "query": "write a config file to the pathname specified in the parameter.  The\n        file extention determines the type of file written and must match a\n        registered type.\n\n        parameters:\n            config_pathname - the full path and filename of the target config\n                               file.",
        "positive_code": "def dump_conf(self, config_pathname=None):\n        \n\n        if not config_pathname:\n            config_pathname = self._get_option().value\n\n        opener = functools.partial(open, config_pathname, )\n        config_file_type = os.path.splitext(config_pathname)[1][1:]\n\n        skip_keys = [\n            k for (k, v)\n            in six.iteritems(self.option_definitions)\n            if isinstance(v, Option) and v.exclude_from_dump_conf\n        ]\n\n        self.write_conf(config_file_type, opener, skip_keys=skip_keys)",
        "hard_negative_ids": [
            232,
            171,
            178,
            454,
            66,
            363,
            360,
            466,
            23,
            318,
            38,
            73,
            134,
            414,
            169,
            429,
            470,
            197,
            44,
            1,
            405,
            349,
            170,
            9,
            228,
            386,
            260,
            373,
            130,
            109,
            364,
            291,
            117,
            227,
            275,
            188,
            144,
            34,
            25,
            76,
            295,
            391,
            376,
            272,
            106,
            382,
            304,
            200,
            456,
            279
        ]
    },
    {
        "query": "Sends a message from the framework to one of its executors.\n\n        These messages are best effort; do not expect a framework message to be\n        retransmitted in any reliable fashion.",
        "positive_code": "def message(self, executor_id, slave_id, message):\n        \n        logging.info(.format(\n                     message, executor_id, slave_id))\n        return self.driver.sendFrameworkMessage(encode(executor_id),\n                                                encode(slave_id),\n                                                message)",
        "hard_negative_ids": [
            488,
            262,
            360,
            232,
            301,
            466,
            264,
            37,
            189,
            470,
            269,
            327,
            295,
            171,
            291,
            404,
            429,
            73,
            414,
            106,
            349,
            197,
            131,
            304,
            136,
            382,
            391,
            99,
            174,
            178,
            462,
            23,
            453,
            69,
            317,
            386,
            425,
            318,
            180,
            499,
            109,
            76,
            15,
            157,
            25,
            451,
            424,
            395,
            193,
            201
        ]
    },
    {
        "query": "Infer the type of a variable (technically a Series).\n\n    The types supported are split in standard types and special types.\n\n    Standard types:\n        * Categorical (`TYPE_CAT`): the default type if no other one can be determined\n        * Numerical (`TYPE_NUM`): if it contains numbers\n        * Boolean (`TYPE_BOOL`): at this time only detected if it contains boolean values, see todo\n        * Date (`TYPE_DATE`): if it contains datetime\n\n    Special types:\n        * Constant (`S_TYPE_CONST`): if all values in the variable are equal\n        * Unique (`S_TYPE_UNIQUE`): if all values in the variable are different\n        * Unsupported (`S_TYPE_UNSUPPORTED`): if the variable is unsupported\n\n     The result is cached by column name in a global variable to avoid recomputing.\n\n    Parameters\n    ----------\n    data : Series\n        The data type of the Series.\n\n    Returns\n    -------\n    str\n        The data type of the Series.\n\n    Notes\n    ----\n        * Should improve verification when a categorical or numeric field has 3 values, it could be a categorical field\n        or just a boolean with NaN values\n        * #72: Numeric with low Distinct count should be treated as \"Categorical\"",
        "positive_code": "def get_vartype(data):\n    \n    if data.name is not None and data.name in _MEMO:\n        return _MEMO[data.name]\n\n    vartype = None\n    try:\n        distinct_count = get_groupby_statistic(data)[1]\n        leng = len(data)\n\n        if distinct_count <= 1:\n            vartype = S_TYPE_CONST\n        elif pd.api.types.is_bool_dtype(data) or (distinct_count == 2 and pd.api.types.is_numeric_dtype(data)):\n            vartype = TYPE_BOOL\n        elif pd.api.types.is_numeric_dtype(data):\n            vartype = TYPE_NUM\n        elif pd.api.types.is_datetime64_dtype(data):\n            vartype = TYPE_DATE\n        elif distinct_count == leng:\n            vartype = S_TYPE_UNIQUE\n        else:\n            vartype = TYPE_CAT\n    except:\n        vartype = S_TYPE_UNSUPPORTED\n\n    if data.name is not None:\n        _MEMO[data.name] = vartype\n\n    return vartype",
        "hard_negative_ids": [
            232,
            424,
            291,
            373,
            142,
            460,
            324,
            332,
            466,
            349,
            360,
            414,
            76,
            295,
            23,
            179,
            15,
            250,
            252,
            85,
            222,
            485,
            333,
            223,
            391,
            201,
            429,
            25,
            44,
            197,
            182,
            462,
            73,
            498,
            382,
            162,
            192,
            470,
            226,
            90,
            499,
            56,
            239,
            421,
            33,
            393,
            199,
            136,
            69,
            264
        ]
    },
    {
        "query": "Utility method for formatting file parameters for transmission",
        "positive_code": "def format_file_params(files):\n        \n        files_payload = {}\n        if files:\n            for idx, filename in enumerate(files):\n                files_payload[\"file[\" + str(idx) + \"]\"] = open(filename, )\n        return files_payload",
        "hard_negative_ids": [
            323,
            103,
            41,
            363,
            70,
            171,
            139,
            402,
            44,
            15,
            23,
            467,
            233,
            144,
            169,
            376,
            434,
            1,
            275,
            87,
            277,
            99,
            289,
            414,
            264,
            426,
            135,
            489,
            321,
            35,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190,
            443
        ]
    },
    {
        "query": "get_network_instances implementation for NX-OS",
        "positive_code": "def get_network_instances(self, name=\"\"):\n        \n\n        \n        \n        command = \"show vrf detail\"\n        vrf_table_raw = self._get_command_table(command, \"TABLE_vrf\", \"ROW_vrf\")\n\n        \n        \n        command = \"show vrf interface\"\n        intf_table_raw = self._get_command_table(command, \"TABLE_if\", \"ROW_if\")\n\n        \n        vrf_intfs = defaultdict(list)\n        for intf in intf_table_raw:\n            vrf_intfs[intf[\"vrf_name\"]].append(py23_compat.text_type(intf[\"if_name\"]))\n\n        vrfs = {}\n        for vrf in vrf_table_raw:\n            vrf_name = py23_compat.text_type(vrf.get(\"vrf_name\"))\n            vrfs[vrf_name] = {}\n            vrfs[vrf_name][\"name\"] = vrf_name\n\n            \n            if vrf_name == \"default\":\n                vrfs[vrf_name][\"type\"] = \"DEFAULT_INSTANCE\"\n            else:\n                vrfs[vrf_name][\"type\"] = \"L3VRF\"\n\n            vrfs[vrf_name][\"state\"] = {\n                \"route_distinguisher\": py23_compat.text_type(vrf.get(\"rd\"))\n            }\n\n            \n            \n            vrfs[vrf_name][\"interfaces\"] = {}\n            vrfs[vrf_name][\"interfaces\"][\"interface\"] = dict.fromkeys(\n                vrf_intfs[vrf_name], {}\n            )\n\n        \n        \n        if name:\n            if name in vrfs.keys():\n                return {py23_compat.text_type(name): vrfs[name]}\n            else:\n                return {}\n        \n        else:\n            return vrfs",
        "hard_negative_ids": [
            11,
            18,
            76,
            368,
            456,
            149,
            170,
            109,
            38,
            363,
            234,
            371,
            34,
            1,
            31,
            194,
            173,
            150,
            163,
            388,
            144,
            169,
            77,
            138,
            53,
            245,
            293,
            68,
            95,
            268,
            373,
            319,
            435,
            188,
            56,
            472,
            17,
            416,
            347,
            361,
            279,
            179,
            391,
            210,
            155,
            289,
            175,
            275,
            142,
            240
        ]
    },
    {
        "query": "Annote the queryset with an 'is_active' property that's true iff that row is the most\n        recently added row for that particular set of KEY_FIELDS values.\n        Filter the queryset to show only is_active rows by default.",
        "positive_code": "def get_queryset(self, request):\n        \n        if request.GET.get(ShowHistoryFilter.parameter_name) == :\n            queryset = self.model.objects.with_active_flag()\n        else:\n            \n            queryset = self.model.objects.current_set()\n        ordering = self.get_ordering(request)\n        if ordering:\n            return queryset.order_by(*ordering)\n        return queryset",
        "hard_negative_ids": [
            142,
            10,
            360,
            424,
            291,
            197,
            168,
            414,
            332,
            466,
            73,
            306,
            246,
            156,
            84,
            136,
            90,
            15,
            103,
            405,
            76,
            429,
            47,
            25,
            349,
            189,
            212,
            23,
            113,
            11,
            232,
            366,
            474,
            395,
            44,
            388,
            109,
            333,
            69,
            275,
            272,
            228,
            269,
            99,
            386,
            107,
            239,
            264,
            56,
            383
        ]
    },
    {
        "query": "Register a custom environment for use with RLlib.\n\n    Args:\n        name (str): Name to register.\n        env_creator (obj): Function that creates an env.",
        "positive_code": "def register_env(name, env_creator):\n    \n\n    if not isinstance(env_creator, FunctionType):\n        raise TypeError(\"Second argument must be a function.\", env_creator)\n    _global_registry.register(ENV_CREATOR, name, env_creator)",
        "hard_negative_ids": [
            297,
            360,
            133,
            59,
            42,
            76,
            498,
            305,
            269,
            103,
            118,
            293,
            391,
            176,
            287,
            488,
            122,
            414,
            324,
            235,
            41,
            142,
            412,
            189,
            159,
            383,
            179,
            219,
            8,
            65,
            147,
            171,
            112,
            47,
            106,
            385,
            66,
            150,
            91,
            304,
            415,
            316,
            73,
            29,
            454,
            222,
            366,
            131,
            277,
            487
        ]
    },
    {
        "query": "Removes existing forwarding rules from a LoadBalancer.\n\n        Args:\n            forwarding_rules (obj:`list`): A list of `ForwrdingRules` objects",
        "positive_code": "def remove_forwarding_rules(self, forwarding_rules):\n        \n        rules_dict = [rule.__dict__ for rule in forwarding_rules]\n\n        return self.get_data(\n            \"load_balancers/%s/forwarding_rules/\" % self.id,\n            type=DELETE,\n            params={\"forwarding_rules\": rules_dict}\n        )",
        "hard_negative_ids": [
            133,
            383,
            305,
            76,
            470,
            118,
            59,
            79,
            287,
            147,
            120,
            89,
            488,
            29,
            41,
            193,
            106,
            69,
            219,
            304,
            269,
            391,
            297,
            332,
            349,
            112,
            385,
            453,
            178,
            316,
            466,
            317,
            324,
            425,
            360,
            500,
            277,
            159,
            487,
            179,
            77,
            81,
            2,
            333,
            171,
            15,
            395,
            183,
            328,
            7
        ]
    },
    {
        "query": "Obtain a binary version of an :class:`openpyxl.Workbook` representation of\n    an Excel file.",
        "positive_code": "def excel_to_bytes(wb: Workbook) -> bytes:\n    \n    memfile = io.BytesIO()\n    wb.save(memfile)\n    return memfile.getvalue()",
        "hard_negative_ids": [
            466,
            73,
            171,
            360,
            470,
            349,
            189,
            363,
            277,
            395,
            1,
            106,
            232,
            304,
            386,
            391,
            76,
            414,
            157,
            147,
            427,
            429,
            453,
            197,
            137,
            178,
            467,
            317,
            425,
            297,
            318,
            136,
            376,
            15,
            272,
            144,
            23,
            47,
            434,
            243,
            180,
            169,
            256,
            382,
            44,
            275,
            462,
            222,
            264,
            472
        ]
    },
    {
        "query": "Callback when a report is received.",
        "positive_code": "def _on_report(_loop, adapter, conn_id, report):\n    \n\n    conn_string = None\n    if conn_id is not None:\n        conn_string = adapter._get_property(conn_id, )\n\n    if isinstance(report, BroadcastReport):\n        adapter.notify_event_nowait(conn_string, , report)\n    elif conn_string is not None:\n        adapter.notify_event_nowait(conn_string, , report)\n    else:\n        adapter._logger.debug(\"Dropping report with unknown conn_id=%s\", conn_id)",
        "hard_negative_ids": [
            455,
            453,
            404,
            227,
            304,
            106,
            391,
            73,
            425,
            237,
            171,
            178,
            317,
            15,
            360,
            382,
            222,
            470,
            423,
            256,
            349,
            462,
            76,
            224,
            66,
            466,
            472,
            272,
            345,
            328,
            212,
            243,
            398,
            263,
            251,
            413,
            197,
            151,
            51,
            134,
            211,
            23,
            141,
            373,
            399,
            270,
            250,
            180,
            108,
            92
        ]
    },
    {
        "query": "Create the user profiles for the given weeks.",
        "positive_code": "def create_profiles(self, prefix, weeks, ip_user=False):\n        \n        \n        \n\n        \n        record_counter = {}\n        for year, week in weeks:\n            file = self.storage.get(prefix, year, week)\n            self.count_records(record_counter, file)\n\n        \n        print(\"Records read all: {}\".format(self.stat))\n\n        \n        records_valid = self.filter_counter(record_counter)\n\n        \n        profiles = defaultdict(list)\n        for year, week in weeks:\n            file = self.storage.get(prefix, year, week)\n            self._create_user_profiles(profiles, file, records_valid, ip_user,\n                                       year, week)\n\n        return profiles",
        "hard_negative_ids": [
            325,
            158,
            73,
            459,
            187,
            55,
            170,
            425,
            360,
            103,
            414,
            197,
            291,
            39,
            466,
            124,
            415,
            136,
            131,
            429,
            44,
            23,
            228,
            99,
            25,
            173,
            293,
            329,
            109,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53
        ]
    },
    {
        "query": "Indexes objs from all modules",
        "positive_code": "def index_modules(idx=None, path=None):\n    \n    suppress_output()\n    modules = defaultdict(list)\n    pkglist = pkgutil.walk_packages(onerror=lambda x: True)\n    print(pkglist)\n    if path:\n        pkglist = pkgutil.walk_packages(path, onerror=lambda x: True)\n    for modl, name, ispkg in pkglist:\n        try:\n            path = os.path.join(modl.path, name.split()[-1])\n        except AttributeError:\n            \n            continue\n\n        if os.path.isdir(path):\n            path = os.path.join(path, )\n        path += \n\n        objs = []\n\n        if os.path.exists(path):\n            try:\n                objs = read_objs_from_path(path)\n            except:\n                continue\n        elif not re.search(MODULE_BLACKLIST, name):\n            try:\n                mod = __import__(name)\n                objs = [k for k in dir(mod) if not k.startswith()]\n            except:\n                continue\n        else:\n            continue\n\n        for obj in objs:\n            if name not in modules[obj]:\n                modules[obj].append(name)\n    suppress_output(True)\n    return merge_dicts(idx, dict(modules))",
        "hard_negative_ids": [
            234,
            215,
            193,
            367,
            493,
            79,
            69,
            85,
            116,
            115,
            311,
            7,
            26,
            347,
            295,
            76,
            131,
            233,
            142,
            11,
            279,
            88,
            153,
            47,
            67,
            201,
            185,
            326,
            147,
            237,
            25,
            231,
            272,
            208,
            343,
            239,
            230,
            466,
            73,
            99,
            23,
            468,
            467,
            465,
            464,
            463,
            462,
            461,
            460,
            459
        ]
    },
    {
        "query": "Create a query and run it for the given arg if it doesn't exist, and\n        return the tweets for the query.",
        "positive_code": "def get_for(self, query_type, value):\n        \n        from yacms.twitter.models import Query\n        lookup = {\"type\": query_type, \"value\": value}\n        query, created = Query.objects.get_or_create(**lookup)\n        if created:\n            query.run()\n        elif not query.interested:\n            query.interested = True\n            query.save()\n        return query.tweets.all()",
        "hard_negative_ids": [
            360,
            280,
            243,
            325,
            73,
            69,
            459,
            90,
            291,
            170,
            466,
            414,
            23,
            197,
            174,
            99,
            462,
            106,
            149,
            451,
            329,
            39,
            375,
            304,
            136,
            216,
            230,
            370,
            237,
            472,
            391,
            179,
            25,
            297,
            201,
            317,
            181,
            429,
            44,
            269,
            453,
            292,
            178,
            239,
            322,
            438,
            15,
            425,
            349,
            343
        ]
    },
    {
        "query": "dtype = 'noUint', uint8, float, 'float', ...",
        "positive_code": "def imread(img, color=None, dtype=None):\r\n    noUintfloat\r\n    COLOR2CV = {: cv2.IMREAD_GRAYSCALE,\r\n                : cv2.IMREAD_COLOR,\r\n                None: cv2.IMREAD_ANYCOLOR\r\n                }\r\n    c = COLOR2CV[color]\r\n    if callable(img):\r\n        img = img()\r\n    elif isinstance(img, string_types):\r\n        \n        \n        \n        \n        \n        \n        \n        if dtype in (None, \"noUint\") or np.dtype(dtype) != np.uint8:\r\n            c |= cv2.IMREAD_ANYDEPTH\r\n        img2 = cv2.imread(img, c)\r\n        if img2 is None:\r\n            raise IOError(\"image  is not existing\" % img)\r\n        img = img2\r\n\r\n    elif color ==  and img.ndim == 3:  \n        \n        img = toGray(img)\r\n    \n    if dtype is not None:\r\n        if isinstance(img, np.ndarray):\r\n            img = _changeArrayDType(img, dtype, cutHigh=False)\r\n\r\n    return img",
        "hard_negative_ids": [
            56,
            271,
            290,
            177,
            381,
            160,
            426,
            256,
            324,
            12,
            440,
            486,
            81,
            318,
            100,
            414,
            490,
            181,
            23,
            478,
            111,
            452,
            212,
            209,
            333,
            487,
            294,
            357,
            352,
            196,
            220,
            151,
            62,
            326,
            323,
            83,
            395,
            123,
            405,
            432,
            270,
            383,
            278,
            11,
            39,
            396,
            364,
            33,
            168,
            459
        ]
    },
    {
        "query": "A wrapper for `os.walk` that skips hidden files and directories.\n\n    This function does not have the parameter `topdown` from\n    `os.walk`: the directories must always be recursed top-down when\n    using this function.\n\n    See also\n    --------\n    os.walk : For a description of the parameters",
        "positive_code": "def walk_skip_hidden(top, onerror=None, followlinks=False):\n    \n\n    for root, dirs, files in os.walk(\n            top, topdown=True, onerror=onerror,\n            followlinks=followlinks):\n        \n        \n        dirs[:] = [d for d in dirs if not is_path_hidden(d)]\n        files[:] = [f for f in files if not is_path_hidden(f)]\n        yield root, dirs, files",
        "hard_negative_ids": [
            363,
            360,
            234,
            414,
            232,
            42,
            470,
            38,
            189,
            166,
            291,
            76,
            466,
            73,
            23,
            425,
            386,
            235,
            349,
            382,
            112,
            142,
            197,
            149,
            237,
            391,
            109,
            368,
            456,
            462,
            41,
            136,
            429,
            171,
            324,
            275,
            106,
            184,
            297,
            44,
            304,
            170,
            318,
            330,
            90,
            369,
            1,
            371,
            192,
            228
        ]
    },
    {
        "query": "Parse and validate MediaFire URI.",
        "positive_code": "def _parse_uri(uri):\n        \n\n        tokens = urlparse(uri)\n\n        if tokens.netloc != :\n            logger.error(\"Invalid URI: %s\", uri)\n            raise ValueError(\"MediaFire URI format error: \"\n                             \"host should be empty - mf:///path\")\n\n        if tokens.scheme !=  and tokens.scheme != URI_SCHEME:\n            raise ValueError(\"MediaFire URI format error: \"\n                             \"must start with  or \")\n\n        return posixpath.normpath(tokens.path)",
        "hard_negative_ids": [
            277,
            480,
            178,
            311,
            300,
            24,
            485,
            345,
            184,
            46,
            219,
            257,
            477,
            94,
            118,
            201,
            21,
            473,
            149,
            349,
            131,
            371,
            318,
            433,
            283,
            326,
            424,
            125,
            347,
            295,
            38,
            490,
            90,
            301,
            185,
            92,
            275,
            179,
            233,
            462,
            198,
            206,
            296,
            173,
            410,
            291,
            113,
            284,
            48,
            81
        ]
    },
    {
        "query": "Create path to recovery file with given name as base.\n        \n        :param str lockfile: Name of file on which to base this path, \n            perhaps already prefixed with the designation of a lock file.\n        :return str: Path to recovery file.",
        "positive_code": "def _recoverfile_from_lockfile(self, lockfile):\n        \n        \n        \n        if not (os.path.isabs(lockfile) or lockfile.startswith(self.outfolder)):\n            lockfile = self._make_lock_path(lockfile)\n        return lockfile.replace(LOCK_PREFIX, \"recover.\" + LOCK_PREFIX)",
        "hard_negative_ids": [
            170,
            171,
            363,
            379,
            73,
            40,
            414,
            466,
            325,
            498,
            360,
            275,
            44,
            456,
            204,
            277,
            144,
            70,
            391,
            1,
            150,
            229,
            47,
            146,
            128,
            264,
            254,
            376,
            269,
            169,
            176,
            459,
            246,
            470,
            23,
            81,
            189,
            412,
            38,
            197,
            34,
            349,
            499,
            99,
            429,
            89,
            74,
            163,
            380,
            68
        ]
    },
    {
        "query": "Check if repo teams match allow/deny lists\n\n    Parameters\n    ----------\n    repo: github.Repository.Repository\n        repo to check for membership\n\n    allow_teams: list(str)\n        list of team names that repo MUST belong to at least one of.\n\n    deny_teams: list(str)\n        list of team that repo MUST NOT be a member of.\n\n    team_names: list(str)\n        list of the team name which the repo is a member of (optional).\n        Providing this list saves retrieving the list of teams from the github\n        API.\n\n    Raises\n    ------\n    RepositoryTeamMembershipError\n        Upon permission error",
        "positive_code": "def check_repo_teams(repo, allow_teams, deny_teams, team_names=None):\n    \n    assert isinstance(repo, github.Repository.Repository), type(repo)\n\n    \n    if not team_names:\n        try:\n            team_names = [t.name for t in repo.get_teams()]\n        except github.RateLimitExceededException:\n            raise\n        except github.GithubException as e:\n            msg = \n            raise CaughtRepositoryError(repo, e, msg) from None\n\n    if not any(x in team_names for x in allow_teams)\\\n       or any(x in team_names for x in deny_teams):\n        raise RepositoryTeamMembershipError(\n            repo,\n            team_names,\n            allow_teams=allow_teams,\n            deny_teams=deny_teams\n        )",
        "hard_negative_ids": [
            429,
            232,
            458,
            295,
            360,
            284,
            197,
            470,
            349,
            233,
            466,
            386,
            201,
            414,
            189,
            185,
            425,
            73,
            435,
            382,
            391,
            23,
            318,
            460,
            388,
            76,
            291,
            498,
            66,
            207,
            77,
            222,
            146,
            47,
            412,
            462,
            171,
            275,
            260,
            2,
            127,
            99,
            445,
            272,
            131,
            395,
            44,
            182,
            176,
            157
        ]
    },
    {
        "query": "Returns a compact representation of all of the subtasks of a task.\n\n        Parameters\n        ----------\n        task : {Id} The task to get the subtasks of.\n        [params] : {Object} Parameters for the request",
        "positive_code": "def subtasks(self, task, params={}, **options): \n        \n        path = \"/tasks/%s/subtasks\" % (task)\n        return self.client.get_collection(path, params, **options)",
        "hard_negative_ids": [
            414,
            402,
            466,
            79,
            197,
            395,
            470,
            360,
            349,
            483,
            429,
            139,
            491,
            432,
            76,
            391,
            256,
            70,
            131,
            73,
            23,
            113,
            230,
            295,
            425,
            106,
            291,
            171,
            25,
            304,
            232,
            157,
            222,
            105,
            129,
            433,
            421,
            136,
            317,
            369,
            453,
            15,
            382,
            85,
            300,
            285,
            272,
            415,
            178,
            226
        ]
    },
    {
        "query": "Stop consuming messages and perform an orderly shutdown.\n\n        If ``reason`` is None, then this is considered a regular close.",
        "positive_code": "def close(self, reason=None):\n        \n        with self._closing:\n            if self._closed:\n                return\n\n            self._websocket.close()\n\n            self._consumer.join()\n            self._consumer = None\n\n            self._websocket = None\n            self._closed = True\n            for cb in self._close_callbacks:\n                cb(self, reason)",
        "hard_negative_ids": [
            248,
            423,
            286,
            175,
            171,
            189,
            10,
            488,
            327,
            201,
            360,
            304,
            301,
            37,
            262,
            275,
            47,
            90,
            106,
            425,
            391,
            414,
            427,
            30,
            15,
            453,
            382,
            148,
            345,
            222,
            264,
            178,
            472,
            73,
            349,
            180,
            24,
            317,
            192,
            462,
            224,
            184,
            92,
            76,
            328,
            212,
            318,
            38,
            243,
            46
        ]
    },
    {
        "query": "Shutdown and close the socket.",
        "positive_code": "def close_socket(sock):\n    \n    if sock:\n        try:\n            sock.shutdown(socket.SHUT_RDWR)\n        except Exception:\n            pass\n        try:\n            sock.close()\n        except Exception:\n            pass",
        "hard_negative_ids": [
            248,
            262,
            423,
            58,
            171,
            266,
            291,
            360,
            275,
            197,
            414,
            30,
            466,
            61,
            136,
            73,
            327,
            148,
            25,
            429,
            44,
            472,
            289,
            23,
            24,
            485,
            345,
            184,
            46,
            219,
            257,
            477,
            109,
            94,
            118,
            201,
            21,
            473,
            149,
            349,
            131,
            371,
            318,
            433,
            283,
            326,
            424,
            125,
            347,
            295
        ]
    },
    {
        "query": "%prog agp evidencefile contigs.fasta\n\n    Convert SSPACE scaffold structure to AGP format.",
        "positive_code": "def agp(args):\n    \n    p = OptionParser(agp.__doc__)\n    opts, args = p.parse_args(args)\n\n    if len(args) != 2:\n        sys.exit(not p.print_help())\n\n    evidencefile, contigs = args\n    ef = EvidenceFile(evidencefile, contigs)\n\n    agpfile = evidencefile.replace(\".evidence\", \".agp\")\n    ef.write_agp(agpfile)",
        "hard_negative_ids": [
            359,
            489,
            12,
            478,
            368,
            376,
            264,
            366,
            57,
            329,
            76,
            275,
            73,
            135,
            171,
            414,
            269,
            131,
            467,
            386,
            90,
            466,
            157,
            45,
            23,
            295,
            99,
            189,
            201,
            499,
            159,
            341,
            266,
            326,
            375,
            317,
            360,
            197,
            66,
            56,
            89,
            165,
            138,
            47,
            154,
            421,
            424,
            389,
            178,
            109
        ]
    },
    {
        "query": "Get the first instance of a `self.pod_types`",
        "positive_code": "def _find_convertable_object(self, data):\n        \n        data = list(data)\n        convertable_object_idxs = [\n            idx\n            for idx, obj\n            in enumerate(data)\n            if obj.get() in self.pod_types.keys()\n        ]\n        if len(convertable_object_idxs) < 1:\n            raise Exception(\"Kubernetes config didn, '.join(self.pod_types.keys())\n            ))\n        return list(data)[convertable_object_idxs[0]]",
        "hard_negative_ids": [
            269,
            219,
            466,
            360,
            285,
            197,
            470,
            469,
            403,
            333,
            421,
            349,
            23,
            429,
            106,
            304,
            391,
            382,
            73,
            395,
            498,
            414,
            326,
            291,
            453,
            178,
            15,
            232,
            317,
            425,
            136,
            171,
            389,
            280,
            272,
            180,
            82,
            114,
            157,
            6,
            44,
            318,
            295,
            256,
            463,
            452,
            315,
            462,
            25,
            402
        ]
    },
    {
        "query": "Detaches a disk from a virtual machine.\n\n    .. versionadded:: 2016.3.0\n\n    name\n        The name of the VM from which to detach the network interface.\n\n    nic_id\n        The ID of the nic to detach.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-cloud -a vm_detach_nic my-vm nic_id=1",
        "positive_code": "def vm_detach_nic(name, kwargs=None, call=None):\n    \n    if call != :\n        raise SaltCloudSystemExit(\n            \n        )\n\n    if kwargs is None:\n        kwargs = {}\n\n    nic_id = kwargs.get(, None)\n    if nic_id is None:\n        raise SaltCloudSystemExit(\n            nic_id\\\n        )\n\n    server, user, password = _get_xml_rpc()\n    auth = .join([user, password])\n    vm_id = int(get_vm_id(kwargs={: name}))\n    response = server.one.vm.detachnic(auth, vm_id, int(nic_id))\n\n    data = {\n        : ,\n        : response[0],\n        : response[1],\n        : response[2],\n    }\n\n    return data",
        "hard_negative_ids": [
            69,
            498,
            466,
            360,
            197,
            123,
            414,
            293,
            315,
            391,
            186,
            77,
            349,
            256,
            73,
            429,
            435,
            146,
            131,
            339,
            171,
            470,
            240,
            176,
            76,
            106,
            371,
            304,
            291,
            469,
            386,
            412,
            153,
            27,
            67,
            157,
            136,
            479,
            23,
            44,
            66,
            453,
            227,
            317,
            178,
            232,
            95,
            462,
            65,
            272
        ]
    },
    {
        "query": "Parse line from CLI read loop and execute provided command",
        "positive_code": "def exec_cmd(self, cmdstr):\n        \n        parts = cmdstr.split()\n        if len(parts):\n            cmd, args = parts[0], parts[1:]\n            self._dispatch(cmd, args)\n        else:\n            pass",
        "hard_negative_ids": [
            444,
            452,
            69,
            378,
            480,
            166,
            407,
            449,
            311,
            450,
            394,
            359,
            438,
            385,
            459,
            356,
            236,
            252,
            466,
            9,
            178,
            64,
            103,
            171,
            131,
            71,
            193,
            186,
            7,
            26,
            206,
            185,
            479,
            367,
            11,
            275,
            472,
            300,
            153,
            67,
            169,
            208,
            353,
            327,
            147,
            24,
            163,
            231,
            485,
            138
        ]
    },
    {
        "query": "Strip the whitespace from all column names in the given DataFrame\n    and return the result.",
        "positive_code": "def clean_column_names(df: DataFrame) -> DataFrame:\n    \n    f = df.copy()\n    f.columns = [col.strip() for col in f.columns]\n    return f",
        "hard_negative_ids": [
            33,
            142,
            73,
            176,
            360,
            223,
            201,
            452,
            445,
            44,
            388,
            151,
            371,
            291,
            424,
            414,
            197,
            226,
            429,
            363,
            466,
            239,
            25,
            198,
            2,
            321,
            86,
            136,
            131,
            85,
            76,
            498,
            199,
            417,
            274,
            23,
            116,
            216,
            329,
            435,
            295,
            443,
            99,
            193,
            290,
            215,
            311,
            7,
            222,
            173
        ]
    },
    {
        "query": "Query last_trade in parallel for multiple symbols and\n        return in dict.\n\n        symbols: list[str]\n\n        return: dict[str -> polygon.Trade]",
        "positive_code": "def _symbol_trades(self, symbols):\n        \n\n        @skip_http_error((404, 504))\n        def fetch(symbol):\n            return self._api.polygon.last_trade(symbol)\n\n        return parallelize(fetch)(symbols)",
        "hard_negative_ids": [
            185,
            2,
            360,
            4,
            67,
            243,
            265,
            345,
            127,
            379,
            331,
            489,
            260,
            77,
            178,
            435,
            298,
            181,
            218,
            183,
            412,
            340,
            490,
            443,
            293,
            53,
            222,
            477,
            190,
            450,
            393,
            387,
            245,
            94,
            142,
            324,
            402,
            485,
            382,
            267,
            56,
            410,
            110,
            235,
            59,
            23,
            84,
            275,
            76,
            25
        ]
    },
    {
        "query": "Create an archive of a gist\n\n        The files in the gist are downloaded and added to a compressed archive\n        (tarball). If the ID of the gist was c78d925546e964b4b1df, the\n        resulting archive would be,\n\n            c78d925546e964b4b1df.tar.gz\n\n        The archive is created in the directory where the command is invoked.\n\n        Arguments:\n            request: an initial request object\n            id:      the gist identifier",
        "positive_code": "def archive(self, request, id):\n        \n        gist = self.send(request, id).json()\n\n        with tarfile.open(.format(id), mode=) as archive:\n            for name, data in gist[].items():\n                with tempfile.NamedTemporaryFile() as fp:\n                    fp.write(data[])\n                    fp.flush()\n                    archive.add(fp.name, arcname=name)",
        "hard_negative_ids": [
            360,
            197,
            466,
            79,
            470,
            429,
            414,
            73,
            459,
            444,
            139,
            291,
            491,
            402,
            131,
            256,
            487,
            325,
            171,
            232,
            105,
            136,
            349,
            222,
            23,
            425,
            363,
            38,
            129,
            189,
            166,
            304,
            285,
            113,
            25,
            170,
            318,
            329,
            106,
            415,
            269,
            237,
            382,
            44,
            137,
            427,
            10,
            394,
            391,
            109
        ]
    },
    {
        "query": "Plots the simple fault source as a composite of the fault trace\n        and the surface projection of the fault.\n        :param source:\n            Fault source as instance of :class: mtkSimpleFaultSource\n        :param str border:\n            Line properties of border (see matplotlib documentation for detail)\n        :param float border_width:\n            Line width of border (see matplotlib documentation for detail)",
        "positive_code": "def _plot_simple_fault(self, source, border=, border_width=1.0):\n        \n        \n        trace_lons = np.array([pnt.longitude\n                               for pnt in source.fault_trace.points])\n        trace_lats = np.array([pnt.latitude\n                               for pnt in source.fault_trace.points])\n        surface_projection = _fault_polygon_from_mesh(source)\n        \n        x, y = self.m(surface_projection[:, 0], surface_projection[:, 1])\n        self.m.plot(x, y, border, linewidth=border_width)\n        \n        x, y = self.m(trace_lons, trace_lats)\n        self.m.plot(x, y, border, linewidth=1.3 * border_width)",
        "hard_negative_ids": [
            452,
            466,
            81,
            22,
            197,
            117,
            360,
            269,
            15,
            349,
            407,
            5,
            135,
            470,
            171,
            414,
            330,
            204,
            429,
            219,
            181,
            67,
            344,
            23,
            199,
            359,
            438,
            291,
            232,
            106,
            395,
            56,
            252,
            300,
            64,
            186,
            304,
            9,
            324,
            369,
            391,
            76,
            317,
            333,
            27,
            222,
            318,
            136,
            73,
            453
        ]
    },
    {
        "query": "source[] array of geojson points\n     kink\tin metres, kinks above this depth kept\n     kink depth is the height of the triangle abc where a-b and b-c are two consecutive line segments",
        "positive_code": "def simplify(source, kink=20):\n    \n    source_coord = map(lambda o: {\"lng\": o.coordinates[0], \"lat\": o.coordinates[1]}, source)\n\n    \n    \n    \n    F = (math.pi / 180.0) * 0.5\n    index = [] \n    sig_start = [] \n    sig_end = []\n\n    \n    count = len(source_coord)\n    if count < 3:\n        return source_coord \n\n    \n\n    band_sqr = kink * 360.0 / (2.0 * math.pi * 6378137.0) \n    band_sqr *= band_sqr\n    n_dest = 0\n    sig_start[0] = 0\n    sig_end[0] = count - 1\n    n_stack = 1\n\n    \n    while n_stack > 0:\n        \n        start = sig_start[n_stack - 1]\n        end = sig_end[n_stack - 1]\n        n_stack -= 1\n\n        if (end - start) > 1: \n            \n            x12 = source[end][\"lng\"] - source[start][\"lng\"]\n            y12 = source[end][\"lat\"] - source[start][\"lat\"]\n            if math.fabs(x12) > 180.0:\n                x12 = 360.0 - math.fabs(x12)\n            x12 *= math.cos(F * (source[end][\"lat\"] + source[start][\"lat\"])) \n            d12 = (x12 * x12) + (y12 * y12)\n\n            i = start + 1\n            sig = start\n            max_dev_sqr = -1.0\n            while i < end:\n                x13 = source[i][\"lng\"] - source[start][\"lng\"]\n                y13 = source[i][\"lat\"] - source[start][\"lat\"]\n                if math.fabs(x13) > 180.0:\n                    x13 = 360.0 - math.fabs(x13)\n                x13 *= math.cos(F * (source[i][\"lat\"] + source[start][\"lat\"]))\n                d13 = (x13 * x13) + (y13 * y13)\n                x23 = source[i][\"lng\"] - source[end][\"lng\"]\n                y23 = source[i][\"lat\"] - source[end][\"lat\"]\n                if math.fabs(x23) > 180.0:\n                    x23 = 360.0 - math.fabs(x23)\n                x23 *= math.cos(F * (source[i][\"lat\"] + source[end][\"lat\"]))\n                d23 = (x23 * x23) + (y23 * y23)\n\n                if d13 >= (d12 + d23):\n                    dev_sqr = d23\n                elif d23 >= (d12 + d13):\n                    dev_sqr = d13\n                else:\n                    dev_sqr = (x13 * y12 - y13 * x12) * (x13 * y12 - y13 * x12) / d12 \n                if dev_sqr > max_dev_sqr:\n                    sig = i\n                    max_dev_sqr = dev_sqr\n                i += 1\n\n\n            if max_dev_sqr < band_sqr: \n            \n                index[n_dest] = start\n                n_dest += 1\n            else: \n                n_stack += 1\n                sig_start[n_stack - 1] = sig\n                sig_end[n_stack - 1] = end\n                n_stack += 1\n                sig_start[n_stack - 1] = start\n                sig_end[n_stack - 1] = sig\n\n        else:  \n            index[n_dest] = start\n            n_dest += 1\n\n    \n    index[n_dest] = count - 1\n    n_dest += 1\n\n    \n    r = []\n    for i in range(0, n_dest):\n        r.append(source_coord[index[i]])\n\n    return map(lambda o:  {\"type\": \"Point\",\"coordinates\": [o.lng, o.lat]}, r)",
        "hard_negative_ids": [
            106,
            391,
            60,
            256,
            466,
            136,
            429,
            279,
            487,
            360,
            452,
            48,
            349,
            15,
            218,
            197,
            450,
            149,
            58,
            210,
            296,
            90,
            414,
            291,
            88,
            137,
            171,
            407,
            318,
            117,
            78,
            470,
            113,
            237,
            5,
            25,
            252,
            64,
            359,
            346,
            490,
            232,
            438,
            304,
            464,
            486,
            500,
            395,
            472,
            23
        ]
    },
    {
        "query": "Disconnect an open tunnel connection",
        "positive_code": "def disconnect(self):\n        \n        if self.connected and self.channel:\n            logging.debug(\"Disconnecting KNX/IP tunnel...\")\n\n            frame = KNXIPFrame(KNXIPFrame.DISCONNECT_REQUEST)\n            frame.body = self.hpai_body()\n\n            \n            \n            if self.seq < 0xff:\n                self.seq += 1\n            else:\n                self.seq = 0\n\n            self.control_socket.sendto(\n                bytes(frame.to_frame()), (self.remote_ip, self.remote_port))\n            \n            \n\n        else:\n            logging.debug(\"Disconnect - no connection, nothing to do\")\n\n        self.channel = None\n        self.connected = False",
        "hard_negative_ids": [
            249,
            450,
            38,
            266,
            189,
            427,
            170,
            360,
            402,
            171,
            59,
            397,
            73,
            1,
            109,
            275,
            414,
            74,
            148,
            163,
            186,
            472,
            138,
            293,
            482,
            483,
            484,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            500,
            462,
            463,
            464,
            465,
            466,
            467,
            468,
            485,
            486,
            487,
            488
        ]
    },
    {
        "query": "Generates list of peer IPs from tracker response. Note: not all of\n        these IPs might be good, which is why we only init peer objects for\n        the subset that respond to handshake",
        "positive_code": "def get_peer_ips(self):\n        \n        presponse = [ord(i) for i in self.tracker_response[]]\n        while presponse:\n            peer_ip = ((.join(str(x) for x in presponse[0:4]),\n                       256 * presponse[4] + presponse[5]))\n            if peer_ip not in self.peer_ips:\n                self.peer_ips.append(peer_ip)\n            presponse = presponse[6:]",
        "hard_negative_ids": [
            360,
            232,
            167,
            470,
            146,
            466,
            197,
            496,
            79,
            463,
            293,
            73,
            193,
            69,
            429,
            439,
            322,
            349,
            414,
            243,
            76,
            47,
            52,
            99,
            291,
            427,
            295,
            131,
            23,
            395,
            142,
            109,
            25,
            85,
            339,
            386,
            383,
            157,
            116,
            81,
            171,
            152,
            425,
            63,
            318,
            182,
            382,
            192,
            264,
            328
        ]
    },
    {
        "query": "Add collection property to schema\n        :param property_name: str, property name\n        :param property_name: str, property name\n        :return: shiftschema.property.CollectionProperty",
        "positive_code": "def add_collection(self, property_name, use_context=True):\n        \n        if self.has_property(property_name):\n            err = \n            raise PropertyExists(err.format(property_name))\n\n        prop = CollectionProperty(use_context=bool(use_context))\n        self.collections[property_name] = prop\n        return prop",
        "hard_negative_ids": [
            484,
            498,
            81,
            113,
            443,
            176,
            272,
            204,
            412,
            266,
            344,
            127,
            215,
            39,
            300,
            91,
            65,
            66,
            150,
            454,
            453,
            131,
            366,
            379,
            386,
            222,
            289,
            239,
            76,
            321,
            190,
            62,
            191,
            171,
            353,
            435,
            269,
            340,
            275,
            63,
            481,
            324,
            165,
            94,
            201,
            339,
            159,
            59,
            183,
            84
        ]
    },
    {
        "query": "Change all Movie objects into Work objects, and their associated\n    data into WorkRole and WorkSelection models, then delete the Movie.",
        "positive_code": "def forwards(apps, schema_editor):\n    \n    Movie = apps.get_model(, )\n    Work = apps.get_model(, )\n    WorkRole = apps.get_model(, )\n    WorkSelection = apps.get_model(, )\n\n    for m in Movie.objects.all():\n\n        work = Work.objects.create(\n            kind=,\n            title=m.title,\n            title_sort=m.title_sort,\n            year=m.year,\n            imdb_id=m.imdb_id\n        )\n\n        for role in m.roles.all():\n            WorkRole.objects.create(\n                creator=role.creator,\n                work=work,\n                role_name=role.role_name,\n                role_order=role.role_order\n            )\n\n        for selection in m.events.all():\n            WorkSelection.objects.create(\n                event=selection.event,\n                work=work,\n                order=selection.order\n            )\n\n        m.delete()",
        "hard_negative_ids": [
            79,
            193,
            383,
            85,
            152,
            421,
            199,
            223,
            187,
            429,
            89,
            424,
            198,
            333,
            13,
            283,
            63,
            489,
            450,
            498,
            474,
            470,
            291,
            33,
            195,
            295,
            357,
            297,
            25,
            116,
            154,
            440,
            360,
            466,
            113,
            324,
            201,
            76,
            81,
            197,
            414,
            284,
            492,
            484,
            393,
            78,
            273,
            23,
            443,
            142
        ]
    },
    {
        "query": "Auto Generated Code",
        "positive_code": "def get_vmpolicy_macaddr_input_datacenter(self, **kwargs):\n        \n        config = ET.Element(\"config\")\n        get_vmpolicy_macaddr = ET.Element(\"get_vmpolicy_macaddr\")\n        config = get_vmpolicy_macaddr\n        input = ET.SubElement(get_vmpolicy_macaddr, \"input\")\n        datacenter = ET.SubElement(input, \"datacenter\")\n        datacenter.text = kwargs.pop()\n\n        callback = kwargs.pop(, self._callback)\n        return callback(config)",
        "hard_negative_ids": [
            339,
            360,
            300,
            69,
            307,
            138,
            16,
            17,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455
        ]
    },
    {
        "query": ":param didMethodName: name of DID Method\n        :param required: if not found and True, throws an exception, else None\n        :return: DID Method",
        "positive_code": "def get(self, didMethodName, required=True) -> DidMethod:\n        \n        dm = self.d.get(didMethodName) if didMethodName else self.default\n        if not dm and required:\n            raise DidMethodNotFound\n        return dm",
        "hard_negative_ids": [
            168,
            323,
            360,
            81,
            41,
            349,
            498,
            70,
            178,
            44,
            402,
            139,
            204,
            344,
            66,
            201,
            176,
            496,
            300,
            414,
            91,
            258,
            424,
            189,
            307,
            318,
            87,
            232,
            429,
            386,
            434,
            435,
            370,
            470,
            65,
            179,
            466,
            412,
            454,
            395,
            150,
            291,
            446,
            197,
            24,
            345,
            184,
            57,
            281,
            73
        ]
    },
    {
        "query": "Set general layout and style properties of text and code cells",
        "positive_code": "def style_layout(style_less,\n                 theme=,\n                 cursorwidth=2,\n                 cursorcolor=,\n                 cellwidth=,\n                 lineheight=170,\n                 margins=,\n                 vimext=False,\n                 toolbar=False,\n                 nbname=False,\n                 kernellogo=False,\n                 altprompt=False,\n                 altmd=False,\n                 altout=False,\n                 hideprompt=False):\n    \n\n    \n    with fileOpen(theme_name_file, ) as f:\n        f.write(theme)\n\n    if (os.path.isdir(styles_dir_user) and\n            .format(theme) in os.listdir(styles_dir_user)):\n        theme_relpath = os.path.relpath(\n            os.path.join(styles_dir_user, theme), package_dir)\n    else:\n        theme_relpath = os.path.relpath(\n            os.path.join(styles_dir, theme), package_dir)\n\n    style_less += .format(theme_relpath)\n\n    textcell_bg = \n    promptText = \n    promptBG = \n    promptPadding = \n    promptBorder = \n    tcPromptBorder = \n    promptMinWidth = 11.5\n    outpromptMinWidth = promptMinWidth \n    tcPromptWidth = promptMinWidth + 3\n    tcPromptFontsize = \"@prompt-fontsize\"\n    ccOutputBG = \n\n    if theme == :\n        textcell_bg = \n    if altprompt:\n        promptPadding = \n        promptMinWidth = 8\n        outpromptMinWidth = promptMinWidth + 3\n        tcPromptWidth = promptMinWidth + 3\n        promptText = \n        tcPromptBorder = \n    if altmd:\n        textcell_bg = \n        tcPromptBorder = \n    if altout:\n        ccOutputBG = \n    if margins != :\n        margins = .format(margins)\n    if  not in cellwidth:\n        cellwidth = str(cellwidth) + \n\n    style_less += .format(margins)\n    style_less += .format(cellwidth)\n    style_less += .format(lineheight)\n    style_less += .format(textcell_bg)\n    style_less += .format(promptMinWidth)\n    style_less += .format(promptBG)\n    style_less += .format(ccOutputBG)\n    style_less += .format(promptText)\n    style_less += .format(promptPadding)\n    style_less += .format(promptBorder)\n    style_less += .format(promptMinWidth)\n    style_less += .format(outpromptMinWidth)\n    style_less += .format(tcPromptWidth)\n    style_less += .format(tcPromptBorder)\n    style_less += .format(cursorwidth)\n    style_less += .format(\n        cursorcolor)\n    style_less += .format(tcPromptFontsize)\n    style_less += \n\n    \n    with fileOpen(nb_style, ) as notebook:\n        style_less += notebook.read() + \n\n    \n    with fileOpen(cl_style, ) as cells:\n        style_less += cells.read() + \n\n    \n    with fileOpen(ex_style, ) as extras:\n        style_less += extras.read() + \n\n    \n    with fileOpen(cm_style, ) as codemirror:\n        style_less += codemirror.read() + \n    with fileOpen(comp_style, ) as codemirror:\n        style_less += codemirror.read() + \n\n    style_less += toggle_settings(\n        toolbar, nbname, hideprompt, kernellogo) + \n    if vimext:\n        set_vim_style(theme)\n\n    return style_less",
        "hard_negative_ids": [
            47,
            327,
            88,
            464,
            339,
            349,
            199,
            397,
            359,
            433,
            15,
            437,
            62,
            425,
            300,
            69,
            184,
            25,
            113,
            90,
            395,
            318,
            116,
            470,
            232,
            466,
            44,
            52,
            272,
            307,
            11,
            97,
            24,
            289,
            138,
            429,
            197,
            485,
            490,
            117,
            78,
            345,
            109,
            46,
            219,
            227,
            257,
            477,
            239,
            236
        ]
    },
    {
        "query": "Initializes self.options",
        "positive_code": "def _init_options(self, kwargs):\n        \n        self.options = self.task_config.options\n        if self.options is None:\n            self.options = {}\n        if kwargs:\n            self.options.update(kwargs)\n\n        \n        for option, value in list(self.options.items()):\n            try:\n                if value.startswith(\"$project_config.\"):\n                    attr = value.replace(\"$project_config.\", \"\", 1)\n                    self.options[option] = getattr(self.project_config, attr, None)\n            except AttributeError:\n                pass",
        "hard_negative_ids": [
            130,
            385,
            182,
            303,
            62,
            64,
            109,
            179,
            498,
            55,
            406,
            423,
            150,
            398,
            351,
            478,
            251,
            487,
            362,
            3,
            196,
            56,
            224,
            313,
            328,
            176,
            168,
            408,
            108,
            170,
            447,
            389,
            338,
            276,
            112,
            361,
            247,
            432,
            45,
            22,
            455,
            320,
            122,
            476,
            411,
            460,
            372,
            482,
            459,
            114
        ]
    },
    {
        "query": "Handler for cp command",
        "positive_code": "def cp_handler(self, args):\n    \n\n    self.validate(, args)\n    source = args[1]\n    target = args[2]\n    self.s3handler().cp_files(source, target)",
        "hard_negative_ids": [
            385,
            444,
            261,
            166,
            394,
            236,
            472,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190,
            443,
            145,
            103,
            4,
            344,
            122,
            387,
            246,
            411,
            477,
            15,
            85,
            215,
            209,
            40,
            388,
            226,
            10,
            64
        ]
    },
    {
        "query": "Read 1 byte as a signed integer value from the stream.\n\n        Args:\n            little_endian (bool): specify the endianness. (Default) Little endian.\n\n        Returns:\n            int:",
        "positive_code": "def read_int8(self, little_endian=True):\n        \n        if little_endian:\n            endian = \"<\"\n        else:\n            endian = \">\"\n        return self.unpack( % endian)",
        "hard_negative_ids": [
            424,
            269,
            168,
            147,
            407,
            360,
            405,
            462,
            414,
            41,
            306,
            84,
            211,
            287,
            488,
            449,
            56,
            11,
            382,
            349,
            219,
            432,
            466,
            386,
            15,
            106,
            267,
            332,
            295,
            391,
            481,
            385,
            304,
            112,
            76,
            197,
            179,
            166,
            91,
            73,
            441,
            459,
            291,
            356,
            242,
            19,
            324,
            316,
            366,
            362
        ]
    },
    {
        "query": "Return a copy of a PIL image as a numpy array.\n\n    Parameters\n    ----------\n    im : PIL image\n        Input image.\n    flatten : bool\n        If true, convert the output to grey-scale.\n    mode : str, optional\n        Mode to convert image to, e.g. ``'RGB'``.  See the Notes of the\n        `imread` docstring for more details.\n\n    Returns\n    -------\n    fromimage : ndarray\n        The different colour bands/channels are stored in the\n        third dimension, such that a grey-image is MxN, an\n        RGB-image MxNx3 and an RGBA-image MxNx4.",
        "positive_code": "def fromimage(im, flatten=False, mode=None):\n    \n    if not Image.isImageType(im):\n        raise TypeError(\"Input is not a PIL image.\")\n\n    if mode is not None:\n        if mode != im.mode:\n            im = im.convert(mode)\n    elif im.mode == :\n        \n        \n        \n        \n        if  in im.info:\n            im = im.convert()\n        else:\n            im = im.convert()\n\n    if flatten:\n        im = im.convert()\n    elif im.mode == :\n        \n        \n        \n        \n        \n        \n        im = im.convert()\n\n    a = array(im)\n    return a",
        "hard_negative_ids": [
            360,
            391,
            12,
            429,
            414,
            466,
            264,
            368,
            496,
            462,
            136,
            275,
            38,
            276,
            286,
            349,
            73,
            197,
            435,
            460,
            291,
            23,
            76,
            18,
            88,
            245,
            171,
            109,
            376,
            256,
            263,
            304,
            189,
            106,
            472,
            34,
            470,
            320,
            317,
            25,
            318,
            222,
            68,
            427,
            271,
            81,
            345,
            331,
            252,
            82
        ]
    },
    {
        "query": "Returns validators description in format:\n    ### Validators:\n    * validator1 name\n     * validator1 docstring\n    * validator2 name\n     * validator2 docstring",
        "positive_code": "def get_validators_description(view):\n    \n    action = getattr(view, , None)\n    if action is None:\n        return \n\n    description = \n    validators = getattr(view, action + , [])\n    for validator in validators:\n        validator_description = get_entity_description(validator)\n        description +=  + validator_description if description else validator_description\n\n    return  + description if description else ",
        "hard_negative_ids": [
            498,
            369,
            184,
            412,
            176,
            478,
            66,
            287,
            16,
            65,
            488,
            191,
            237,
            324,
            150,
            123,
            5,
            212,
            85,
            454,
            70,
            366,
            359,
            420,
            112,
            451,
            258,
            139,
            284,
            321,
            269,
            385,
            386,
            179,
            316,
            7,
            91,
            396,
            41,
            500,
            296,
            492,
            391,
            82,
            207,
            27,
            453,
            411,
            62,
            226
        ]
    },
    {
        "query": "Take the branch, commit, and build selection and add them as plugins",
        "positive_code": "def on_ok(self):\n        \n        self.parentApp.repo_value[] = {}\n        self.parentApp.repo_value[] = {}\n        for branch in self.branch_cb:\n            if self.branch_cb[branch].value:\n                \n                self.parentApp.repo_value[][branch] = self.commit_tc[branch].values[self.commit_tc[branch].value]\n                self.parentApp.repo_value[][branch] = True\n        if self.error:\n            self.quit()\n        self.parentApp.addForm(,\n                               ChooseToolsForm,\n                               name=\n                               ,\n                               color=)\n        self.parentApp.change_form()",
        "hard_negative_ids": [
            127,
            328,
            335,
            291,
            131,
            414,
            105,
            453,
            215,
            360,
            142,
            23,
            289,
            466,
            197,
            272,
            136,
            106,
            73,
            24,
            304,
            25,
            349,
            391,
            485,
            429,
            44,
            345,
            184,
            46,
            462,
            219,
            257,
            477,
            178,
            426,
            317,
            425,
            94,
            118,
            201,
            21,
            473,
            149,
            171,
            371,
            15,
            76,
            318,
            433
        ]
    },
    {
        "query": "Convert persistence collector output to downloadable rdfvalues.",
        "positive_code": "def Parse(self, persistence, knowledge_base, download_pathtype):\n    \n    pathspecs = []\n\n    if isinstance(persistence, rdf_client.WindowsServiceInformation):\n      if persistence.HasField(\"binary\"):\n        pathspecs.append(persistence.binary.pathspec)\n      elif persistence.HasField(\"image_path\"):\n        pathspecs = self._GetFilePaths(persistence.image_path,\n                                       download_pathtype, knowledge_base)\n\n    if isinstance(\n        persistence,\n        rdf_client_fs.StatEntry) and persistence.HasField(\"registry_type\"):\n      pathspecs = self._GetFilePaths(persistence.registry_data.string,\n                                     download_pathtype, knowledge_base)\n\n    for pathspec in pathspecs:\n      yield rdf_standard.PersistenceFile(pathspec=pathspec)",
        "hard_negative_ids": [
            376,
            136,
            227,
            9,
            34,
            252,
            275,
            171,
            269,
            327,
            131,
            368,
            295,
            414,
            264,
            189,
            73,
            360,
            47,
            76,
            266,
            157,
            329,
            466,
            99,
            109,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464,
            463
        ]
    },
    {
        "query": "Generates a blob for importing a key to CryptoAPI\n\n    :param key_info:\n        An asn1crypto.keys.PublicKeyInfo or asn1crypto.keys.PrivateKeyInfo\n        object\n\n    :param key_type:\n        A unicode string of \"public\" or \"private\"\n\n    :param algo:\n        A unicode string of \"rsa\" or \"dsa\"\n\n    :param signing:\n        If the key handle is for signing - may only be False for rsa keys\n\n    :return:\n        A byte string of a blob to pass to advapi32.CryptImportKey()",
        "positive_code": "def _advapi32_create_blob(key_info, key_type, algo, signing=True):\n    \n\n    if key_type == :\n        blob_type = Advapi32Const.PUBLICKEYBLOB\n    else:\n        blob_type = Advapi32Const.PRIVATEKEYBLOB\n\n    if algo == :\n        struct_type = \n        if signing:\n            algorithm_id = Advapi32Const.CALG_RSA_SIGN\n        else:\n            algorithm_id = Advapi32Const.CALG_RSA_KEYX\n    else:\n        struct_type = \n        algorithm_id = Advapi32Const.CALG_DSS_SIGN\n\n    blob_header_pointer = struct(advapi32, )\n    blob_header = unwrap(blob_header_pointer)\n    blob_header.bType = blob_type\n    blob_header.bVersion = Advapi32Const.CUR_BLOB_VERSION\n    blob_header.reserved = 0\n    blob_header.aiKeyAlg = algorithm_id\n\n    blob_struct_pointer = struct(advapi32, struct_type)\n    blob_struct = unwrap(blob_struct_pointer)\n    blob_struct.publickeystruc = blob_header\n\n    bit_size = key_info.bit_size\n    len1 = bit_size // 8\n    len2 = bit_size // 16\n\n    if algo == :\n        pubkey_pointer = struct(advapi32, )\n        pubkey = unwrap(pubkey_pointer)\n        pubkey.bitlen = bit_size\n        if key_type == :\n            parsed_key_info = key_info[].parsed\n            pubkey.magic = Advapi32Const.RSA1\n            pubkey.pubexp = parsed_key_info[].native\n            blob_data = int_to_bytes(parsed_key_info[].native, signed=False, width=len1)[::-1]\n        else:\n            parsed_key_info = key_info[].parsed\n            pubkey.magic = Advapi32Const.RSA2\n            pubkey.pubexp = parsed_key_info[].native\n            blob_data = int_to_bytes(parsed_key_info[].native, signed=False, width=len1)[::-1]\n            blob_data += int_to_bytes(parsed_key_info[].native, signed=False, width=len2)[::-1]\n            blob_data += int_to_bytes(parsed_key_info[].native, signed=False, width=len2)[::-1]\n            blob_data += int_to_bytes(parsed_key_info[].native, signed=False, width=len2)[::-1]\n            blob_data += int_to_bytes(parsed_key_info[].native, signed=False, width=len2)[::-1]\n            blob_data += int_to_bytes(parsed_key_info[].native, signed=False, width=len2)[::-1]\n            blob_data += int_to_bytes(parsed_key_info[].native, signed=False, width=len1)[::-1]\n        blob_struct.rsapubkey = pubkey\n\n    else:\n        pubkey_pointer = struct(advapi32, )\n        pubkey = unwrap(pubkey_pointer)\n        pubkey.bitlen = bit_size\n\n        if key_type == :\n            pubkey.magic = Advapi32Const.DSS1\n            params = key_info[][].native\n            key_data = int_to_bytes(key_info[].parsed.native, signed=False, width=len1)[::-1]\n        else:\n            pubkey.magic = Advapi32Const.DSS2\n            params = key_info[][].native\n            key_data = int_to_bytes(key_info[].parsed.native, signed=False, width=20)[::-1]\n        blob_struct.dsspubkey = pubkey\n\n        blob_data = int_to_bytes(params[], signed=False, width=len1)[::-1]\n        blob_data += int_to_bytes(params[], signed=False, width=20)[::-1]\n        blob_data += int_to_bytes(params[], signed=False, width=len1)[::-1]\n        blob_data += key_data\n\n        dssseed_pointer = struct(advapi32, )\n        dssseed = unwrap(dssseed_pointer)\n        \n        dssseed.counter = 0xffffffff\n\n        blob_data += struct_bytes(dssseed_pointer)\n\n    return struct_bytes(blob_struct_pointer) + blob_data",
        "hard_negative_ids": [
            210,
            481,
            413,
            81,
            196,
            470,
            40,
            360,
            425,
            342,
            73,
            45,
            466,
            349,
            15,
            113,
            476,
            232,
            391,
            79,
            97,
            291,
            382,
            171,
            387,
            414,
            304,
            106,
            344,
            204,
            197,
            300,
            442,
            48,
            188,
            222,
            76,
            462,
            11,
            429,
            264,
            179,
            189,
            345,
            4,
            317,
            453,
            178,
            249,
            182
        ]
    },
    {
        "query": "Apply incoming copying manipulators to `son`.",
        "positive_code": "def _apply_incoming_copying_manipulators(self, son, collection):\n        \n        for manipulator in self.__incoming_copying_manipulators:\n            son = manipulator.transform_incoming(son, collection)\n        return son",
        "hard_negative_ids": [
            61,
            23,
            171,
            269,
            131,
            239,
            368,
            376,
            295,
            414,
            264,
            189,
            73,
            275,
            360,
            47,
            76,
            266,
            157,
            329,
            466,
            99,
            109,
            25,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464,
            463,
            462,
            461
        ]
    },
    {
        "query": "Build dictionary of content",
        "positive_code": "def render_to_response(self, context, *args, **kwargs):\n        \n        preview_outputs = []\n        file_outputs = []\n        bast_ctx = context\n        added = set()\n\n        for output_group, output_files in context[][].items():\n            for output_file_content in output_files:\n                if output_group:\n                    bast_ctx.update({\n                        : context[],\n                        : output_group,\n                        : output_file_content,\n                    })\n                    preview = render_to_string( % output_group, bast_ctx)\n                    preview_outputs.append(preview)\n\n        for file_info in context[][]:\n            if file_info and file_info.get() not in added:\n                row_ctx = dict(\n                    file=file_info,\n                    **context\n                )\n                table_row = render_to_string(, row_ctx)\n                file_outputs.append(table_row)\n                added.add(file_info.get())\n\n        return JsonResponse({\n            : context[][].lower(),\n            : context[][].command,\n            : context[][].get_stdout(),\n            : context[][].get_stderr(),\n            : preview_outputs,\n            : file_outputs,\n        })",
        "hard_negative_ids": [
            273,
            308,
            62,
            105,
            382,
            178,
            275,
            349,
            395,
            470,
            232,
            466,
            429,
            197,
            318,
            23,
            157,
            272,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            469,
            468,
            467,
            465,
            464,
            463,
            462,
            461,
            460
        ]
    },
    {
        "query": "Initializes internal state and build fp32 master copy of weights.\n\n        :param model: fp16 model",
        "positive_code": "def initialize_model(self, model):\n        \n        logging.info()\n        self.fp16_model = model\n        self.fp16_model.zero_grad()\n        self.fp32_params = [param.to(torch.float32).detach()\n                            for param in model.parameters()]\n\n        for param in self.fp32_params:\n            param.requires_grad = True",
        "hard_negative_ids": [
            89,
            333,
            489,
            198,
            81,
            325,
            410,
            217,
            273,
            202,
            185,
            465,
            360,
            344,
            467,
            105,
            97,
            152,
            204,
            349,
            336,
            300,
            179,
            420,
            395,
            352,
            470,
            232,
            466,
            318,
            23,
            34,
            74,
            76,
            429,
            197,
            256,
            24,
            485,
            157,
            345,
            184,
            46,
            219,
            257,
            477,
            272,
            94,
            118,
            201
        ]
    },
    {
        "query": "Read the ical file",
        "positive_code": "def read_ical(self, ical_file_location):  \n        \n        with open(ical_file_location, ) as ical_file:\n            data = ical_file.read()\n        self.cal = Calendar.from_ical(data)\n        return self.cal",
        "hard_negative_ids": [
            449,
            171,
            363,
            459,
            414,
            356,
            169,
            44,
            360,
            197,
            275,
            291,
            23,
            466,
            467,
            479,
            136,
            73,
            376,
            1,
            144,
            206,
            429,
            353,
            327,
            163,
            277,
            25,
            138,
            264,
            319,
            289,
            365,
            99,
            109,
            21,
            20,
            19,
            18,
            480,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469
        ]
    },
    {
        "query": "Gest a specific user",
        "positive_code": "def get_user(self, username):\n        \n        ret = {}\n        tmp = self._get_user(self._byte_p2(username), ALL_ATTRS)\n        if tmp is None:\n            raise UserDoesntExist(username, self.backend_name)\n        attrs_tmp = tmp[1]\n        for attr in attrs_tmp:\n            value_tmp = attrs_tmp[attr]\n            if len(value_tmp) == 1:\n                ret[attr] = value_tmp[0]\n            else:\n                ret[attr] = value_tmp\n        return ret",
        "hard_negative_ids": [
            425,
            187,
            55,
            103,
            106,
            415,
            304,
            391,
            131,
            453,
            178,
            317,
            360,
            228,
            173,
            171,
            15,
            470,
            256,
            382,
            293,
            462,
            222,
            349,
            472,
            76,
            466,
            180,
            272,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471,
            469,
            468,
            467,
            465,
            464
        ]
    },
    {
        "query": "Returns a template for this report.\n\n        :rtype: `jinja2.Template`",
        "positive_code": "def _get_template(self):\n        \n        loader = PackageLoader(self._package_name, )\n        env = Environment(extensions=[], loader=loader)\n        return env.get_template(.format(self._report_name))",
        "hard_negative_ids": [
            325,
            198,
            71,
            106,
            304,
            391,
            293,
            189,
            90,
            317,
            453,
            178,
            425,
            15,
            47,
            360,
            171,
            470,
            256,
            414,
            382,
            192,
            275,
            222,
            462,
            76,
            349,
            472,
            272,
            466,
            23,
            180,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            247,
            29,
            305,
            205,
            61,
            500,
            267,
            133,
            53
        ]
    },
    {
        "query": "Prepare reserved tokens and a regex for splitting them out of strings.",
        "positive_code": "def _prepare_reserved_tokens(reserved_tokens):\n  \n  reserved_tokens = [tf.compat.as_text(tok) for tok in reserved_tokens or []]\n  dups = _find_duplicates(reserved_tokens)\n  if dups:\n    raise ValueError(\"Duplicates found in tokens: %s\" % dups)\n  reserved_tokens_re = _make_reserved_tokens_re(reserved_tokens)\n  return reserved_tokens, reserved_tokens_re",
        "hard_negative_ids": [
            280,
            477,
            94,
            131,
            349,
            435,
            210,
            171,
            413,
            40,
            323,
            342,
            470,
            163,
            106,
            189,
            304,
            185,
            291,
            203,
            269,
            466,
            414,
            391,
            439,
            232,
            157,
            317,
            395,
            453,
            198,
            178,
            425,
            318,
            15,
            360,
            112,
            462,
            429,
            149,
            174,
            197,
            272,
            76,
            256,
            382,
            266,
            24,
            222,
            184
        ]
    },
    {
        "query": "Simulates a mouse right click on pixel (x,y) if x and y are provided\n    If x and y are not passed to this function, a mouse click is simulated at the current (x,y)\n\n    :param x: target x-ordinate\n    :param y: target y-ordinate\n    :param hold_time: length of time to hold the mouse's right button\n    :return: None",
        "positive_code": "def click_right(x = None, y = None, hold_time = 0):\n    \n\n    if not x or not y:\n        cursor = win32api.GetCursorPos()\n        if not x:\n            x = cursor[0]\n        if not y:\n            y = cursor[1]\n    move(x, y)\n    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTDOWN, x, y, 0, 0)\n    time.sleep(hold_time)\n    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTUP, x, y, 0, 0)",
        "hard_negative_ids": [
            3,
            263,
            240,
            81,
            466,
            245,
            134,
            495,
            321,
            25,
            24,
            360,
            228,
            349,
            318,
            499,
            296,
            241,
            204,
            414,
            201,
            464,
            472,
            496,
            449,
            490,
            109,
            290,
            197,
            42,
            76,
            156,
            429,
            23,
            46,
            47,
            202,
            267,
            295,
            291,
            171,
            73,
            67,
            136,
            333,
            58,
            185,
            344,
            235,
            391
        ]
    },
    {
        "query": "Register a gradient function to a random string.\n\n  In order to use a custom gradient in TensorFlow, it must be registered to a\n  string. This is both a hassle, and -- because only one function can every be\n  registered to a string -- annoying to iterate on in an interactive\n  environemnt.\n\n  This function registers a function to a unique random string of the form:\n\n    {FUNCTION_NAME}_{RANDOM_SALT}\n\n  And then returns the random string. This is a helper in creating more\n  convenient gradient overrides.\n\n  Args:\n    grad_f: gradient function to register. Should map (op, grad) -> grad(s)\n\n  Returns:\n    String that gradient function was registered to.",
        "positive_code": "def register_to_random_name(grad_f):\n  \n  grad_f_name = grad_f.__name__ + \"_\" + str(uuid.uuid4())\n  tf.RegisterGradient(grad_f_name)(grad_f)\n  return grad_f_name",
        "hard_negative_ids": [
            210,
            66,
            360,
            413,
            42,
            232,
            40,
            342,
            73,
            414,
            297,
            47,
            470,
            386,
            415,
            466,
            462,
            235,
            189,
            295,
            99,
            171,
            429,
            382,
            291,
            192,
            142,
            197,
            391,
            269,
            349,
            304,
            106,
            318,
            2,
            275,
            76,
            471,
            90,
            255,
            69,
            23,
            179,
            15,
            178,
            218,
            159,
            109,
            219,
            41
        ]
    },
    {
        "query": "|HeaderPart| object containing content of this header.",
        "positive_code": "def _definition(self):\n        \n        headerReference = self._sectPr.get_headerReference(self._hdrftr_index)\n        return self._document_part.header_part(headerReference.rId)",
        "hard_negative_ids": [
            223,
            273,
            79,
            62,
            107,
            470,
            283,
            152,
            275,
            368,
            102,
            300,
            157,
            297,
            236,
            189,
            349,
            90,
            395,
            232,
            265,
            466,
            113,
            47,
            81,
            44,
            429,
            197,
            148,
            68,
            318,
            109,
            414,
            192,
            272,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            469,
            468,
            467,
            465
        ]
    },
    {
        "query": "Clip off all parts of the line strings that are outside of the image.\n\n        Returns\n        -------\n        imgaug.augmentables.lines.LineStringsOnImage\n            Line strings, clipped to fall within the image dimensions.",
        "positive_code": "def clip_out_of_image(self):\n        \n        lss_cut = [ls_clipped\n                   for ls in self.line_strings\n                   for ls_clipped in ls.clip_out_of_image(self.shape)]\n        return LineStringsOnImage(lss_cut, shape=self.shape)",
        "hard_negative_ids": [
            360,
            452,
            477,
            466,
            210,
            407,
            413,
            429,
            12,
            201,
            40,
            264,
            414,
            197,
            186,
            342,
            171,
            276,
            73,
            286,
            359,
            64,
            438,
            291,
            25,
            349,
            136,
            252,
            341,
            300,
            9,
            448,
            76,
            69,
            318,
            295,
            395,
            23,
            470,
            157,
            232,
            109,
            85,
            116,
            47,
            142,
            159,
            499,
            44,
            424
        ]
    },
    {
        "query": "Query the execution environment.\n\n        Parameters\n        ----------\n        field : {'platform', 'arena', 'data_frequency',\n                 'start', 'end', 'capital_base', 'platform', '*'}\n            The field to query. The options have the following meanings:\n              arena : str\n                  The arena from the simulation parameters. This will normally\n                  be ``'backtest'`` but some systems may use this distinguish\n                  live trading from backtesting.\n              data_frequency : {'daily', 'minute'}\n                  data_frequency tells the algorithm if it is running with\n                  daily data or minute data.\n              start : datetime\n                  The start date for the simulation.\n              end : datetime\n                  The end date for the simulation.\n              capital_base : float\n                  The starting capital for the simulation.\n              platform : str\n                  The platform that the code is running on. By default this\n                  will be the string 'zipline'. This can allow algorithms to\n                  know if they are running on the Quantopian platform instead.\n              * : dict[str -> any]\n                  Returns all of the fields in a dictionary.\n\n        Returns\n        -------\n        val : any\n            The value for the field queried. See above for more information.\n\n        Raises\n        ------\n        ValueError\n            Raised when ``field`` is not a valid option.",
        "positive_code": "def get_environment(self, field=):\n        \n        env = {\n            : self.sim_params.arena,\n            : self.sim_params.data_frequency,\n            : self.sim_params.first_open,\n            : self.sim_params.last_close,\n            : self.sim_params.capital_base,\n            : self._platform\n        }\n        if field == :\n            return env\n        else:\n            try:\n                return env[field]\n            except KeyError:\n                raise ValueError(\n                     % field,\n                )",
        "hard_negative_ids": [
            360,
            460,
            466,
            278,
            291,
            130,
            493,
            349,
            382,
            136,
            178,
            268,
            47,
            414,
            424,
            82,
            182,
            80,
            73,
            23,
            232,
            429,
            485,
            56,
            174,
            269,
            25,
            189,
            324,
            69,
            222,
            211,
            404,
            210,
            57,
            8,
            499,
            197,
            85,
            76,
            243,
            385,
            64,
            237,
            413,
            371,
            127,
            201,
            472,
            339
        ]
    },
    {
        "query": "zb: Zone bypass. Zone < 0 unbypass all; Zone > Max bypass all.",
        "positive_code": "def zb_encode(zone, area, user_code):\n    \n    if zone < 0:\n        zone = 0\n    elif zone > Max.ZONES.value:\n        zone = 999\n    else:\n        zone += 1\n    return MessageEncode(.format(\n        zone=zone, area=area+1, code=user_code), )",
        "hard_negative_ids": [
            23,
            142,
            159,
            116,
            85,
            475,
            80,
            485,
            429,
            240,
            179,
            245,
            295,
            12,
            76,
            88,
            252,
            162,
            17,
            60,
            25,
            47,
            206,
            430,
            237,
            201,
            105,
            154,
            64,
            149,
            197,
            347,
            268,
            24,
            56,
            182,
            203,
            379,
            155,
            256,
            460,
            284,
            404,
            81,
            450,
            202,
            331,
            254,
            314,
            217
        ]
    },
    {
        "query": "Gets the list of BIOS/UEFI values currently set on the physical server.\n\n        Returns:\n            dict: Dictionary of BIOS/UEFI values.",
        "positive_code": "def get_bios(self):\n        \n        uri = \"{}/bios\".format(self.data[\"uri\"])\n        return self._helper.do_get(uri)",
        "hard_negative_ids": [
            332,
            382,
            376,
            429,
            308,
            349,
            466,
            265,
            2,
            395,
            197,
            178,
            142,
            15,
            267,
            333,
            90,
            232,
            56,
            182,
            11,
            291,
            207,
            25,
            127,
            272,
            360,
            457,
            481,
            424,
            500,
            499,
            414,
            166,
            441,
            239,
            204,
            228,
            470,
            130,
            23,
            73,
            159,
            280,
            366,
            362,
            361,
            91,
            47,
            410
        ]
    },
    {
        "query": "Return a list containing the ports of local side of the TCP tunnels",
        "positive_code": "def local_bind_ports(self):\n        \n        self._check_is_started()\n        return [_server.local_port for _server in self._server_list if\n                _server.local_port is not None]",
        "hard_negative_ids": [
            429,
            466,
            197,
            360,
            470,
            349,
            414,
            395,
            291,
            106,
            232,
            304,
            227,
            391,
            136,
            23,
            73,
            147,
            453,
            178,
            25,
            44,
            425,
            317,
            272,
            318,
            77,
            293,
            2,
            171,
            15,
            328,
            157,
            267,
            256,
            382,
            332,
            76,
            477,
            183,
            462,
            410,
            260,
            98,
            290,
            222,
            110,
            81,
            79,
            424
        ]
    },
    {
        "query": "Shortcut for manifest.files.append",
        "positive_code": "def add_file(self, name=\"\", hashalg=\"\", hash=\"\", comClasses=None, \n                 typelibs=None, comInterfaceProxyStubs=None, \n                 windowClasses=None):\n        \n        self.files.append(File(name, hashalg, hash, comClasses, \n                          typelibs, comInterfaceProxyStubs, windowClasses))",
        "hard_negative_ids": [
            363,
            402,
            405,
            171,
            413,
            27,
            223,
            342,
            427,
            275,
            285,
            145,
            196,
            35,
            445,
            199,
            274,
            467,
            321,
            443,
            455,
            344,
            205,
            458,
            206,
            172,
            341,
            144,
            2,
            169,
            104,
            376,
            192,
            149,
            340,
            81,
            1,
            64,
            444,
            438,
            322,
            61,
            302,
            349,
            155,
            469,
            315,
            293,
            23,
            44
        ]
    },
    {
        "query": "Fetch default value for a function argument\n\n    Args:\n        __func: Function to inspect\n        __arg: Argument to extract default value for",
        "positive_code": "def get_default(__func: Callable, __arg: str) -> str:\n    \n    return signature(__func).parameters[__arg].default",
        "hard_negative_ids": [
            424,
            168,
            42,
            306,
            405,
            84,
            395,
            142,
            56,
            235,
            269,
            76,
            267,
            179,
            332,
            481,
            287,
            382,
            488,
            166,
            349,
            441,
            41,
            15,
            171,
            366,
            219,
            362,
            91,
            147,
            11,
            73,
            19,
            242,
            360,
            112,
            222,
            106,
            199,
            385,
            304,
            324,
            316,
            182,
            232,
            280,
            391,
            34,
            277,
            103
        ]
    },
    {
        "query": "Return dictionary with default repo name and url",
        "positive_code": "def default_repository(self):\n        \n        default_dict_repo = {}\n        for line in self.default_repositories_list.splitlines():\n            line = line.lstrip()\n            if not line.startswith(\"\n                if line.split()[0] in self.DEFAULT_REPOS_NAMES:\n                    default_dict_repo[line.split()[0]] = line.split()[1]\n                else:\n                    print(\"\\nslpkg: Error: Repository name  is not \"\n                          \"default.\\n              Please check file: \"\n                          \"/etc/slpkg/default-repositories\\n\".format(\n                              line.split()[0]))\n                    raise SystemExit()\n        return default_dict_repo",
        "hard_negative_ids": [
            458,
            168,
            424,
            308,
            306,
            84,
            498,
            389,
            405,
            38,
            76,
            176,
            364,
            322,
            161,
            382,
            178,
            187,
            369,
            357,
            339,
            429,
            249,
            65,
            402,
            179,
            9,
            66,
            150,
            319,
            463,
            412,
            138,
            454,
            201,
            391,
            366,
            184,
            170,
            386,
            230,
            324,
            96,
            91,
            131,
            321,
            427,
            434,
            74,
            269
        ]
    },
    {
        "query": "Timeseries in PyPSA compatible format for generator instances\n\n    Parameters\n    ----------\n    network : Network\n        The eDisGo grid topology model overall container\n    timesteps : array_like\n        Timesteps is an array-like object with entries of type\n        :pandas:`pandas.Timestamp<timestamp>` specifying which time steps\n        to export to pypsa representation and use in power flow analysis.\n    mode : str, optional\n        Specifically retrieve generator time series for MV or LV grid level or\n        both. Either choose 'mv' or 'lv'.\n        Defaults to None, which returns both timeseries for MV and LV in a\n        single DataFrame.\n\n    Returns\n    -------\n    :pandas:`pandas.DataFrame<dataframe>`\n        Time series table in PyPSA format",
        "positive_code": "def _pypsa_generator_timeseries(network, timesteps, mode=None):\n    \n\n    mv_gen_timeseries_q = []\n    mv_gen_timeseries_p = []\n    lv_gen_timeseries_q = []\n    lv_gen_timeseries_p = []\n\n    \n    if mode is  or mode is None:\n        for gen in network.mv_grid.generators:\n            mv_gen_timeseries_q.append(gen.pypsa_timeseries().rename(\n                repr(gen)).to_frame().loc[timesteps])\n            mv_gen_timeseries_p.append(gen.pypsa_timeseries().rename(\n                repr(gen)).to_frame().loc[timesteps])\n        if mode is :\n            lv_gen_timeseries_p, lv_gen_timeseries_q = \\\n                _pypsa_generator_timeseries_aggregated_at_lv_station(\n                    network, timesteps)\n\n    \n    if mode is  or mode is None:\n        for lv_grid in network.mv_grid.lv_grids:\n            for gen in lv_grid.generators:\n                lv_gen_timeseries_q.append(gen.pypsa_timeseries().rename(\n                    repr(gen)).to_frame().loc[timesteps])\n                lv_gen_timeseries_p.append(gen.pypsa_timeseries().rename(\n                    repr(gen)).to_frame().loc[timesteps])\n\n    gen_df_p = pd.concat(mv_gen_timeseries_p + lv_gen_timeseries_p, axis=1)\n    gen_df_q = pd.concat(mv_gen_timeseries_q + lv_gen_timeseries_q, axis=1)\n\n    return gen_df_p, gen_df_q",
        "hard_negative_ids": [
            156,
            291,
            202,
            360,
            429,
            239,
            414,
            450,
            466,
            146,
            412,
            460,
            490,
            25,
            435,
            33,
            245,
            368,
            349,
            333,
            260,
            232,
            76,
            24,
            269,
            275,
            38,
            32,
            73,
            159,
            79,
            345,
            113,
            81,
            103,
            137,
            469,
            391,
            197,
            293,
            489,
            26,
            89,
            470,
            17,
            23,
            252,
            201,
            485,
            222
        ]
    },
    {
        "query": "Converts DB-API parameter values into query parameters.\n\n    :type parameters: Mapping[str, Any] or Sequence[Any]\n    :param parameters: A dictionary or sequence of query parameter values.\n\n    :rtype: List[google.cloud.bigquery.query._AbstractQueryParameter]\n    :returns: A list of query parameters.",
        "positive_code": "def to_query_parameters(parameters):\n    \n    if parameters is None:\n        return []\n\n    if isinstance(parameters, collections_abc.Mapping):\n        return to_query_parameters_dict(parameters)\n\n    return to_query_parameters_list(parameters)",
        "hard_negative_ids": [
            360,
            332,
            243,
            165,
            123,
            349,
            232,
            113,
            382,
            15,
            359,
            404,
            178,
            308,
            142,
            81,
            267,
            395,
            391,
            429,
            56,
            222,
            192,
            470,
            182,
            333,
            23,
            481,
            269,
            442,
            425,
            259,
            174,
            280,
            181,
            106,
            127,
            344,
            466,
            304,
            11,
            233,
            424,
            91,
            76,
            272,
            166,
            204,
            199,
            207
        ]
    },
    {
        "query": "Setter method for lsp_select_path, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/lsp_select_path (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp_select_path is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp_select_path() directly.",
        "positive_code": "def _set_lsp_select_path(self, v, load=False):\n    \n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lsp_select_path.lsp_select_path, is_container=, presence=False, yang_name=\"lsp-select-path\", rest_name=\"select-path\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u: {u: u, u: None, u: None, u: None, u: None, u: u}}, namespace=, defining_module=, yang_type=, is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          : ,\n          : \"container\",\n          : ,\n        })\n\n    self.__lsp_select_path = t\n    if hasattr(self, ):\n      self._set()",
        "hard_negative_ids": [
            373,
            292,
            324,
            323,
            189,
            69,
            409,
            171,
            391,
            429,
            414,
            275,
            454,
            41,
            178,
            425,
            360,
            207,
            291,
            462,
            500,
            405,
            466,
            402,
            44,
            70,
            457,
            228,
            139,
            317,
            361,
            99,
            449,
            130,
            47,
            304,
            265,
            192,
            117,
            73,
            363,
            5,
            188,
            159,
            382,
            388,
            23,
            106,
            181,
            222
        ]
    },
    {
        "query": "Delete a Network Interface Controller",
        "positive_code": "def delete_nic(self, instance_id, port_id):\n        \n        self.client.servers.interface_detach(instance_id, port_id)\n        return True",
        "hard_negative_ids": [
            498,
            315,
            469,
            187,
            13,
            450,
            293,
            106,
            304,
            391,
            227,
            453,
            429,
            178,
            317,
            425,
            360,
            171,
            15,
            470,
            329,
            256,
            382,
            462,
            222,
            349,
            472,
            76,
            466,
            180,
            272,
            23,
            25,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471,
            468
        ]
    },
    {
        "query": "Get information about this object as a dictionary.  Used by WebSocket interface to pass some\n            relevant information to client applications.",
        "positive_code": "def get_as_datadict(self):\n        \n        return dict(type=self.__class__.__name__, tags=list(self.tags))",
        "hard_negative_ids": [
            382,
            498,
            423,
            315,
            79,
            308,
            472,
            178,
            291,
            113,
            171,
            470,
            189,
            269,
            360,
            434,
            297,
            106,
            304,
            47,
            421,
            414,
            391,
            275,
            191,
            295,
            453,
            264,
            73,
            15,
            317,
            425,
            103,
            227,
            90,
            131,
            326,
            427,
            76,
            93,
            368,
            376,
            74,
            81,
            266,
            466,
            256,
            180,
            23,
            82
        ]
    },
    {
        "query": "Retrieve a single page of NotificationInstance records from the API.\n        Request is executed immediately\n\n        :param unicode log: Filter by log level\n        :param date message_date_before: Filter by date\n        :param date message_date: Filter by date\n        :param date message_date_after: Filter by date\n        :param str page_token: PageToken provided by the API\n        :param int page_number: Page Number, this value is simply for client state\n        :param int page_size: Number of records to return, defaults to 50\n\n        :returns: Page of NotificationInstance\n        :rtype: twilio.rest.api.v2010.account.call.notification.NotificationPage",
        "positive_code": "def page(self, log=values.unset, message_date_before=values.unset,\n             message_date=values.unset, message_date_after=values.unset,\n             page_token=values.unset, page_number=values.unset,\n             page_size=values.unset):\n        \n        params = values.of({\n            : log,\n            : serialize.iso8601_date(message_date_before),\n            : serialize.iso8601_date(message_date),\n            : serialize.iso8601_date(message_date_after),\n            : page_token,\n            : page_number,\n            : page_size,\n        })\n\n        response = self._version.page(\n            ,\n            self._uri,\n            params=params,\n        )\n\n        return NotificationPage(self._version, response, self._solution)",
        "hard_negative_ids": [
            460,
            306,
            193,
            481,
            57,
            273,
            81,
            291,
            360,
            383,
            105,
            423,
            482,
            246,
            8,
            142,
            429,
            197,
            191,
            207,
            26,
            252,
            466,
            349,
            131,
            73,
            32,
            222,
            204,
            16,
            212,
            97,
            412,
            407,
            312,
            474,
            300,
            414,
            344,
            424,
            139,
            232,
            491,
            388,
            136,
            384,
            13,
            185,
            107,
            275
        ]
    },
    {
        "query": "Extract the JSON payload from a JWT.\n\n    Does the extraction w/o checking the signature.\n\n    Args:\n        id_token: string or bytestring, OAuth 2.0 id_token.\n\n    Returns:\n        object, The deserialized JSON payload.",
        "positive_code": "def _extract_id_token(id_token):\n    \n    if type(id_token) == bytes:\n        segments = id_token.split(b)\n    else:\n        segments = id_token.split(u)\n\n    if len(segments) != 3:\n        raise VerifyJwtTokenError(\n            .format(id_token))\n\n    return json.loads(\n        _helpers._from_bytes(_helpers._urlsafe_b64decode(segments[1])))",
        "hard_negative_ids": [
            70,
            428,
            395,
            76,
            73,
            413,
            210,
            401,
            79,
            429,
            360,
            40,
            382,
            414,
            342,
            41,
            136,
            24,
            291,
            434,
            297,
            391,
            207,
            287,
            466,
            147,
            488,
            179,
            197,
            334,
            159,
            112,
            219,
            470,
            265,
            240,
            269,
            44,
            149,
            162,
            69,
            353,
            109,
            23,
            472,
            385,
            425,
            52,
            230,
            324
        ]
    },
    {
        "query": "Creates a decorator that will instantiate objects based on function\n    parameter annotations.\n\n    The decorator will check every argument passed into ``f``. If ``f`` has an\n    annotation for the specified parameter and the annotation is found in\n    ``classes``, the parameter value passed in will be used to construct a new\n    instance of the expression that is the annotation.\n\n    An example (Python 3):\n\n    .. code-block:: python\n\n        @auto_instantiate(int)\n        def foo(a: int, b: float):\n            pass\n\n    Any value passed in as ``b`` is left unchanged. Anything passed as the\n    parameter for ``a`` will be converted to :class:`int` before calling the\n    function.\n\n    Since Python 2 does not support annotations, the\n    :func:`~data.decorators.annotate` function should can be used:\n\n    .. code-block:: python\n\n        @auto_instantiate(int)\n        @annotate(a=int)\n        def foo(a, b):\n            pass\n\n\n    :param classes: Any number of classes/callables for which\n                    auto-instantiation should be performed. If empty, perform\n                    for all.\n\n    :note: When dealing with data, it is almost always more convenient to use\n           the :func:`~data.decorators.data` decorator instead.",
        "positive_code": "def auto_instantiate(*classes):\n    \n    def decorator(f):\n        \n        sig = signature(f)\n\n        @wraps(f)\n        def _(*args, **kwargs):\n            bvals = sig.bind(*args, **kwargs)\n\n            \n            for varname, val in bvals.arguments.items():\n                anno = sig.parameters[varname].annotation\n\n                if anno in classes or (len(classes) == 0 and anno != _empty):\n                    bvals.arguments[varname] = anno(val)\n\n            return f(*bvals.args, **bvals.kwargs)\n\n        \n        \n        return FunctionMaker.create(\n            f, , dict(_=_, __wrapped__=f)\n        )\n\n    return decorator",
        "hard_negative_ids": [
            42,
            425,
            360,
            201,
            269,
            142,
            391,
            69,
            76,
            252,
            106,
            291,
            414,
            466,
            297,
            195,
            47,
            349,
            15,
            186,
            73,
            232,
            462,
            149,
            56,
            58,
            48,
            424,
            382,
            197,
            470,
            324,
            453,
            386,
            60,
            217,
            136,
            337,
            294,
            404,
            421,
            182,
            112,
            89,
            97,
            23,
            178,
            82,
            429,
            77
        ]
    },
    {
        "query": "Drop all tables in a database.",
        "positive_code": "def truncate_database(self, database=None):\n        \n        \n        if database in self.databases and database is not self.database:\n            self.change_db(database)\n\n        \n        tables = self.tables if isinstance(self.tables, list) else [self.tables]\n        if len(tables) > 0:\n            self.drop(tables)\n            self._printer( + str(len(tables)), , database)\n        return tables",
        "hard_negative_ids": [
            291,
            314,
            247,
            450,
            329,
            9,
            103,
            106,
            85,
            304,
            76,
            116,
            391,
            183,
            44,
            317,
            178,
            453,
            425,
            142,
            295,
            15,
            360,
            88,
            171,
            137,
            47,
            201,
            470,
            181,
            90,
            256,
            382,
            237,
            25,
            222,
            23,
            462,
            349,
            472,
            272,
            466,
            180,
            305,
            135,
            321,
            215,
            209,
            489,
            35
        ]
    },
    {
        "query": "This serverextension handles:\n            {base_url}/proxy/{port([0-9]+)}/{proxied_path}\n            {base_url}/proxy/absolute/{port([0-9]+)}/{proxied_path}\n            {base_url}/{proxy_base}/{proxied_path}",
        "positive_code": "async def proxy(self, port, proxied_path):\n        \n\n        if  in self.request.headers:\n            del self.request.headers[]\n\n        self._record_activity()\n\n        if self.request.headers.get(\"Upgrade\", \"\").lower() == :\n            \n            \n            self.log.info(\"we wanna websocket, but we donPOSTContent-LengthTransfer-EncodingContent-EncodingConnectionSet-Cookie'\n                    self.add_header(header, v)\n\n            if response.body:\n                self.write(response.body)",
        "hard_negative_ids": [
            429,
            222,
            189,
            266,
            227,
            207,
            361,
            162,
            457,
            391,
            500,
            147,
            265,
            69,
            159,
            95,
            177,
            88,
            293,
            350,
            296,
            443,
            464,
            275,
            426,
            160,
            12,
            317,
            388,
            462,
            90,
            245,
            472,
            206,
            47,
            387,
            403,
            414,
            14,
            175,
            382,
            97,
            100,
            416,
            347,
            240,
            109,
            17,
            264,
            291
        ]
    },
    {
        "query": "Invert the transform",
        "positive_code": "def invert(self):\n        \n        libfn = utils.get_lib_fn( % (self._libsuffix))\n        inv_tx_ptr = libfn(self.pointer)\n\n        new_tx = ANTsTransform(precision=self.precision, dimension=self.dimension,\n                                transform_type=self.transform_type, pointer=inv_tx_ptr)\n\n        return new_tx",
        "hard_negative_ids": [
            299,
            49,
            360,
            197,
            414,
            318,
            291,
            466,
            136,
            73,
            429,
            44,
            23,
            25,
            109,
            30,
            29,
            28,
            27,
            26,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457
        ]
    },
    {
        "query": "Initialize an empty RNA quantification set",
        "positive_code": "def initRnaQuantificationSet(self):\n        \n        store = rnaseq2ga.RnaSqliteStore(self._args.filePath)\n        store.createTables()",
        "hard_negative_ids": [
            340,
            97,
            189,
            381,
            360,
            44,
            327,
            25,
            11,
            427,
            90,
            73,
            289,
            414,
            239,
            184,
            99,
            236,
            61,
            109,
            272,
            235,
            127,
            258,
            490,
            23,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461
        ]
    },
    {
        "query": "Compiles a directory of Jinja2 templates to python code.\n  \n  :param env: a Jinja2 Environment instance.\n  :param src_path: path to the source directory.\n  :param dst_path: path to the destination directory.\n  :param encoding: template encoding.\n  :param base_dir: the base path to be removed from the compiled template filename.",
        "positive_code": "def compile_dir(env, src_path, dst_path, pattern=r, encoding=, base_dir=None):\n  \n  from os import path, listdir, mkdir\n  file_re = re.compile(pattern)\n\n  if base_dir is None:\n    base_dir = src_path\n\n  for filename in listdir(src_path):\n    src_name = path.join(src_path, filename)\n    dst_name = path.join(dst_path, filename)\n\n    if path.isdir(src_name):\n      mkdir(dst_name)\n      compile_dir(env, src_name, dst_name, encoding=encoding, base_dir=base_dir)\n    elif path.isfile(src_name) and file_re.match(filename):\n      compile_file(env, src_name, dst_name, encoding=encoding, base_dir=base_dir)",
        "hard_negative_ids": [
            38,
            325,
            360,
            81,
            269,
            163,
            291,
            466,
            117,
            1,
            300,
            293,
            414,
            413,
            333,
            204,
            169,
            456,
            216,
            73,
            198,
            71,
            170,
            181,
            103,
            373,
            40,
            470,
            197,
            339,
            344,
            171,
            193,
            386,
            392,
            364,
            44,
            407,
            232,
            47,
            275,
            379,
            246,
            254,
            131,
            219,
            363,
            23,
            109,
            380
        ]
    },
    {
        "query": "REGEXP function for Sqlite",
        "positive_code": "def _regexp(expr, item):\n    \n    reg = re.compile(expr)\n    return reg.search(item) is not None",
        "hard_negative_ids": [
            42,
            235,
            142,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            29,
            247,
            317,
            205,
            305,
            61,
            500,
            65,
            267,
            232,
            133,
            53,
            384,
            476,
            190,
            443,
            145,
            103,
            4,
            344,
            122,
            387,
            246,
            411,
            477,
            15,
            85,
            215,
            209,
            40,
            388,
            226,
            10,
            64,
            169,
            149,
            88,
            36,
            146
        ]
    },
    {
        "query": "Find the first prefix that has been mapped to a namespace URI.\n        The local mapping is searched, then it walks up the tree until\n        it reaches the top or finds a match.\n        @param uri: A namespace URI.\n        @type uri: basestring\n        @param default: A default prefix when not found.\n        @type default: basestring\n        @return: A mapped prefix.\n        @rtype: basestring",
        "positive_code": "def findPrefix(self, uri, default=None):\n        \n        for item in self.nsprefixes.items():\n            if item[1] == uri:\n                prefix = item[0]\n                return prefix\n        for item in self.specialprefixes.items():\n            if item[1] == uri:\n                prefix = item[0]\n                return prefix\n        if self.parent is not None:\n            return self.parent.findPrefix(uri, default)\n        else:\n            return default",
        "hard_negative_ids": [
            277,
            360,
            199,
            168,
            424,
            306,
            73,
            341,
            76,
            84,
            500,
            146,
            405,
            204,
            377,
            81,
            197,
            165,
            291,
            232,
            178,
            304,
            391,
            171,
            466,
            106,
            414,
            113,
            23,
            425,
            349,
            429,
            87,
            44,
            453,
            344,
            136,
            222,
            353,
            60,
            317,
            258,
            189,
            69,
            403,
            469,
            300,
            15,
            122,
            285
        ]
    },
    {
        "query": "shortcut making an XML element getter",
        "positive_code": "def elemgetter(path: str) -> t.Callable[[Element], Element]:\n    \n    return compose(\n        partial(_raise_if_none, exc=LookupError(path)),\n        methodcaller(, path)\n    )",
        "hard_negative_ids": [
            461,
            433,
            339,
            348,
            34,
            227,
            189,
            360,
            327,
            440,
            427,
            311,
            73,
            414,
            17,
            498,
            31,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462
        ]
    },
    {
        "query": "Pulls a string from redis and deserializes it from json. Deserialized\n    dictionary data loaded directly into top level if pillar_key is not set.\n\n    pillar_key\n        Pillar key to return data into",
        "positive_code": "def key_json(minion_id,\n             pillar,  \n             pillar_key=None):\n    \n    key_data = __salt__[](minion_id)\n    \n    if not key_data:\n        return {}\n\n    data = salt.utils.json.loads(key_data)\n    \n    if isinstance(data, dict) and not pillar_key:\n        return data\n    elif not pillar_key:\n        return {: data}\n    else:\n        return {pillar_key: data}",
        "hard_negative_ids": [
            11,
            26,
            413,
            210,
            421,
            32,
            428,
            40,
            196,
            308,
            382,
            342,
            178,
            223,
            484,
            338,
            45,
            131,
            69,
            73,
            498,
            424,
            334,
            171,
            283,
            476,
            179,
            33,
            387,
            195,
            15,
            324,
            357,
            48,
            85,
            256,
            154,
            440,
            13,
            442,
            345,
            264,
            222,
            360,
            99,
            304,
            376,
            193,
            492,
            141
        ]
    },
    {
        "query": "r\"\"\"Calculate the horizontal divergence of the horizontal wind.\n\n    Parameters\n    ----------\n    u : (M, N) ndarray\n        x component of the wind\n    v : (M, N) ndarray\n        y component of the wind\n    dx : float or ndarray\n        The grid spacing(s) in the x-direction. If an array, there should be one item less than\n        the size of `u` along the applicable axis.\n    dy : float or ndarray\n        The grid spacing(s) in the y-direction. If an array, there should be one item less than\n        the size of `u` along the applicable axis.\n\n    Returns\n    -------\n    (M, N) ndarray\n        The horizontal divergence\n\n    See Also\n    --------\n    vorticity\n\n    Notes\n    -----\n    If inputs have more than two dimensions, they are assumed to have either leading dimensions\n    of (x, y) or trailing dimensions of (y, x), depending on the value of ``dim_order``.",
        "positive_code": "def divergence(u, v, dx, dy):\n    r\n    dudx = first_derivative(u, delta=dx, axis=-1)\n    dvdy = first_derivative(v, delta=dy, axis=-2)\n    return dudx + dvdy",
        "hard_negative_ids": [
            263,
            245,
            291,
            462,
            240,
            156,
            466,
            414,
            496,
            160,
            3,
            360,
            232,
            472,
            23,
            73,
            464,
            381,
            56,
            1,
            292,
            192,
            179,
            197,
            495,
            429,
            349,
            189,
            321,
            49,
            290,
            149,
            386,
            122,
            267,
            296,
            152,
            328,
            318,
            88,
            25,
            182,
            85,
            326,
            426,
            136,
            53,
            329,
            77,
            470
        ]
    },
    {
        "query": "List all roles.\n\n        Args:\n            **request_parameters: Additional request parameters (provides\n                support for parameters that may be added in the future).\n\n        Returns:\n            GeneratorContainer: A GeneratorContainer which, when iterated,\n            yields the roles returned by the Webex Teams query.\n\n        Raises:\n            TypeError: If the parameter types are incorrect.\n            ApiError: If the Webex Teams cloud returns an error.",
        "positive_code": "def list(self, **request_parameters):\n        \n        \n        items = self._session.get_items(\n            API_ENDPOINT,\n            params=request_parameters\n        )\n\n        \n        for item in items:\n            yield self._object_factory(OBJECT_TYPE, item)",
        "hard_negative_ids": [
            360,
            291,
            123,
            136,
            23,
            233,
            293,
            139,
            73,
            287,
            488,
            8,
            232,
            222,
            466,
            146,
            414,
            41,
            269,
            491,
            243,
            297,
            85,
            470,
            197,
            324,
            112,
            25,
            382,
            295,
            429,
            385,
            44,
            425,
            316,
            192,
            402,
            76,
            219,
            415,
            285,
            237,
            147,
            129,
            453,
            496,
            131,
            427,
            477,
            344
        ]
    },
    {
        "query": "Returns a generator of all URLs attached to this API",
        "positive_code": "def urls(self):\n        \n        for base_url, mapping in self.routes.items():\n            for url, _ in mapping.items():\n                yield base_url + url",
        "hard_negative_ids": [
            429,
            47,
            71,
            189,
            470,
            171,
            76,
            349,
            295,
            466,
            207,
            360,
            106,
            304,
            85,
            116,
            391,
            389,
            414,
            90,
            395,
            453,
            275,
            178,
            232,
            317,
            425,
            38,
            322,
            161,
            157,
            142,
            187,
            357,
            269,
            15,
            339,
            131,
            364,
            88,
            197,
            222,
            249,
            368,
            376,
            201,
            402,
            264,
            9,
            256
        ]
    },
    {
        "query": "Evaluate all recordings in `sample_dir`.\n\n    Parameters\n    ----------\n    sample_dir : string\n        The path to a directory with *.inkml files.\n\n    Returns\n    -------\n    list of dictionaries\n        Each dictionary contains the keys 'filename' and 'results', where\n        'results' itself is a list of dictionaries. Each of the results has\n        the keys 'latex' and 'probability'",
        "positive_code": "def evaluate_dir(sample_dir):\n    \n    results = []\n    if sample_dir[-1] == \"/\":\n        sample_dir = sample_dir[:-1]\n    for filename in glob.glob(\"%s/*.inkml\" % sample_dir):\n        results.append(evaluate_inkml(filename))\n    return results",
        "hard_negative_ids": [
            287,
            38,
            363,
            360,
            466,
            308,
            210,
            178,
            429,
            32,
            349,
            201,
            382,
            414,
            76,
            413,
            2,
            197,
            487,
            391,
            291,
            438,
            496,
            171,
            329,
            25,
            40,
            373,
            223,
            196,
            169,
            452,
            222,
            23,
            151,
            73,
            342,
            493,
            109,
            364,
            272,
            264,
            237,
            226,
            470,
            170,
            290,
            44,
            295,
            96
        ]
    },
    {
        "query": "Determine how many bytes can be read out of C{fObj} (assuming it is not\n        modified from this point on).  If the determination cannot be made,\n        return C{UNKNOWN_LENGTH}.",
        "positive_code": "def _determineLength(self, fObj):\n        \n        try:\n            seek = fObj.seek\n            tell = fObj.tell\n        except AttributeError:\n            return UNKNOWN_LENGTH\n        originalPosition = tell()\n        seek(0, self._SEEK_END)\n        end = tell()\n        seek(originalPosition, self._SEEK_SET)\n        return end - originalPosition",
        "hard_negative_ids": [
            255,
            232,
            210,
            296,
            429,
            78,
            163,
            342,
            256,
            435,
            470,
            197,
            383,
            449,
            47,
            414,
            97,
            500,
            131,
            466,
            386,
            499,
            69,
            291,
            254,
            192,
            450,
            490,
            183,
            204,
            73,
            382,
            459,
            356,
            360,
            269,
            349,
            239,
            315,
            189,
            157,
            101,
            130,
            99,
            439,
            462,
            90,
            275,
            23,
            479
        ]
    },
    {
        "query": "Send the PGRP chunk over the specified socket.",
        "positive_code": "def send_pgrp(cls, sock, pgrp):\n    \n    assert(isinstance(pgrp, IntegerForPid) and pgrp < 0)\n    encoded_int = cls.encode_int(pgrp)\n    cls.write_chunk(sock, ChunkType.PGRP, encoded_int)",
        "hard_negative_ids": [
            262,
            132,
            414,
            73,
            360,
            465,
            197,
            149,
            58,
            291,
            466,
            266,
            136,
            318,
            61,
            429,
            44,
            23,
            25,
            109,
            27,
            26,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            464,
            463,
            462,
            461,
            460,
            459,
            458
        ]
    },
    {
        "query": "Send message to backend.",
        "positive_code": "def send(self, stat, value, rate=1):\n        \n        if rate < 1:\n            value = \"%s|@%s\" % (value, rate)\n        return super().send(stat, value, rate)",
        "hard_negative_ids": [
            488,
            262,
            132,
            301,
            264,
            37,
            327,
            465,
            171,
            269,
            131,
            293,
            368,
            376,
            427,
            295,
            414,
            189,
            73,
            275,
            360,
            47,
            76,
            266,
            157,
            329,
            466,
            99,
            109,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468
        ]
    },
    {
        "query": "Setter method for customized, mapped from YANG variable /rbridge_id/hardware_profile/kap/customized (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_customized is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_customized() directly.",
        "positive_code": "def _set_customized(self, v, load=False):\n    \n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=customized.customized, is_container=, presence=False, yang_name=\"customized\", rest_name=\"custom-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u: {u: u, u: u, u: None}}, namespace=, defining_module=, yang_type=, is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          : ,\n          : \"container\",\n          : ,\n        })\n\n    self.__customized = t\n    if hasattr(self, ):\n      self._set()",
        "hard_negative_ids": [
            373,
            324,
            323,
            189,
            409,
            171,
            69,
            414,
            391,
            275,
            454,
            429,
            41,
            178,
            425,
            360,
            291,
            405,
            466,
            462,
            402,
            44,
            70,
            207,
            228,
            139,
            500,
            99,
            457,
            449,
            317,
            130,
            47,
            304,
            192,
            117,
            73,
            361,
            363,
            5,
            188,
            106,
            265,
            23,
            197,
            181,
            382,
            227,
            222,
            9
        ]
    },
    {
        "query": "This is an internal method, building the command for a particular file.",
        "positive_code": "def buildCommand(self,fileName,count,args):\n        \n        \n\tfileNameWithPath = self.escapePlaceholders(fileName)\n\n        \n        commandParts = args.command.split()\n        processedParts = []\n        \n        for part in commandParts:\n            processedParts.append(self.buildPart(part,fileNameWithPath,count,args))\n        \n        return self.unescapePlaceholders(.join(processedParts))",
        "hard_negative_ids": [
            444,
            323,
            360,
            171,
            414,
            189,
            166,
            41,
            44,
            23,
            363,
            70,
            73,
            394,
            139,
            304,
            236,
            402,
            97,
            106,
            385,
            197,
            466,
            391,
            47,
            90,
            291,
            317,
            472,
            425,
            275,
            453,
            15,
            178,
            467,
            222,
            136,
            429,
            144,
            376,
            434,
            382,
            169,
            427,
            1,
            25,
            192,
            277,
            470,
            99
        ]
    },
    {
        "query": "Matches the function identified by the given ``Id``.\n\n        arg:    function_id (osid.id.Id): the Id of the ``Function``\n        arg:    match (boolean): ``true`` if a positive match, ``false``\n                for a negative match\n        raise:  NullArgument - ``function_id`` is ``null``\n        *compliance: mandatory -- This method must be implemented.*",
        "positive_code": "def match_function_id(self, function_id, match):\n        \n        self._add_match(, str(function_id), bool(match))",
        "hard_negative_ids": [
            42,
            197,
            73,
            232,
            429,
            291,
            470,
            256,
            318,
            23,
            462,
            360,
            466,
            192,
            323,
            258,
            386,
            382,
            41,
            63,
            235,
            414,
            477,
            349,
            44,
            142,
            139,
            391,
            79,
            70,
            459,
            52,
            295,
            304,
            453,
            425,
            106,
            489,
            136,
            344,
            402,
            434,
            187,
            345,
            463,
            178,
            113,
            25,
            99,
            222
        ]
    },
    {
        "query": "Use this method to send point on the map.\n        :param chat_id:\n        :param latitude:\n        :param longitude:\n        :param live_period\n        :param reply_to_message_id:\n        :param reply_markup:\n        :return: API reply.",
        "positive_code": "def send_location(self, chat_id, latitude, longitude, live_period=None, reply_to_message_id=None, reply_markup=None,\n                      disable_notification=None):\n        \n        return types.Message.de_json(\n            apihelper.send_location(self.token, chat_id, latitude, longitude, live_period, reply_to_message_id,\n                                    reply_markup,\n                                    disable_notification))",
        "hard_negative_ids": [
            132,
            204,
            81,
            47,
            323,
            414,
            344,
            300,
            41,
            122,
            429,
            189,
            70,
            360,
            139,
            465,
            499,
            207,
            402,
            152,
            44,
            73,
            343,
            466,
            130,
            392,
            192,
            197,
            90,
            291,
            275,
            58,
            136,
            171,
            269,
            434,
            131,
            368,
            376,
            295,
            183,
            87,
            264,
            23,
            25,
            109,
            426,
            76,
            266,
            157
        ]
    },
    {
        "query": "Generates samples of text from the provided vocabulary.\n\n  Args:\n    plain_vocab: vocabulary.\n    distribution: distribution.\n    train_samples: samples for training.\n    length: length.\n\n  Returns:\n    train_indices (np.array of Integers): random integers for training.\n      shape = [num_samples, length]\n    test_indices (np.array of Integers): random integers for testing.\n      shape = [num_samples, length]\n    plain_vocab   (list of Integers): unique vocabularies.",
        "positive_code": "def generate_plaintext_random(plain_vocab, distribution, train_samples,\n                              length):\n  \n  if distribution is not None:\n    assert len(distribution) == len(plain_vocab)\n\n  train_indices = np.random.choice(\n      range(len(plain_vocab)), (train_samples, length), p=distribution)\n\n  return train_indices",
        "hard_negative_ids": [
            81,
            449,
            88,
            448,
            12,
            419,
            218,
            240,
            317,
            256,
            349,
            299,
            318,
            466,
            471,
            197,
            211,
            179,
            287,
            147,
            488,
            100,
            462,
            177,
            440,
            41,
            381,
            232,
            429,
            395,
            23,
            333,
            437,
            263,
            101,
            219,
            464,
            470,
            269,
            486,
            62,
            112,
            433,
            385,
            324,
            316,
            67,
            425,
            414,
            73
        ]
    },
    {
        "query": "Pass in a mongo model class and extract all the attributes which\n    are mongoengine fields\n\n    Returns:\n        list of strings of field attributes",
        "positive_code": "def get_fields(model_class):\n    \n    return [\n        attr for attr, value in model_class.__dict__.items()\n        if issubclass(type(value), (mongo.base.BaseField, mongo.EmbeddedDocumentField))  \n    ]",
        "hard_negative_ids": [
            91,
            84,
            477,
            466,
            8,
            89,
            360,
            146,
            333,
            489,
            411,
            76,
            198,
            349,
            429,
            278,
            291,
            210,
            197,
            235,
            470,
            73,
            25,
            413,
            40,
            318,
            136,
            424,
            342,
            23,
            273,
            127,
            395,
            106,
            467,
            232,
            297,
            85,
            304,
            113,
            152,
            142,
            116,
            391,
            34,
            353,
            295,
            414,
            499,
            277
        ]
    },
    {
        "query": "Describe this _LocalTransformJob\n\n        The response is a JSON-like dictionary that follows the response of the\n        boto describe_transform_job() API.\n\n        Returns:\n            dict: description of this _LocalTransformJob",
        "positive_code": "def describe(self):\n        \n        response = {\n            : self.state,\n            : self.model_name,\n            : self.name,\n            : _UNUSED_ARN,\n            : self.end_time,\n            : self.start_time,\n            : self.start_time,\n            : {},\n            : self.batch_strategy,\n        }\n\n        if self.transform_resources:\n            response[] = self.transform_resources\n\n        if self.output_data:\n            response[] = self.output_data\n\n        if self.input_data:\n            response[] = self.input_data\n\n        return response",
        "hard_negative_ids": [
            167,
            360,
            429,
            414,
            463,
            178,
            466,
            197,
            428,
            52,
            308,
            382,
            349,
            425,
            427,
            322,
            7,
            207,
            243,
            470,
            2,
            265,
            339,
            369,
            291,
            184,
            189,
            391,
            90,
            232,
            304,
            395,
            73,
            47,
            434,
            106,
            136,
            237,
            359,
            23,
            318,
            124,
            25,
            44,
            345,
            453,
            171,
            489,
            157,
            272
        ]
    },
    {
        "query": "Sets column width",
        "positive_code": "def set_col_width(self, col, tab, width):\n        \n\n        try:\n            old_width = self.col_widths.pop((col, tab))\n\n        except KeyError:\n            old_width = None\n\n        if width is not None:\n            self.col_widths[(col, tab)] = float(width)",
        "hard_negative_ids": [
            22,
            135,
            142,
            424,
            346,
            44,
            126,
            464,
            25,
            125,
            11,
            97,
            90,
            289,
            239,
            184,
            236,
            61,
            109,
            272,
            235,
            127,
            258,
            490,
            23,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456
        ]
    },
    {
        "query": "Save the load to the specified jid",
        "positive_code": "def save_load(jid, clear_load, minion=None):\n    \n    cb_ = _get_connection()\n\n    try:\n        jid_doc = cb_.get(six.text_type(jid))\n    except couchbase.exceptions.NotFoundError:\n        cb_.add(six.text_type(jid), {}, ttl=_get_ttl())\n        jid_doc = cb_.get(six.text_type(jid))\n\n    jid_doc.value[] = clear_load\n    cb_.replace(six.text_type(jid), jid_doc.value, cas=jid_doc.cas, ttl=_get_ttl())\n\n    \n    if  in clear_load and clear_load[] != :\n        ckminions = salt.utils.minions.CkMinions(__opts__)\n        \n        _res = ckminions.check_minions(\n            clear_load[],\n            clear_load.get(, )\n            )\n        minions = _res[]\n        save_minions(jid, minions)",
        "hard_negative_ids": [
            478,
            73,
            360,
            414,
            452,
            264,
            466,
            197,
            291,
            467,
            22,
            409,
            109,
            340,
            136,
            302,
            318,
            397,
            273,
            429,
            44,
            178,
            260,
            171,
            329,
            269,
            163,
            23,
            131,
            25,
            368,
            376,
            292,
            295,
            189,
            275,
            47,
            76,
            266,
            157,
            99,
            19,
            18,
            1,
            480,
            479,
            477,
            476,
            475,
            474
        ]
    },
    {
        "query": "Determine whether `action` is strictly dominated by some mixed\n        action.\n\n        Parameters\n        ----------\n        action : scalar(int)\n            Integer representing a pure action.\n\n        tol : scalar(float), optional(default=None)\n            Tolerance level used in determining domination. If None,\n            default to the value of the `tol` attribute.\n\n        method : str, optional(default=None)\n            If None, `lemke_howson` from `quantecon.game_theory` is used\n            to solve for a Nash equilibrium of an auxiliary zero-sum\n            game. If `method` is set to `'simplex'` or\n            `'interior-point'`, `scipy.optimize.linprog` is used with\n            the method as specified by `method`.\n\n        Returns\n        -------\n        bool\n            True if `action` is strictly dominated by some mixed action;\n            False otherwise.",
        "positive_code": "def is_dominated(self, action, tol=None, method=None):\n        \n        if tol is None:\n            tol = self.tol\n\n        payoff_array = self.payoff_array\n\n        if self.num_opponents == 0:\n            return payoff_array.max() > payoff_array[action] + tol\n\n        ind = np.ones(self.num_actions, dtype=bool)\n        ind[action] = False\n        D = payoff_array[ind]\n        D -= payoff_array[action]\n        if D.shape[0] == 0:  \n            return False\n        if self.num_opponents >= 2:\n            D.shape = (D.shape[0], np.prod(D.shape[1:]))\n\n        if method is None:\n            from .lemke_howson import lemke_howson\n            g_zero_sum = NormalFormGame([Player(D), Player(-D.T)])\n            NE = lemke_howson(g_zero_sum)\n            return NE[0] @ D @ NE[1] > tol\n        elif method in [, ]:\n            from scipy.optimize import linprog\n            m, n = D.shape\n            A = np.empty((n+2, m+1))\n            A[:n, :m] = -D.T\n            A[:n, -1] = 1  \n            A[n, :m], A[n+1, :m] = 1, -1  \n            A[n:, -1] = 0\n            b = np.empty(n+2)\n            b[:n] = 0\n            b[n], b[n+1] = 1, -1\n            c = np.zeros(m+1)\n            c[-1] = -1\n            res = linprog(c, A_ub=A, b_ub=b, method=method)\n            if res.success:\n                return res.x[-1] > tol\n            elif res.status == 2:  \n                return False\n            else:  \n                msg = .format(res.status)\n                raise RuntimeError(msg)\n        else:\n            raise ValueError(.format(method))",
        "hard_negative_ids": [
            91,
            132,
            323,
            424,
            168,
            291,
            209,
            360,
            414,
            56,
            73,
            306,
            460,
            429,
            349,
            329,
            41,
            466,
            255,
            435,
            84,
            462,
            76,
            26,
            405,
            197,
            451,
            23,
            391,
            211,
            44,
            11,
            106,
            402,
            32,
            260,
            222,
            70,
            232,
            318,
            171,
            139,
            304,
            12,
            185,
            382,
            25,
            425,
            15,
            272
        ]
    },
    {
        "query": "Touch all of the related models for the relationship.",
        "positive_code": "def touch(self):\n        \n        column = self.get_related().get_updated_at_column()\n\n        self.raw_update({column: self.get_related().fresh_timestamp()})",
        "hard_negative_ids": [
            480,
            152,
            466,
            197,
            360,
            489,
            429,
            89,
            414,
            333,
            291,
            193,
            85,
            25,
            198,
            116,
            136,
            73,
            232,
            349,
            23,
            395,
            142,
            470,
            76,
            44,
            273,
            295,
            88,
            467,
            47,
            201,
            237,
            318,
            157,
            109,
            272,
            135,
            321,
            35,
            363,
            234,
            223,
            377,
            29,
            247,
            317,
            205,
            305,
            61
        ]
    },
    {
        "query": " ",
        "positive_code": "def _example_stock_basic(quote_ctx):\n    \n    ret_status, ret_data = quote_ctx.get_stock_basicinfo(ft.Market.HK, ft.SecurityType.STOCK)\n    if ret_status != ft.RET_OK:\n        print(ret_data)\n        exit()\n    print(\"stock_basic\")\n    print(ret_data)",
        "hard_negative_ids": [
            500,
            499,
            498,
            497,
            496,
            495,
            494,
            493,
            492,
            491,
            490,
            489,
            488,
            487,
            486,
            485,
            484,
            483,
            482,
            481,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453,
            452,
            451
        ]
    },
    {
        "query": "Parse the XML returned by the C{CreateSnapshot} function.\n\n        @param xml_bytes: XML bytes with a C{CreateSnapshotResponse} root\n            element.\n        @return: The L{Snapshot} instance created.\n\n        TODO: ownerId, volumeSize, description.",
        "positive_code": "def create_snapshot(self, xml_bytes):\n        \n        root = XML(xml_bytes)\n        snapshot_id = root.findtext(\"snapshotId\")\n        volume_id = root.findtext(\"volumeId\")\n        status = root.findtext(\"status\")\n        start_time = root.findtext(\"startTime\")\n        start_time = datetime.strptime(\n            start_time[:19], \"%Y-%m-%dT%H:%M:%S\")\n        progress = root.findtext(\"progress\")[:-1]\n        progress = float(progress or \"0\") / 100.\n        return model.Snapshot(\n            snapshot_id, volume_id, status, start_time, progress)",
        "hard_negative_ids": [
            461,
            339,
            291,
            269,
            433,
            42,
            363,
            256,
            210,
            34,
            348,
            360,
            78,
            135,
            296,
            342,
            300,
            414,
            237,
            322,
            480,
            178,
            81,
            53,
            219,
            466,
            235,
            500,
            23,
            197,
            369,
            391,
            450,
            109,
            311,
            204,
            333,
            184,
            490,
            142,
            227,
            106,
            136,
            344,
            73,
            304,
            101,
            105,
            472,
            359
        ]
    },
    {
        "query": "This method is used to validate the checkin_date and checkout_date.\n        -------------------------------------------------------------------\n        @param self: object pointer\n        @return: raise warning depending on the validation",
        "positive_code": "def check_dates(self):\n        \n        if self.checkin_date >= self.checkout_date:\n                raise ValidationError(_())\n        if self.folio_id.date_order and self.checkin_date:\n            if self.checkin_date <= self.folio_id.date_order:\n                raise ValidationError(_())",
        "hard_negative_ids": [
            81,
            323,
            414,
            204,
            79,
            47,
            189,
            41,
            360,
            466,
            73,
            136,
            499,
            44,
            488,
            197,
            349,
            70,
            25,
            130,
            139,
            76,
            113,
            291,
            470,
            429,
            345,
            307,
            402,
            275,
            95,
            268,
            297,
            90,
            56,
            109,
            344,
            264,
            300,
            245,
            1,
            292,
            435,
            462,
            361,
            472,
            17,
            46,
            149,
            416
        ]
    },
    {
        "query": "str: the `Term` serialized in an Obo ``[Term]`` stanza.\n\n        Note:\n            The following guide was used:\n            ftp://ftp.geneontology.org/pub/go/www/GO.format.obo-1_4.shtml",
        "positive_code": "def obo(self):\n        \n        def add_tags(stanza_list, tags):\n            for tag in tags:\n                if tag in self.other:\n                    if isinstance(self.other[tag], list):\n                        for attribute in self.other[tag]:\n                            stanza_list.append(\"{}: {}\".format(tag, attribute))\n                    else:\n                        stanza_list.append(\"{}: {}\".format(tag, self.other[tag]))\n\n        \n        \n        \n        \n        \n\n        stanza_list = [\"[Term]\"]\n\n        \n        stanza_list.append(\"id: {}\".format(self.id))\n\n\n        \n        if self.name is not None:\n            stanza_list.append(\"name: {}\".format(self.name))\n        else:\n            stanza_list.append(\"name: \")\n\n        add_tags(stanza_list, [, ])\n\n        \n        if self.desc:\n            stanza_list.append(self.desc.obo)\n\n        \n        add_tags(stanza_list, [, ])\n\n        \n        for synonym in sorted(self.synonyms, key=str):\n            stanza_list.append(synonym.obo)\n\n        add_tags(stanza_list, [])\n\n        \n        if Relationship() in self.relations:\n            for companion in self.relations[Relationship()]:\n                stanza_list.append(\"is_a: {} ! {}\".format(companion.id, companion.name))\n\n        add_tags(stanza_list, [, , ])\n\n        for relation in self.relations:\n            if relation.direction==\"bottomup\" and relation is not Relationship():\n                stanza_list.extend(\n                    \"relationship: {} {} ! {}\".format(\n                        relation.obo_name, companion.id, companion.name\n                    ) for companion in self.relations[relation]\n                )\n\n        add_tags(stanza_list, [, , ,\n                               , , ])\n\n        return \"\\n\".join(stanza_list)",
        "hard_negative_ids": [
            258,
            429,
            207,
            360,
            265,
            500,
            128,
            414,
            73,
            457,
            291,
            361,
            23,
            391,
            159,
            466,
            162,
            222,
            69,
            197,
            177,
            296,
            478,
            388,
            345,
            88,
            95,
            350,
            136,
            189,
            71,
            379,
            340,
            472,
            160,
            427,
            464,
            462,
            44,
            426,
            25,
            317,
            206,
            387,
            435,
            109,
            275,
            382,
            56,
            12
        ]
    },
    {
        "query": "Alias to run with check return code and stderr",
        "positive_code": "def succ(cmd, check_stderr=True, stdout=None, stderr=None):\n    \n    code, out, err = run(cmd)\n\n    \n    if stdout is not None:\n        stdout[:] = out\n    if stderr is not None:\n        stderr[:] = err\n\n    if code != 0:\n        for l in out:\n            print(l)\n    assert code == 0, .format(code, cmd, err)\n    if check_stderr:\n        assert err == [], .format(err, code)\n    return code, out, err",
        "hard_negative_ids": [
            321,
            201,
            185,
            339,
            69,
            181,
            425,
            451,
            173,
            269,
            370,
            300,
            216,
            131,
            138,
            197,
            275,
            295,
            264,
            438,
            322,
            414,
            171,
            307,
            170,
            293,
            9,
            96,
            368,
            179,
            376,
            434,
            74,
            236,
            189,
            277,
            59,
            73,
            439,
            468,
            291,
            397,
            24,
            128,
            289,
            360,
            76,
            466,
            485,
            404
        ]
    },
    {
        "query": "Complete an value of an abstract type by determining the runtime type of that value, then completing based\n    on that type.",
        "positive_code": "def complete_abstract_value(\n    exe_context,  \n    return_type,  \n    field_asts,  \n    info,  \n    path,  \n    result,  \n):\n    \n    \n    runtime_type = None  \n\n    \n    if isinstance(return_type, (GraphQLInterfaceType, GraphQLUnionType)):\n        if return_type.resolve_type:\n            runtime_type = return_type.resolve_type(result, info)\n        else:\n            runtime_type = get_default_resolve_type_fn(result, info, return_type)\n\n    if isinstance(runtime_type, string_types):\n        runtime_type = info.schema.get_type(runtime_type)  \n\n    if not isinstance(runtime_type, GraphQLObjectType):\n        raise GraphQLError(\n            (\n                \"Abstract type {} must resolve to an Object type at runtime \"\n                + \n            ).format(\n                return_type, info.parent_type, info.field_name, result, runtime_type\n            ),\n            field_asts,\n        )\n\n    if not exe_context.schema.is_possible_type(return_type, runtime_type):\n        raise GraphQLError(\n            u.format(\n                runtime_type, return_type\n            ),\n            field_asts,\n        )\n\n    return complete_object_value(\n        exe_context, runtime_type, field_asts, info, path, result\n    )",
        "hard_negative_ids": [
            232,
            360,
            349,
            280,
            291,
            56,
            443,
            332,
            267,
            481,
            199,
            466,
            166,
            197,
            441,
            414,
            366,
            362,
            91,
            73,
            279,
            189,
            11,
            429,
            424,
            222,
            382,
            19,
            242,
            133,
            115,
            499,
            20,
            395,
            239,
            204,
            470,
            411,
            273,
            23,
            226,
            182,
            353,
            117,
            272,
            130,
            303,
            431,
            105,
            113
        ]
    },
    {
        "query": "Parse zoneinfo zone description data files.\n\n        ``import_locations()`` returns a list of :class:`Zone` objects.\n\n        It expects data files in one of the following formats::\n\n            AN\t+1211-06900\tAmerica/Curacao\n            AO\t-0848+01314\tAfrica/Luanda\n            AQ\t-7750+16636\tAntarctica/McMurdo\tMcMurdo Station, Ross Island\n\n        Files containing the data in this format can be found in the\n        :file:`zone.tab` file that is normally found in\n        :file:`/usr/share/zoneinfo` on UNIX-like systems, or from the `standard\n        distribution site`_.\n\n        When processed by ``import_locations()`` a ``list`` object of the\n        following style will be returned::\n\n            [Zone(None, None, \"AN\", \"America/Curacao\", None),\n             Zone(None, None, \"AO\", \"Africa/Luanda\", None),\n             Zone(None, None, \"AO\", \"Antartica/McMurdo\",\n                  [\"McMurdo Station\", \"Ross Island\"])]\n\n        Args:\n            zone_file (iter): ``zone.tab`` data to read\n\n        Returns:\n            list: Locations as :class:`Zone` objects\n\n        Raises:\n            FileFormatError: Unknown file format\n\n        .. _standard distribution site: ftp://elsie.nci.nih.gov/pub/",
        "positive_code": "def import_locations(self, zone_file):\n        \n        self._zone_file = zone_file\n        field_names = (, , , )\n\n        data = utils.prepare_csv_read(zone_file, field_names, delimiter=r\"\t\")\n\n        for row in (x for x in data if not x[].startswith()):\n            if row[]:\n                row[] = row[].split()\n            self.append(Zone(**row))",
        "hard_negative_ids": [
            23,
            466,
            363,
            47,
            291,
            360,
            414,
            232,
            349,
            470,
            429,
            73,
            171,
            79,
            391,
            402,
            424,
            275,
            500,
            297,
            421,
            264,
            405,
            277,
            69,
            179,
            44,
            382,
            237,
            197,
            15,
            207,
            462,
            324,
            159,
            76,
            427,
            189,
            99,
            464,
            285,
            223,
            317,
            383,
            369,
            457,
            154,
            265,
            63,
            162
        ]
    },
    {
        "query": "Update the subscriptions at a node.\n\n        :param jid: Address of the PubSub service.\n        :type jid: :class:`aioxmpp.JID`\n        :param node: Name of the node to modify\n        :type node: :class:`str`\n        :param subscriptions_to_set: The subscriptions to set at the node.\n        :type subscriptions_to_set: :class:`~collections.abc.Iterable` of\n            tuples consisting of the JID to (un)subscribe and the subscription\n            level to use.\n        :raises aioxmpp.errors.XMPPError: as returned by the service\n\n        `subscriptions_to_set` must be an iterable of pairs (`jid`,\n        `subscription`), where the `jid` indicates the JID for which the\n        `subscription` is to be set.",
        "positive_code": "def change_node_subscriptions(self, jid, node, subscriptions_to_set):\n        \n        iq = aioxmpp.stanza.IQ(\n            type_=aioxmpp.structs.IQType.SET,\n            to=jid,\n            payload=pubsub_xso.OwnerRequest(\n                pubsub_xso.OwnerSubscriptions(\n                    node,\n                    subscriptions=[\n                        pubsub_xso.OwnerSubscription(\n                            jid,\n                            subscription\n                        )\n                        for jid, subscription in subscriptions_to_set\n                    ]\n                )\n            )\n        )\n\n        yield from self.client.send(iq)",
        "hard_negative_ids": [
            232,
            470,
            360,
            349,
            414,
            77,
            466,
            291,
            295,
            305,
            174,
            272,
            76,
            197,
            126,
            386,
            429,
            32,
            73,
            81,
            25,
            215,
            379,
            23,
            18,
            266,
            366,
            311,
            113,
            321,
            487,
            26,
            382,
            90,
            109,
            171,
            204,
            146,
            344,
            189,
            318,
            222,
            237,
            412,
            47,
            439,
            345,
            338,
            498,
            44
        ]
    },
    {
        "query": "Perform a query similar to an SQL *group by* operation.\n\n        **DEPRECATED** - The group command was deprecated in MongoDB 3.4. The\n        :meth:`~group` method is deprecated and will be removed in PyMongo 4.0.\n        Use :meth:`~aggregate` with the `$group` stage or :meth:`~map_reduce`\n        instead.\n\n        .. versionchanged:: 3.5\n           Deprecated the group method.\n        .. versionchanged:: 3.4\n           Added the `collation` option.\n        .. versionchanged:: 2.2\n           Removed deprecated argument: command",
        "positive_code": "def group(self, key, condition, initial, reduce, finalize=None, **kwargs):\n        \n        warnings.warn(\"The group method is deprecated and will be removed in \"\n                      \"PyMongo 4.0. Use the aggregate method with the $group \"\n                      \"stage or the map_reduce method instead.\",\n                      DeprecationWarning, stacklevel=2)\n        group = {}\n        if isinstance(key, string_type):\n            group[\"$keyf\"] = Code(key)\n        elif key is not None:\n            group = {\"key\": helpers._fields_list_to_dict(key, \"key\")}\n        group[\"ns\"] = self.__name\n        group[\"$reduce\"] = Code(reduce)\n        group[\"cond\"] = condition\n        group[\"initial\"] = initial\n        if finalize is not None:\n            group[\"finalize\"] = Code(finalize)\n\n        cmd = SON([(\"group\", group)])\n        collation = validate_collation_or_none(kwargs.pop(, None))\n        cmd.update(kwargs)\n\n        with self._socket_for_reads(session=None) as (sock_info, slave_ok):\n            return self._command(sock_info, cmd, slave_ok,\n                                 collation=collation,\n                                 user_fields={: 1})[\"retval\"]",
        "hard_negative_ids": [
            360,
            291,
            414,
            182,
            41,
            412,
            77,
            444,
            244,
            240,
            323,
            130,
            216,
            198,
            129,
            101,
            48,
            73,
            36,
            179,
            438,
            139,
            149,
            70,
            466,
            166,
            23,
            385,
            294,
            140,
            95,
            44,
            243,
            178,
            111,
            122,
            269,
            154,
            391,
            197,
            64,
            425,
            234,
            394,
            29,
            175,
            296,
            402,
            434,
            236
        ]
    },
    {
        "query": "Execute the code once to get it's results (to be used in function validation). Compare the result to the\n        first function in the group.",
        "positive_code": "def validate(self):\n        \n        validation_code = self.setup_src +  + self.stmt\n        validation_scope = {}\n        exec(validation_code, validation_scope)\n        \n        if len(self.groups[self.group]) == 1:\n            self.result = validation_scope[]\n            logging.info(\n                         .format(b=self))\n        else:\n            compare_against_benchmark = self.groups[self.group][0]\n            test = [benchmark.result_validation for benchmark in self.groups[self.group]]\n            if not all(test):\n                raise ValueError()\n            compare_result = compare_against_benchmark.result\n            if self.validation_func:\n                results_are_valid = self.validation_func(compare_result, validation_scope[])\n            else:\n                results_are_valid = compare_result == validation_scope[]\n            if results_are_valid:\n                logging.info(.format(self.callable.__name__))\n            else:\n                error = \n                raise ValidationError(error.format(compare_against_benchmark.callable.__name__, self.callable.__name__,\n                                          compare_result, validation_scope[]))",
        "hard_negative_ids": [
            42,
            360,
            452,
            438,
            223,
            414,
            73,
            235,
            386,
            339,
            151,
            201,
            197,
            291,
            329,
            378,
            412,
            69,
            32,
            375,
            466,
            226,
            285,
            129,
            363,
            142,
            264,
            311,
            2,
            109,
            450,
            23,
            326,
            469,
            403,
            417,
            199,
            295,
            140,
            232,
            136,
            421,
            44,
            149,
            101,
            368,
            275,
            382,
            443,
            171
        ]
    },
    {
        "query": "Returns the switch with the provided ``name``.\n\n        If ``autocreate`` is set to ``True`` and no switch with that name\n        exists, a ``DISABLED`` switch will be with that name.\n\n        Keyword Arguments:\n        name -- A name of a switch.",
        "positive_code": "def switch(self, name):\n        \n        try:\n            switch = self.storage[self.__namespaced(name)]\n        except KeyError:\n            if not self.autocreate:\n                raise ValueError(\"No switch named  registered in \" % (name, self.namespace))\n\n            switch = self.__create_and_register_disabled_switch(name)\n\n        switch.manager = self\n        return switch",
        "hard_negative_ids": [
            360,
            498,
            391,
            466,
            291,
            109,
            197,
            176,
            203,
            390,
            269,
            470,
            414,
            386,
            349,
            170,
            232,
            429,
            201,
            76,
            66,
            304,
            171,
            106,
            412,
            65,
            25,
            462,
            179,
            38,
            23,
            382,
            150,
            272,
            184,
            73,
            44,
            454,
            97,
            275,
            131,
            324,
            425,
            453,
            366,
            178,
            439,
            239,
            91,
            317
        ]
    },
    {
        "query": "Returns a list of the indices for the CPU registers.\n\n        The returned indices can be used to read the register content or grab\n        the register name.\n\n        Args:\n          self (JLink): the ``JLink`` instance\n\n        Returns:\n          List of registers.",
        "positive_code": "def register_list(self):\n        \n        num_items = self.MAX_NUM_CPU_REGISTERS\n        buf = (ctypes.c_uint32 * num_items)()\n        num_regs = self._dll.JLINKARM_GetRegisterList(buf, num_items)\n        return buf[:num_regs]",
        "hard_negative_ids": [
            269,
            297,
            219,
            466,
            360,
            62,
            273,
            197,
            79,
            291,
            232,
            470,
            414,
            255,
            429,
            493,
            275,
            73,
            23,
            498,
            287,
            349,
            488,
            449,
            112,
            272,
            41,
            136,
            386,
            179,
            391,
            415,
            324,
            347,
            182,
            176,
            233,
            159,
            147,
            97,
            326,
            171,
            315,
            333,
            76,
            395,
            462,
            459,
            385,
            254
        ]
    },
    {
        "query": "Build an instance of TokenInstance\n\n        :param dict payload: Payload response from the API\n\n        :returns: twilio.rest.api.v2010.account.token.TokenInstance\n        :rtype: twilio.rest.api.v2010.account.token.TokenInstance",
        "positive_code": "def get_instance(self, payload):\n        \n        return TokenInstance(self._version, payload, account_sid=self._solution[], )",
        "hard_negative_ids": [
            70,
            395,
            189,
            407,
            191,
            323,
            429,
            203,
            167,
            185,
            269,
            349,
            207,
            427,
            265,
            360,
            105,
            81,
            219,
            76,
            463,
            73,
            466,
            198,
            197,
            112,
            2,
            369,
            322,
            414,
            204,
            333,
            174,
            23,
            52,
            300,
            344,
            243,
            339,
            178,
            193,
            291,
            470,
            7,
            232,
            489,
            26,
            425,
            367,
            131
        ]
    },
    {
        "query": "Return the named spec.",
        "positive_code": "def _spec(self, name):\n        \"Return the named spec.\"\n        for s in self._framespec:\n            if s.name == name:\n                return s\n        raise ValueError(\"Unknown spec: \" + name)",
        "hard_negative_ids": [
            390,
            360,
            197,
            414,
            291,
            466,
            136,
            73,
            429,
            44,
            23,
            25,
            109,
            176,
            150,
            380,
            328,
            460,
            485,
            498,
            487,
            478,
            435,
            481,
            94,
            441,
            21,
            134,
            386,
            5,
            250,
            193,
            454,
            226,
            112,
            86,
            128,
            210,
            42,
            3,
            56,
            433,
            141,
            425,
            55,
            304,
            118,
            424,
            453,
            48
        ]
    },
    {
        "query": "Revoke a specified permission from a user.\n\n    Permissions are only revoked if they are in the scope any of the user's\n    roles. If the permission is out of scope, a RolePermissionScopeException\n    is raised.",
        "positive_code": "def revoke_permission(user, permission_name):\n    \n    roles = get_user_roles(user)\n\n    for role in roles:\n        if permission_name in role.permission_names_list():\n            permission = get_permission(permission_name)\n            user.user_permissions.remove(permission)\n            return\n\n    raise RolePermissionScopeException(\n        \"This permission isns roles.\")",
        "hard_negative_ids": [
            466,
            360,
            425,
            291,
            197,
            131,
            429,
            352,
            293,
            187,
            73,
            318,
            55,
            269,
            136,
            349,
            304,
            470,
            414,
            499,
            435,
            106,
            15,
            103,
            404,
            391,
            178,
            69,
            415,
            201,
            173,
            25,
            23,
            424,
            232,
            453,
            163,
            317,
            171,
            174,
            395,
            157,
            462,
            44,
            386,
            272,
            382,
            99,
            222,
            228
        ]
    },
    {
        "query": "Fix whitespace around hyphens and commas. Can be used to remove whitespace tokenization artefacts.",
        "positive_code": "def fix_whitespace(tokens, start, result):\n    \n    for e in result:\n        for child in e.iter():\n            child.text = child.text.replace(, )\n            for hyphen in HYPHENS:\n                child.text = child.text.replace( % hyphen,  % hyphen)\n            child.text = re.sub(r, r, child.text)\n    return result",
        "hard_negative_ids": [
            255,
            69,
            500,
            332,
            254,
            232,
            97,
            386,
            74,
            38,
            315,
            96,
            131,
            462,
            295,
            374,
            470,
            382,
            171,
            291,
            192,
            269,
            275,
            368,
            376,
            414,
            264,
            189,
            73,
            109,
            24,
            182,
            76,
            360,
            485,
            183,
            180,
            47,
            345,
            184,
            46,
            219,
            257,
            34,
            477,
            266,
            94,
            118,
            201,
            21
        ]
    },
    {
        "query": "If an arc_element is modified and it's characters/locations are not already in the story node, add them.\n    We don't assume that removing the arc element would change the characters or locations as of yet.\n    This takes up a little more space in the database, but the additional flexibility for users is\n    worth it.",
        "positive_code": "def arc_node_edit_add_missing_characters_and_locations_to_related_story_node(\n        sender,\n        instance,\n        action,\n        reverse,\n        pk_set,\n        *args,\n        **kwargs\n):\n    s characters/locations are not already in the story node, add them.\n    We don\n    if action == :\n        logger.debug(\"Updating nodes after character or location change.\")\n        if reverse:\n            logger.debug(\"Searching backwards from character or location to arc node\")\n            \n            for arcnode in instance.arcelementnode_set.all().select_related():\n                logger.debug(\"Scanning arc node...\")\n                if arcnode.story_element_node:\n                    logger.debug(\"Found story node to update...\")\n                    story_node = arcnode.story_element_node\n                    if isinstance(instance, CharacterInstance):\n                        logger.debug(\"Updating characters...\")\n                        story_node.assoc_characters.add(instance)\n                    if isinstance(instance, LocationInstance):\n                        logger.debug(\"updating locations...\")\n                        story_node.assoc_locations.add(instance)\n        else:\n            \n            logger.debug()\n            if instance.story_element_node:\n                logger.debug(\"found story node to update...\")\n                story_node = instance.story_element_node\n                if sender == ArcElementNode.assoc_characters.through:\n                    logger.debug()\n                    story_node.assoc_characters.add(*pk_set)\n                if sender == ArcElementNode.assoc_locations.through:\n                    logger.debug()\n                    story_node.assoc_locations.add(*pk_set)",
        "hard_negative_ids": [
            360,
            69,
            268,
            429,
            215,
            291,
            440,
            477,
            174,
            414,
            349,
            466,
            280,
            197,
            73,
            433,
            103,
            461,
            272,
            425,
            305,
            462,
            178,
            136,
            348,
            311,
            131,
            237,
            391,
            328,
            189,
            453,
            366,
            375,
            18,
            23,
            126,
            90,
            304,
            179,
            1,
            109,
            15,
            89,
            25,
            161,
            199,
            499,
            106,
            277
        ]
    },
    {
        "query": "parse is the base function for parsing the Dockerfile, and extracting\n           elements into the correct data structures. Everything is parsed into\n           lists or dictionaries that can be assembled again on demand. \n\n           Environment: Since Docker also exports environment as we go, \n                        we add environment to the environment section and \n                        install\n\n           Labels: include anything that is a LABEL, ARG, or (deprecated)\n                   maintainer.\n\n           Add/Copy: are treated the same",
        "positive_code": "def _parse(self):\n        \n        parser = None\n        previous = None\n\n        for line in self.lines:\n\n            parser = self._get_mapping(line, parser, previous)\n\n            \n            if parser:\n                parser(line)\n\n            previous = line",
        "hard_negative_ids": [
            360,
            178,
            130,
            291,
            73,
            414,
            23,
            466,
            467,
            215,
            42,
            429,
            184,
            382,
            60,
            451,
            499,
            453,
            277,
            109,
            40,
            136,
            255,
            12,
            235,
            391,
            424,
            244,
            197,
            435,
            462,
            421,
            433,
            480,
            100,
            166,
            461,
            379,
            426,
            171,
            256,
            97,
            128,
            425,
            25,
            254,
            304,
            76,
            283,
            47
        ]
    },
    {
        "query": "Append `context` to model\n\n        Arguments:\n            context (dict): Serialised to add\n\n        Schema:\n            context.json",
        "positive_code": "def add_context(self, context, label=None):\n        \n\n        assert isinstance(context, dict)\n\n        item = defaults[\"common\"].copy()\n        item.update(defaults[\"instance\"])\n        item.update(context)\n\n        item[\"family\"] = None\n        item[\"label\"] = context[\"data\"].get(\"label\") or settings.ContextLabel\n        item[\"itemType\"] = \"instance\"\n        item[\"isToggled\"] = True\n        item[\"optional\"] = False\n        item[\"hasCompatible\"] = True\n\n        item = self.add_item(item)\n        self.instances.append(item)",
        "hard_negative_ids": [
            423,
            244,
            269,
            484,
            129,
            489,
            330,
            428,
            89,
            390,
            333,
            2,
            198,
            266,
            383,
            215,
            265,
            376,
            153,
            273,
            127,
            203,
            434,
            467,
            152,
            453,
            414,
            171,
            178,
            131,
            289,
            368,
            443,
            377,
            295,
            275,
            264,
            189,
            73,
            272,
            52,
            360,
            413,
            463,
            207,
            382,
            342,
            47,
            188,
            345
        ]
    },
    {
        "query": "Function for batch usage of already trained and tested MLP.\n\n        **Args:**\n\n        * `x` : input array (2-dimensional array).\n            Every row represents one input vector (features).\n\n        **Returns:**\n        \n        * `y`: output vector (n-dimensional array). Every row represents\n            output (outputs) for an input vector.",
        "positive_code": "def run(self, x):\n        \n        \n        try:    \n            x = np.array(x)\n        except:\n            raise ValueError()\n        N = len(x)   \n        \n        if self.outputs == 1:\n            y = np.zeros(N)\n        else:\n            y = np.zeros((N, self.outputs))\n        \n        for k in range(N):\n            y[k] = self.predict(x[k])\n        return y",
        "hard_negative_ids": [
            240,
            496,
            212,
            142,
            3,
            88,
            287,
            488,
            198,
            156,
            41,
            263,
            252,
            296,
            185,
            245,
            429,
            42,
            269,
            227,
            112,
            495,
            385,
            321,
            9,
            53,
            464,
            376,
            199,
            316,
            324,
            136,
            232,
            295,
            318,
            328,
            149,
            462,
            67,
            219,
            466,
            290,
            16,
            34,
            229,
            235,
            12,
            424,
            160,
            472
        ]
    },
    {
        "query": "Return a boolean indicating if the experiment has any running jobs",
        "positive_code": "def has_running_jobs(self) -> bool:\n        \n        return self.jobs.exclude(status__status__in=ExperimentLifeCycle.DONE_STATUS).exists()",
        "hard_negative_ids": [
            13,
            466,
            404,
            136,
            360,
            25,
            201,
            269,
            174,
            106,
            304,
            391,
            268,
            197,
            414,
            291,
            453,
            178,
            425,
            317,
            73,
            15,
            171,
            23,
            429,
            44,
            470,
            382,
            256,
            157,
            462,
            222,
            12,
            349,
            76,
            472,
            109,
            180,
            272,
            421,
            498,
            380,
            441,
            176,
            454,
            423,
            150,
            481,
            128,
            94
        ]
    },
    {
        "query": "Transforms a given ``bundle`` into a *sorted* list of tuples with materialized value paths and values:\n    ``('path.to.value', <value>)``. Output is ordered by depth: the deepest element first.\n\n    :param bundle: a dict to materialize\n    :param separator: build paths with a given separator\n    :return: a depth descending and alphabetically ascending sorted list (-deep, asc), the longest first\n\n    ::\n\n        sample = {\n            'a': 1,\n            'aa': 1,\n            'b': {\n                'c': 1,\n                'b': 1,\n                'a': 1,\n                'aa': 1,\n                'aaa': {\n                    'a': 1\n                }\n            }\n        }\n        materialize_dict(sample, '/')\n        [\n            ('b/aaa/a', 1),\n            ('b/a', 1),\n            ('b/aa', 1),\n            ('b/b', 1),\n            ('b/c', 1),\n            ('a', 1),\n            ('aa', 1)\n        ]",
        "positive_code": "def materialize_dict(bundle: dict, separator: str = ) -> t.List[t.Tuple[str, t.Any]]:\n    \n\n    def _matkeysort(tup: t.Tuple[str, t.Any]):\n        return len(tup[0].split(separator))\n\n    s1 = sorted(_materialize_dict(bundle, separator=separator), key=lambda x: x[0])\n    return sorted(s1, key=_matkeysort, reverse=True)",
        "hard_negative_ids": [
            391,
            106,
            60,
            149,
            15,
            218,
            48,
            332,
            429,
            261,
            296,
            349,
            256,
            382,
            291,
            81,
            58,
            56,
            491,
            360,
            159,
            466,
            500,
            73,
            210,
            23,
            267,
            433,
            457,
            170,
            222,
            265,
            178,
            162,
            2,
            252,
            227,
            207,
            317,
            304,
            414,
            171,
            254,
            461,
            361,
            197,
            136,
            453,
            76,
            34
        ]
    },
    {
        "query": "Pack object `o` and write it to `stream`\n\n    See :class:`Packer` for options.",
        "positive_code": "def pack(o, stream, **kwargs):\n    \n    packer = Packer(**kwargs)\n    stream.write(packer.pack(o))",
        "hard_negative_ids": [
            130,
            79,
            76,
            407,
            269,
            297,
            149,
            300,
            385,
            368,
            182,
            432,
            179,
            303,
            109,
            64,
            470,
            260,
            62,
            170,
            1,
            69,
            113,
            275,
            173,
            78,
            81,
            131,
            277,
            375,
            58,
            181,
            258,
            295,
            99,
            91,
            171,
            9,
            189,
            414,
            272,
            365,
            376,
            74,
            264,
            73,
            163,
            24,
            477,
            360
        ]
    },
    {
        "query": "Create directories in the indicated path.\n    :param path:\n    :param mode:\n    :param exists_ok:\n    :return:",
        "positive_code": "def createpath(path, mode, exists_ok=True):\n    \n    try:\n        os.makedirs(path, mode)\n    except OSError, e:\n        if e.errno != errno.EEXIST or not exists_ok:\n            raise e",
        "hard_negative_ids": [
            38,
            170,
            81,
            325,
            368,
            204,
            456,
            344,
            459,
            246,
            300,
            363,
            254,
            44,
            380,
            414,
            39,
            144,
            245,
            458,
            333,
            193,
            436,
            234,
            457,
            31,
            394,
            163,
            360,
            275,
            194,
            261,
            109,
            291,
            197,
            150,
            169,
            466,
            34,
            71,
            496,
            311,
            68,
            136,
            138,
            243,
            73,
            23,
            98,
            74
        ]
    },
    {
        "query": "Extract the string used to specify the model type of this model object in\n    `pylogit.create_chohice_model`.\n\n    Parameters\n    ----------\n    model_obj : An MNDC_Model instance.\n\n    Returns\n    -------\n    str. The internal abbreviation used for the particular type of MNDC_Model.",
        "positive_code": "def get_model_abbrev(model_obj):\n    \n    \n    model_type = model_obj.model_type\n    \n    for key in model_type_to_display_name:\n        if model_type_to_display_name[key] == model_type:\n            return key\n    \n    \n    msg = \"Model object has an unknown or incorrect model type.\"\n    raise ValueError(msg)",
        "hard_negative_ids": [
            333,
            414,
            210,
            73,
            232,
            89,
            489,
            466,
            360,
            269,
            273,
            413,
            79,
            40,
            198,
            189,
            197,
            342,
            470,
            429,
            353,
            23,
            349,
            113,
            295,
            279,
            152,
            76,
            219,
            291,
            467,
            393,
            297,
            17,
            379,
            133,
            34,
            157,
            280,
            136,
            435,
            345,
            25,
            395,
            222,
            275,
            115,
            47,
            411,
            20
        ]
    },
    {
        "query": "A helper method that does the actual sending.",
        "positive_code": "def _send(self, messages):\n        \n        if len(messages) == 1:\n            to_send = self._build_message(messages[0])\n            if to_send is False:\n                \n                \n                return False\n        else:\n            pm_messages = list(map(self._build_message, messages))\n            pm_messages = [m for m in pm_messages if m]\n            if len(pm_messages) == 0:\n                \n                \n                return False\n            to_send = PMBatchMail(messages=pm_messages)\n        try:\n            to_send.send(test=self.test_mode)\n        except:\n            if self.fail_silently:\n                return False\n            raise\n        return True",
        "hard_negative_ids": [
            213,
            360,
            323,
            41,
            70,
            136,
            139,
            402,
            44,
            106,
            304,
            466,
            391,
            197,
            414,
            291,
            453,
            178,
            317,
            425,
            73,
            171,
            434,
            15,
            23,
            429,
            470,
            230,
            87,
            256,
            382,
            25,
            462,
            329,
            222,
            349,
            472,
            76,
            109,
            180,
            272,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471
        ]
    },
    {
        "query": "interface with vrtsexplorer to capture veritas related data",
        "positive_code": "def setup(self):\n        \n        r = self.call_ext_prog(self.get_option(\"script\"))\n        if r[] == 0:\n            tarfile = \"\"\n            for line in r[]:\n                line = line.strip()\n                tarfile = self.do_regex_find_all(r\"ftp (.*tar.gz)\", line)\n            if len(tarfile) == 1:\n                self.add_copy_spec(tarfile[0])",
        "hard_negative_ids": [
            498,
            315,
            421,
            223,
            269,
            33,
            195,
            357,
            85,
            424,
            154,
            440,
            163,
            227,
            283,
            492,
            484,
            393,
            78,
            324,
            264,
            252,
            414,
            171,
            170,
            256,
            466,
            22,
            141,
            275,
            131,
            96,
            368,
            376,
            434,
            74,
            295,
            189,
            59,
            73,
            439,
            468,
            397,
            383,
            128,
            285,
            360,
            404,
            47,
            461
        ]
    },
    {
        "query": "Returns True if you have vision on a grid point.",
        "positive_code": "def is_visible(self, pos: Union[Point2, Point3, Unit]) -> bool:\n        \n        \n        assert isinstance(pos, (Point2, Point3, Unit))\n        pos = pos.position.to2.rounded\n        return self.state.visibility[pos] == 2",
        "hard_negative_ids": [
            156,
            189,
            360,
            499,
            269,
            466,
            136,
            204,
            106,
            304,
            391,
            130,
            453,
            178,
            47,
            425,
            317,
            183,
            15,
            171,
            470,
            382,
            256,
            462,
            222,
            349,
            421,
            351,
            491,
            468,
            485,
            326,
            295,
            281,
            164,
            76,
            472,
            229,
            345,
            380,
            343,
            122,
            221,
            36,
            370,
            239,
            44,
            306,
            327,
            119
        ]
    },
    {
        "query": "Sparse multihead self attention.\n\n  Perform an approximation of the full multihead attention by dispatching\n  the tokens using their keys/values. Thus the attention matrix are only\n  computed each times on a subset of the tokens.\n\n  Notes:\n   * The function don't perform scaling here (multihead_attention does\n  the /sqrt(depth)).\n   * The padding should have been removed (so batch size should be 1 but length\n   contains the elements from all different batches)\n   * Right now, only self attention is supported so length_q and length_kv\n   should be identical and the function will add triangular mask.\n   * If bi.order is not None, The bias is added inside this function to\n   prevent attention to the future.\n\n  Args:\n    q (tf.Tensor): Queries of shape [batch, heads, length_q, depth_k]\n    k (tf.Tensor): Keys of shape [batch, heads, length_q, depth_k]\n    v (tf.Tensor): Values of shape [batch, heads, length_kv, depth_v]\n    bi (BatchInfo): Contains the batch coordinates and sequence order\n    experts_params (dict): Additional params for the local expert\n    use_map_fn (bool): Use either tf.map_fn of python for loop to compute the\n      heads separately\n    mask_right (bool):\n  Returns:\n    tf.Tensor: Approximation of Softmax(Q.K) * V, of shape\n      [batch, heads, length_q, depth_v]",
        "positive_code": "def sparse_dot_product_attention_truncated(\n    q,\n    k,\n    v,\n    bi,  \n    experts_params,\n    use_map_fn=False,  \n    mask_right=False,\n):  \n  \n  \n  batch_size, nb_heads, _, depth = common_layers.shape_list(q)\n\n  total_loss = 0.0\n\n  \n  list_lsh = [LshGating(depth=depth, **experts_params) for _ in range(nb_heads)]\n\n  @expert_utils.add_name_scope()\n  def get_gates_head(x, add_first=False):\n    \n    length = common_layers.shape_list(x)[2]\n\n    \n    x = tf.transpose(x, perm=[1, 0, 2, 3])\n    x = tf.reshape(x, [nb_heads, batch_size * length, depth])\n\n    list_x = tf.unstack(x)  \n\n    \n    list_gates = []\n    \n    for lsh, single_x in zip(list_lsh, list_x):\n      \n      gates = lsh.get_gates(single_x)\n      nb_buckets = gates.get_shape().as_list()[-1]\n      \n      \n      gates = tf.reshape(gates, [batch_size, length, nb_buckets])\n      list_gates.append(gates)\n\n    gates = tf.stack(list_gates)\n\n    \n    gates = tf.reshape(gates, [nb_heads, batch_size, length, nb_buckets])\n    gates = tf.transpose(gates, [1, 0, 2, 3])\n\n    \n    if add_first:\n      gates = tf.maximum(gates,\n                         tf.reshape(tf.one_hot([0], length), [1, 1, length, 1]))\n\n    return gates\n\n  gates_q = get_gates_head(q)\n  gates_k = get_gates_head(k, add_first=True)\n\n  \n  q, k, v, gates_q, gates_k = [\n      combine_first_two_dimensions(t) for t in (q, k, v, gates_q, gates_k)\n  ]\n\n  v_out = dot_product_batched_head(q, k, v, gates_q, gates_k, mask_right)\n\n  \n  v_out = tf.reshape(v_out, [batch_size, nb_heads, -1, depth])\n\n  return v_out, total_loss / nb_heads",
        "hard_negative_ids": [
            291,
            360,
            287,
            272,
            391,
            189,
            349,
            166,
            47,
            192,
            466,
            23,
            462,
            269,
            190,
            429,
            232,
            179,
            414,
            12,
            94,
            69,
            142,
            411,
            395,
            230,
            202,
            201,
            332,
            42,
            46,
            318,
            382,
            73,
            240,
            160,
            90,
            499,
            197,
            343,
            280,
            171,
            317,
            377,
            107,
            299,
            112,
            348,
            15,
            88
        ]
    },
    {
        "query": "create instance and add it to existing replcia\n        Args:\n            repl_id - replica set identity\n            params - member params\n\n        return True if operation success otherwise False",
        "positive_code": "def member_add(self, repl_id, params):\n        \n        repl = self[repl_id]\n        member_id = repl.repl_member_add(params)\n        self[repl_id] = repl\n        return member_id",
        "hard_negative_ids": [
            269,
            219,
            483,
            402,
            70,
            432,
            325,
            230,
            395,
            433,
            41,
            287,
            459,
            29,
            488,
            179,
            333,
            170,
            324,
            329,
            69,
            289,
            215,
            300,
            226,
            109,
            147,
            316,
            112,
            39,
            385,
            272,
            275,
            485,
            25,
            295,
            99,
            149,
            345,
            453,
            127,
            487,
            159,
            97,
            11,
            131,
            375,
            239,
            184,
            490
        ]
    },
    {
        "query": "Fetch a page of results.\n\n    This is the asynchronous version of Query.fetch_page().",
        "positive_code": "def fetch_page_async(self, page_size, **q_options):\n    \n    qry = self._fix_namespace()\n    return qry._fetch_page_async(page_size, **q_options)",
        "hard_negative_ids": [
            360,
            395,
            193,
            306,
            466,
            243,
            482,
            273,
            73,
            197,
            349,
            470,
            32,
            429,
            47,
            414,
            136,
            232,
            151,
            438,
            304,
            452,
            223,
            106,
            201,
            493,
            178,
            277,
            157,
            386,
            391,
            222,
            189,
            147,
            90,
            425,
            318,
            291,
            453,
            171,
            137,
            226,
            317,
            363,
            15,
            272,
            2,
            23,
            329,
            1
        ]
    },
    {
        "query": "Find schema nodes under `stmt`, also in used groupings.\n\n        `names` is a list with qualified names of the schema nodes to\n        look up. All 'uses'/'grouping' pairs between `stmt` and found\n        schema nodes are marked for expansion.",
        "positive_code": "def lookup_expand(self, stmt, names):\n        \n        if not names: return []\n        todo = [stmt]\n        while todo:\n            pst = todo.pop()\n            for sub in pst.substmts:\n                if sub.keyword in self.schema_nodes:\n                    qname = self.qname(sub)\n                    if qname in names:\n                        names.remove(qname)\n                        par = sub.parent\n                        while hasattr(par,\"d_ref\"): \n                            par.d_ref.d_expand = True\n                            par = par.d_ref.parent\n                        if not names: return [] \n                elif sub.keyword == \"uses\":\n                    g = sub.i_grouping\n                    g.d_ref = sub\n                    todo.append(g)\n        return names",
        "hard_negative_ids": [
            484,
            216,
            35,
            388,
            215,
            429,
            445,
            266,
            305,
            321,
            466,
            274,
            291,
            109,
            360,
            349,
            174,
            464,
            18,
            391,
            347,
            126,
            197,
            76,
            424,
            366,
            311,
            272,
            498,
            23,
            25,
            235,
            414,
            379,
            393,
            171,
            295,
            500,
            136,
            47,
            142,
            499,
            318,
            304,
            201,
            470,
            176,
            317,
            73,
            86
        ]
    },
    {
        "query": "Returns the canonical key for the given ``key``.",
        "positive_code": "def canonical_key(self, key):\n        \n        if key.startswith():\n            return urlparse.urljoin(self.base_uri, key)\n        else:\n            return self.curies.expand(key)",
        "hard_negative_ids": [
            196,
            45,
            476,
            73,
            387,
            442,
            48,
            360,
            414,
            113,
            197,
            436,
            291,
            11,
            15,
            466,
            136,
            105,
            124,
            179,
            222,
            345,
            429,
            44,
            384,
            96,
            23,
            64,
            99,
            25,
            382,
            36,
            490,
            230,
            353,
            327,
            76,
            109,
            135,
            489,
            321,
            35,
            363,
            234,
            223,
            377,
            142,
            247,
            29,
            317
        ]
    },
    {
        "query": "Save the local scope before entering a function call by saving all the LHS's of assignments so far.\n\n        Args:\n            line_number(int): Of the def of the function call about to be entered into.\n            saved_function_call_index(int): Unique number for each call.\n\n        Returns:\n            saved_variables(list[SavedVariable])\n            first_node(EntryOrExitNode or None or RestoreNode): Used to connect previous statements to this function.",
        "positive_code": "def save_local_scope(\n        self,\n        line_number,\n        saved_function_call_index\n    ):\n        \n        saved_variables = list()\n        saved_variables_so_far = set()\n        first_node = None\n\n        \n        for assignment in [node for node in self.nodes\n                           if (type(node) == AssignmentNode or\n                               type(node) == AssignmentCallNode or\n                               type(Node) == BBorBInode)]:  \n            if assignment.left_hand_side in saved_variables_so_far:\n                continue\n            saved_variables_so_far.add(assignment.left_hand_side)\n            save_name = .format(saved_function_call_index, assignment.left_hand_side)\n\n            previous_node = self.nodes[-1]\n\n            saved_scope_node = RestoreNode(\n                save_name +  + assignment.left_hand_side,\n                save_name,\n                [assignment.left_hand_side],\n                line_number=line_number,\n                path=self.filenames[-1]\n            )\n            if not first_node:\n                first_node = saved_scope_node\n\n            self.nodes.append(saved_scope_node)\n            \n            saved_variables.append(SavedVariable(LHS=save_name,\n                                                 RHS=assignment.left_hand_side))\n            self.connect_if_allowed(previous_node, saved_scope_node)\n\n        return (saved_variables, first_node)",
        "hard_negative_ids": [
            142,
            287,
            42,
            16,
            291,
            386,
            466,
            235,
            360,
            197,
            414,
            329,
            171,
            232,
            470,
            23,
            73,
            472,
            147,
            269,
            462,
            252,
            47,
            41,
            76,
            349,
            50,
            207,
            295,
            429,
            112,
            172,
            352,
            189,
            488,
            275,
            333,
            179,
            136,
            452,
            90,
            467,
            425,
            219,
            77,
            264,
            25,
            395,
            391,
            159
        ]
    },
    {
        "query": "read([size]) -> read at most size bytes, returned as a string.\n\n        If the size argument is negative or omitted, read until EOF is reached.\n        Notice that when in non-blocking mode, less data than what was\n        requested may be returned, even if no size parameter was given.",
        "positive_code": "def read(self, size=-1):\n        \n        if self.left is not None:\n            size = min(size, self.left)\n        if self.closed:\n            raise ValueError()\n        if size < 0:\n            return .join(self)\n        elif not size:\n            chunk = \n        elif self.buf:\n            chunk = self.buf\n            self.buf = None\n        else:\n            try:\n                chunk = next(self.iterator)\n            except StopIteration:\n                return \n        if len(chunk) > size:\n            self.buf = chunk[size:]\n            chunk = chunk[:size]\n        if self.left is not None:\n            self.left -= len(chunk)\n        return chunk",
        "hard_negative_ids": [
            73,
            342,
            179,
            210,
            163,
            327,
            360,
            413,
            449,
            40,
            291,
            349,
            368,
            414,
            38,
            326,
            245,
            324,
            197,
            421,
            471,
            356,
            459,
            275,
            391,
            448,
            203,
            256,
            304,
            462,
            466,
            109,
            425,
            496,
            382,
            232,
            223,
            106,
            206,
            470,
            141,
            365,
            295,
            393,
            283,
            429,
            498,
            154,
            479,
            23
        ]
    },
    {
        "query": "Differentiate a B-spline once, and return the resulting coefficients and Bspline objects.\n\nThis preserves the Bspline object nature of the data, enabling recursive implementation\nof higher-order differentiation (see `diff`).\n\nThe value of the first derivative of `B` at a point `x` can be obtained as::\n\n    def diff1(B, x):\n        terms = B.__diff_internal()\n        return sum( ci*Bi(x) for ci,Bi in terms )\n\nReturns:\n    tuple of tuples, where each item is (coefficient, Bspline object).\n\nSee:\n    `diff`: differentiation of any order >= 0",
        "positive_code": "def __diff_internal(self):\n        \n        assert self.p > 0, \"order of Bspline must be > 0\"  \n\n        \n        \n        t    = self.knot_vector\n        p    = self.p\n        Bi   = Bspline( t[:-1], p-1 )\n        Bip1 = Bspline( t[1:],  p-1 )\n\n        numer1 = +p\n        numer2 = -p\n        denom1 = t[p:-1]   - t[:-(p+1)]\n        denom2 = t[(p+1):] - t[1:-p]\n\n        with np.errstate(divide=, invalid=):\n            ci   = np.where(denom1 != 0., (numer1 / denom1), 0.)\n            cip1 = np.where(denom2 != 0., (numer2 / denom2), 0.)\n\n        return ( (ci,Bi), (cip1,Bip1) )",
        "hard_negative_ids": [
            106,
            349,
            391,
            470,
            267,
            79,
            60,
            15,
            23,
            466,
            85,
            287,
            232,
            240,
            58,
            149,
            429,
            197,
            48,
            414,
            25,
            90,
            256,
            360,
            222,
            487,
            78,
            3,
            291,
            462,
            382,
            192,
            263,
            424,
            255,
            404,
            324,
            56,
            297,
            245,
            46,
            285,
            269,
            421,
            304,
            44,
            318,
            254,
            290,
            76
        ]
    },
    {
        "query": "Add a method to this object\n\n        interface: D-Bus interface to add this to. For convenience you can\n                   specify '' here to add the method to the object's main\n                   interface (as specified on construction).\n        name: Name of the method\n        in_sig: Signature of input arguments; for example \"ias\" for a method\n                that takes an int32 and a string array as arguments; see\n                http://dbus.freedesktop.org/doc/dbus-specification.html#message-protocol-signatures\n        out_sig: Signature of output arguments; for example \"s\" for a method\n                 that returns a string; use '' for methods that do not return\n                 anything.\n        code: Python 3 code to run in the method call; you have access to the\n              arguments through the \"args\" list, and can set the return value\n              by assigning a value to the \"ret\" variable. You can also read the\n              global \"objects\" variable, which is a dictionary mapping object\n              paths to DBusMockObject instances.\n\n              For keeping state across method calls, you are free to use normal\n              Python members of the \"self\" object, which will be persistent for\n              the whole mock's life time. E. g. you can have a method with\n              \"self.my_state = True\", and another method that returns it with\n              \"ret = self.my_state\".\n\n              When specifying '', the method will not do anything (except\n              logging) and return None.",
        "positive_code": "def AddMethod(self, interface, name, in_sig, out_sig, code):\n        s main\n                   interface (as specified on construction).\n        name: Name of the method\n        in_sig: Signature of input arguments; for example \"ias\" for a method\n                that takes an int32 and a string array as arguments; see\n                http://dbus.freedesktop.org/doc/dbus-specification.html\n        out_sig: Signature of output arguments; for example \"s\" for a method\n                 that returns a string; use  for methods that do not return\n                 anything.\n        code: Python 3 code to run in the method call; you have access to the\n              arguments through the \"args\" list, and can set the return value\n              by assigning a value to the \"ret\" variable. You can also read the\n              global \"objects\" variable, which is a dictionary mapping object\n              paths to DBusMockObject instances.\n\n              For keeping state across method calls, you are free to use normal\n              Python members of the \"self\" object, which will be persistent for\n              the whole mock\n        if not interface:\n            interface = self.interface\n        n_args = len(dbus.Signature(in_sig))\n\n        \n        \n        \n        \n        method = lambda self, *args, **kwargs: DBusMockObject.mock_method(\n            self, interface, name, in_sig, *args, **kwargs)\n\n        \n        \n        dbus_method = dbus.service.method(interface,\n                                          out_signature=out_sig)(method)\n        dbus_method.__name__ = str(name)\n        dbus_method._dbus_in_signature = in_sig\n        dbus_method._dbus_args = [ % i for i in range(1, n_args + 1)]\n\n        \n        \n        if interface == self.interface:\n            setattr(self.__class__, name, dbus_method)\n\n        self.methods.setdefault(interface, {})[str(name)] = (in_sig, out_sig, code, dbus_method)",
        "hard_negative_ids": [
            360,
            189,
            269,
            498,
            316,
            382,
            466,
            73,
            315,
            190,
            414,
            323,
            488,
            429,
            41,
            47,
            275,
            291,
            69,
            136,
            324,
            462,
            373,
            470,
            79,
            179,
            434,
            201,
            329,
            391,
            349,
            25,
            264,
            197,
            210,
            254,
            113,
            272,
            255,
            386,
            232,
            413,
            77,
            202,
            427,
            203,
            294,
            44,
            418,
            23
        ]
    },
    {
        "query": "Moves the cursor on the right.\n\n        :param keep_anchor: True to keep anchor (to select text) or False to\n            move the anchor (no selection)\n        :param nb_chars: Number of characters to move.",
        "positive_code": "def move_right(self, keep_anchor=False, nb_chars=1):\n        \n        text_cursor = self._editor.textCursor()\n        text_cursor.movePosition(\n            text_cursor.Right, text_cursor.KeepAnchor if keep_anchor else\n            text_cursor.MoveAnchor, nb_chars)\n        self._editor.setTextCursor(text_cursor)",
        "hard_negative_ids": [
            142,
            197,
            125,
            127,
            204,
            268,
            81,
            429,
            414,
            466,
            360,
            291,
            73,
            472,
            275,
            349,
            344,
            136,
            252,
            295,
            437,
            47,
            425,
            64,
            433,
            62,
            203,
            464,
            300,
            327,
            499,
            171,
            329,
            269,
            44,
            131,
            109,
            201,
            52,
            368,
            376,
            130,
            157,
            264,
            23,
            189,
            496,
            395,
            470,
            326
        ]
    },
    {
        "query": "Add new entry to the current index\n        :param tree: \n        :return:",
        "positive_code": "def add_index(self, mode, blob_id, path):\n        \n        self.command_exec([, , , mode, blob_id, path])",
        "hard_negative_ids": [
            82,
            246,
            500,
            466,
            377,
            493,
            79,
            137,
            81,
            215,
            360,
            414,
            68,
            272,
            347,
            204,
            285,
            233,
            73,
            344,
            279,
            453,
            300,
            58,
            197,
            291,
            289,
            326,
            136,
            171,
            269,
            131,
            239,
            230,
            127,
            429,
            44,
            368,
            376,
            295,
            189,
            264,
            275,
            23,
            25,
            109,
            47,
            76,
            266,
            157
        ]
    },
    {
        "query": "Pass through to provider SequenceRuleEnablerAdminSession.get_sequence_rule_enabler_form_for_update",
        "positive_code": "def get_sequence_rule_enabler_form(self, *args, **kwargs):\n        \n        \n        \n        \n        if isinstance(args[-1], list) or  in kwargs:\n            return self.get_sequence_rule_enabler_form_for_create(*args, **kwargs)\n        else:\n            return self.get_sequence_rule_enabler_form_for_update(*args, **kwargs)",
        "hard_negative_ids": [
            331,
            126,
            269,
            93,
            275,
            171,
            131,
            368,
            376,
            295,
            370,
            414,
            264,
            189,
            73,
            74,
            360,
            324,
            47,
            297,
            378,
            41,
            76,
            266,
            157,
            121,
            329,
            291,
            162,
            466,
            97,
            99,
            283,
            64,
            109,
            239,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469
        ]
    },
    {
        "query": "Reverse the object or return an iterator that iterates over it the other\n    way round.",
        "positive_code": "def do_reverse(value):\n    \n    if isinstance(value, string_types):\n        return value[::-1]\n    try:\n        return reversed(value)\n    except TypeError:\n        try:\n            rv = list(value)\n            rv.reverse()\n            return rv\n        except TypeError:\n            raise FilterArgumentError()",
        "hard_negative_ids": [
            250,
            485,
            360,
            414,
            494,
            79,
            73,
            113,
            291,
            197,
            136,
            238,
            131,
            466,
            470,
            297,
            189,
            69,
            179,
            375,
            429,
            44,
            105,
            23,
            81,
            427,
            181,
            25,
            285,
            326,
            149,
            240,
            99,
            141,
            425,
            5,
            270,
            215,
            112,
            72,
            182,
            306,
            127,
            11,
            109,
            283,
            295,
            415,
            191,
            144
        ]
    },
    {
        "query": "Parses a quadrant measurement of the form \"AxxB\", where A and B are cardinal\n    directions and xx is an angle measured relative to those directions.\n\n    In other words, it converts a measurement such as E30N into an azimuth of\n    60 degrees, or W10S into an azimuth of 260 degrees.\n\n    For ambiguous quadrant measurements such as \"N30S\", a ValueError is raised.\n\n    Parameters\n    -----------\n    quad_azimuth : string\n        An azimuth measurement in quadrant form.\n\n    Returns\n    -------\n    azi : float\n        An azimuth in degrees clockwise from north.\n\n    See Also\n    --------\n    parse_azimuth",
        "positive_code": "def parse_quadrant_measurement(quad_azimuth):\n    \n    def rotation_direction(first, second):\n        return np.cross(_azimuth2vec(first), _azimuth2vec(second))\n\n    \n    quad_azimuth = quad_azimuth.strip()\n    try:\n        first_dir = quadrantletter_to_azimuth(quad_azimuth[0].upper())\n        sec_dir = quadrantletter_to_azimuth(quad_azimuth[-1].upper())\n    except KeyError:\n        raise ValueError(.format(quad_azimuth))\n\n    angle = float(quad_azimuth[1:-1])\n\n    \n    direc = rotation_direction(first_dir, sec_dir)\n    azi = first_dir + direc * angle\n\n    \n    if abs(direc) < 0.9:\n        raise ValueError(.format(quad_azimuth))\n\n    \n    if azi < 0:\n        azi += 360\n    elif azi > 360:\n        azi -= 360\n\n    return azi",
        "hard_negative_ids": [
            360,
            391,
            429,
            485,
            250,
            106,
            75,
            415,
            414,
            466,
            349,
            73,
            210,
            245,
            149,
            413,
            313,
            494,
            487,
            15,
            40,
            232,
            60,
            56,
            189,
            486,
            304,
            318,
            342,
            470,
            11,
            462,
            197,
            171,
            345,
            425,
            76,
            120,
            23,
            291,
            69,
            256,
            48,
            426,
            499,
            317,
            136,
            237,
            25,
            272
        ]
    },
    {
        "query": "Do the actual update.\n\n        action: if provided it will be looked up\n        on the implementing class and called with\n        **kwargs. If action is not provided each k/v pair\n        in kwargs will be set on self and then self\n        is saved.\n\n        kwargs: any other you passed for this update\n        passed along to whichever method performs\n        the update.",
        "positive_code": "def do_scheduled_update(self, action, **kwargs):\n        \n\n        action = getattr(self, action, None)\n        if callable(action):\n            return action(**kwargs)\n        else:\n            for k, v in kwargs.items():\n                setattr(self, k, v)\n            self.save()",
        "hard_negative_ids": [
            269,
            213,
            287,
            485,
            250,
            85,
            295,
            189,
            414,
            190,
            478,
            212,
            466,
            329,
            139,
            451,
            45,
            132,
            411,
            209,
            16,
            41,
            412,
            192,
            252,
            360,
            291,
            494,
            90,
            123,
            420,
            377,
            488,
            5,
            396,
            255,
            323,
            201,
            133,
            47,
            264,
            128,
            112,
            207,
            316,
            92,
            222,
            232,
            179,
            429
        ]
    },
    {
        "query": "Return imported task module of feature.\n\n    This function first tries to import the feature and raises FeatureNotFound\n    if that is not possible.\n    Thereafter, it looks for a submodules called ``apetasks`` and ``tasks`` in that order.\n    If such a submodule exists, it is imported and returned.\n\n    :param feature: name of feature to fet task module for.\n    :raises: FeatureNotFound if feature_module could not be imported.\n    :return: imported module containing the ape tasks of feature or None,\n                if module cannot be imported.",
        "positive_code": "def get_task_module(feature):\n    \n    try:\n        importlib.import_module(feature)\n    except ImportError:\n        raise FeatureNotFound(feature)\n\n    tasks_module = None\n\n    \n    \n    try:\n        tasks_module = importlib.import_module(feature + )\n    except ImportError:\n        \n        pass\n\n    try:\n        tasks_module = importlib.import_module(feature + )\n    except ImportError:\n        \n        pass\n\n    return tasks_module",
        "hard_negative_ids": [
            212,
            199,
            234,
            215,
            414,
            360,
            232,
            193,
            470,
            349,
            466,
            192,
            69,
            429,
            354,
            311,
            73,
            204,
            189,
            386,
            81,
            42,
            197,
            291,
            275,
            23,
            462,
            382,
            235,
            171,
            76,
            131,
            179,
            304,
            391,
            38,
            47,
            142,
            498,
            425,
            255,
            66,
            345,
            318,
            295,
            106,
            44,
            184,
            176,
            264
        ]
    },
    {
        "query": "Determine whether the model of the instance is an NDB model.\n\n        Returns:\n            Boolean indicating whether or not the model is an NDB or DB model.",
        "positive_code": "def _is_ndb(self):\n        \n        \n        \n        \n        if isinstance(self._model, type):\n            if _NDB_MODEL is not None and issubclass(self._model, _NDB_MODEL):\n                return True\n            elif issubclass(self._model, db.Model):\n                return False\n\n        raise TypeError(\n            .format(self._model))",
        "hard_negative_ids": [
            333,
            89,
            489,
            198,
            360,
            73,
            197,
            269,
            273,
            414,
            466,
            467,
            152,
            219,
            429,
            442,
            291,
            259,
            136,
            189,
            349,
            23,
            181,
            232,
            141,
            44,
            423,
            270,
            395,
            425,
            427,
            112,
            470,
            25,
            211,
            318,
            179,
            345,
            326,
            224,
            182,
            52,
            97,
            66,
            240,
            306,
            24,
            5,
            157,
            215
        ]
    },
    {
        "query": "Returns a status string for business rules based items formatted\n        using business_rule_output_template attribute as template.\n\n        The template may embed output formatting for itself, and for its child\n        (dependent) items. Child format string is expanded into the $( and )$,\n        using the string between brackets as format string.\n\n        Any business rule based item or child macro may be used. In addition,\n        the $STATUS$, $SHORTSTATUS$ and $FULLNAME$ macro which name is common\n        to hosts and services may be used to ease template writing.\n\n        Caution: only children in state not OK are displayed.\n\n        Example:\n          A business rule with a format string looking like\n              \"$STATUS$ [ $($TATUS$: $HOSTNAME$,$SERVICEDESC$ )$ ]\"\n          Would return\n              \"CRITICAL [ CRITICAL: host1,srv1 WARNING: host2,srv2  ]\"\n\n        :param hosts: Hosts object to look for objects\n        :type hosts: alignak.objects.host.Hosts\n        :param services: Services object to look for objects\n        :type services: alignak.objects.service.Services\n        :param macromodulations: Macromodulations object to look for objects\n        :type macromodulations: alignak.objects.macromodulation.Macromodulations\n        :param timeperiods: Timeperiods object to look for objects\n        :type timeperiods: alignak.objects.timeperiod.Timeperiods\n        :return: status for business rules\n        :rtype: str",
        "positive_code": "def get_business_rule_output(self, hosts, services, macromodulations, timeperiods):\n        \n        \n        got_business_rule = getattr(self, , False)\n        \n        if got_business_rule is False or self.business_rule is None:\n            return \"\"\n        \n        output_template = self.business_rule_output_template\n        if not output_template:\n            return \"\"\n        macroresolver = MacroResolver()\n\n        \n        elts = re.findall(r\"\\$\\((.*)\\)\\$\", output_template)\n        if not elts:\n            child_template_string = \"\"\n        else:\n            child_template_string = elts[0]\n\n        \n        children_output = \"\"\n        ok_count = 0\n        \n        items = self.business_rule.list_all_elements()\n        for item_uuid in items:\n            if item_uuid in hosts:\n                item = hosts[item_uuid]\n            elif item_uuid in services:\n                item = services[item_uuid]\n\n            \n            \n            if item.last_hard_state_id == 0:\n                ok_count += 1\n                continue\n            data = item.get_data_for_checks(hosts)\n            children_output += macroresolver.resolve_simple_macros_in_string(child_template_string,\n                                                                             data,\n                                                                             macromodulations,\n                                                                             timeperiods)\n\n        if ok_count == len(items):\n            children_output = \"all checks were successful.\"\n\n        \n        template_string = re.sub(r\"\\$\\(.*\\)\\$\", children_output, output_template)\n        data = self.get_data_for_checks(hosts)\n        output = macroresolver.resolve_simple_macros_in_string(template_string, data,\n                                                               macromodulations, timeperiods)\n        return output.strip()",
        "hard_negative_ids": [
            325,
            61,
            360,
            376,
            470,
            91,
            79,
            210,
            81,
            413,
            161,
            89,
            232,
            388,
            222,
            40,
            444,
            23,
            291,
            85,
            342,
            136,
            25,
            166,
            78,
            73,
            335,
            466,
            113,
            269,
            414,
            302,
            336,
            383,
            34,
            293,
            173,
            15,
            264,
            71,
            429,
            69,
            179,
            297,
            198,
            76,
            345,
            63,
            204,
            192
        ]
    },
    {
        "query": "Updates an existing gradebook.\n\n        arg:    gradebook_form (osid.grading.GradebookForm): the form\n                containing the elements to be updated\n        raise:  IllegalState - ``gradebook_form`` already used in an\n                update transaction\n        raise:  InvalidArgument - the form contains an invalid value\n        raise:  NullArgument - ``gradebook_form`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        raise:  Unsupported - ``gradebook_form did not originate from\n                get_gradebook_form_for_update()``\n        *compliance: mandatory -- This method must be implemented.*",
        "positive_code": "def update_gradebook(self, gradebook_form):\n        \n        \n        \n        if self._catalog_session is not None:\n            return self._catalog_session.update_catalog(catalog_form=gradebook_form)\n        collection = JSONClientValidated(,\n                                         collection=,\n                                         runtime=self._runtime)\n        if not isinstance(gradebook_form, ABCGradebookForm):\n            raise errors.InvalidArgument()\n        if not gradebook_form.is_for_update():\n            raise errors.InvalidArgument()\n        try:\n            if self._forms[gradebook_form.get_id().get_identifier()] == UPDATED:\n                raise errors.IllegalState()\n        except KeyError:\n            raise errors.Unsupported()\n        if not gradebook_form.is_valid():\n            raise errors.InvalidArgument()\n        collection.save(gradebook_form._my_map)  \n\n        self._forms[gradebook_form.get_id().get_identifier()] = UPDATED\n\n        \n        return objects.Gradebook(osid_object_map=gradebook_form._my_map, runtime=self._runtime, proxy=self._proxy)",
        "hard_negative_ids": [
            232,
            360,
            415,
            386,
            139,
            73,
            414,
            295,
            192,
            189,
            382,
            171,
            166,
            402,
            429,
            85,
            131,
            63,
            477,
            323,
            41,
            466,
            470,
            222,
            56,
            329,
            491,
            474,
            23,
            349,
            44,
            291,
            269,
            267,
            142,
            47,
            67,
            182,
            70,
            412,
            109,
            90,
            178,
            197,
            9,
            433,
            462,
            427,
            11,
            331
        ]
    },
    {
        "query": "Deserialises the given JSON into an element.\n\n        >>> json = '{\"element\": \"string\", \"content\": \"Hello\"'\n        >>> JSONDeserialiser().deserialise(json)\n        String(content='Hello')",
        "positive_code": "def deserialise(self, element_json: str) -> Element:\n        \n\n        return self.deserialise_dict(json.loads(element_json))",
        "hard_negative_ids": [
            210,
            428,
            433,
            273,
            413,
            40,
            62,
            348,
            461,
            73,
            342,
            429,
            434,
            414,
            360,
            275,
            227,
            265,
            159,
            197,
            484,
            377,
            291,
            245,
            52,
            376,
            56,
            463,
            189,
            207,
            327,
            188,
            379,
            440,
            460,
            311,
            485,
            404,
            466,
            230,
            314,
            25,
            217,
            136,
            203,
            48,
            206,
            138,
            412,
            340
        ]
    },
    {
        "query": "Rebases text with stop words removed.",
        "positive_code": "def rebase(self, text, char=):\n        \n        regexp = re.compile(r % .join(self.collection),\n                            re.IGNORECASE | re.UNICODE)\n\n        def replace(m):\n            word = m.group(1)\n            return char * len(word)\n\n        return regexp.sub(replace, text)",
        "hard_negative_ids": [
            313,
            175,
            10,
            120,
            437,
            291,
            62,
            464,
            433,
            425,
            327,
            349,
            52,
            170,
            427,
            96,
            117,
            78,
            434,
            74,
            227,
            269,
            59,
            439,
            468,
            397,
            128,
            404,
            374,
            1,
            149,
            391,
            179,
            34,
            163,
            186,
            138,
            264,
            319,
            252,
            466,
            414,
            365,
            275,
            293,
            480,
            479,
            478,
            477,
            476
        ]
    },
    {
        "query": "Fetch a remote vispy font",
        "positive_code": "def _get_vispy_font_filename(face, bold, italic):\n    \n    name = face + \n    name +=  if not bold and not italic else \n    name +=  if bold else \n    name +=  if italic else \n    name += \n    return load_data_file( % name)",
        "hard_negative_ids": [
            395,
            15,
            106,
            304,
            391,
            291,
            277,
            180,
            453,
            178,
            317,
            425,
            360,
            171,
            470,
            256,
            382,
            462,
            222,
            349,
            472,
            76,
            466,
            272,
            23,
            29,
            28,
            27,
            26,
            25,
            24,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471,
            469,
            468,
            467,
            465
        ]
    },
    {
        "query": "Total byte size of fields in this structure => total byte size of\n            the structure on the file",
        "positive_code": "def get_size(cls):\n        \n        return sum([getattr(cls, name).length\n                    for name in cls.get_fields_names()])",
        "hard_negative_ids": [
            252,
            489,
            197,
            466,
            411,
            414,
            429,
            12,
            179,
            23,
            327,
            471,
            47,
            363,
            291,
            360,
            171,
            349,
            448,
            44,
            326,
            499,
            395,
            204,
            8,
            232,
            470,
            127,
            163,
            130,
            275,
            136,
            189,
            73,
            278,
            90,
            467,
            300,
            324,
            25,
            318,
            20,
            376,
            157,
            159,
            144,
            239,
            183,
            1,
            245
        ]
    },
    {
        "query": "Find a model by its primary key or return new instance of the related model.\n\n        :param id: The primary key\n        :type id: mixed\n\n        :param columns:  The columns to retrieve\n        :type columns: list\n\n        :rtype: Collection or Model",
        "positive_code": "def find_or_new(self, id, columns=None):\n        \n        if columns is None:\n            columns = [\"*\"]\n\n        instance = self._query.find(id, columns)\n\n        if instance is None:\n            instance = self._related.new_instance()\n            instance.set_attribute(self.get_plain_foreign_key(), self.get_parent_key())\n\n        return instance",
        "hard_negative_ids": [
            333,
            489,
            197,
            89,
            196,
            82,
            291,
            424,
            103,
            273,
            141,
            269,
            198,
            23,
            113,
            81,
            232,
            360,
            142,
            443,
            45,
            204,
            466,
            476,
            44,
            414,
            256,
            73,
            387,
            353,
            105,
            442,
            344,
            179,
            79,
            467,
            76,
            152,
            48,
            219,
            15,
            11,
            222,
            345,
            349,
            459,
            429,
            136,
            39,
            272
        ]
    },
    {
        "query": "Download the master database\n    :param ftp: ftp connection\n    :param ftp_path: path to file on the ftp server\n    :param local_path: local path to download file\n    :return:",
        "positive_code": "def ftp_download(ftp, ftp_path, local_path):\n    \n    with open(local_path, ) as _f:\n        ftp.retrbinary( % ftp_path, _f.write)",
        "hard_negative_ids": [
            376,
            363,
            204,
            38,
            81,
            171,
            405,
            414,
            44,
            249,
            456,
            360,
            170,
            144,
            344,
            73,
            374,
            266,
            254,
            246,
            300,
            34,
            169,
            466,
            450,
            380,
            275,
            47,
            9,
            23,
            197,
            499,
            1,
            264,
            291,
            228,
            458,
            193,
            467,
            436,
            333,
            457,
            31,
            163,
            394,
            130,
            136,
            234,
            269,
            194
        ]
    },
    {
        "query": "Safely remove the given file or directory.\n\n    Works in a multithreaded scenario.",
        "positive_code": "def safe_remove(path):\n    \n    if not os.path.exists(path):\n        return\n\n    try:\n        if os.path.isdir(path) and not os.path.islink(path):\n            shutil.rmtree(path)\n        else:\n            os.remove(path)\n    except OSError:\n        if os.path.exists(path):\n            raise",
        "hard_negative_ids": [
            38,
            73,
            171,
            500,
            360,
            69,
            363,
            332,
            391,
            414,
            425,
            106,
            291,
            23,
            304,
            44,
            74,
            466,
            136,
            96,
            197,
            99,
            144,
            317,
            178,
            453,
            467,
            374,
            15,
            462,
            376,
            349,
            275,
            1,
            169,
            429,
            215,
            470,
            256,
            326,
            5,
            382,
            183,
            25,
            240,
            141,
            222,
            277,
            270,
            182
        ]
    },
    {
        "query": "Create a `BootResource`.\n\n        Creates an uploaded boot resource with `content`. The `content` is\n        uploaded in chunks of `chunk_size`. `content` must be seekable as the\n        first pass through the `content` will calculate the size and sha256\n        value then the second pass will perform the actual upload.\n\n        :param name: Name of the boot resource. Must be in format 'os/release'.\n        :type name: `str`\n        :param architecture: Architecture of the boot resource. Must be in\n            format 'arch/subarch'.\n        :type architecture: `str`\n        :param content: Content of the boot resource.\n        :type content: `io.IOBase`\n        :param title: Title of the boot resource.\n        :type title: `str`\n        :param filetype: Type of file in content.\n        :type filetype: `str`\n        :param chunk_size: Size in bytes to upload to MAAS in chunks.\n            (Default is 4 MiB).\n        :type chunk_size: `int`\n        :param progress_callback: Called to inform the current progress of the\n            upload. One argument is passed with the progress as a precentage.\n            If the resource was already complete and no content\n            needed to be uploaded then this callback will never be called.\n        :type progress_callback: Callable\n        :returns: Create boot resource.\n        :rtype: `BootResource`.",
        "positive_code": "async def create(\n            cls, name: str, architecture: str, content: io.IOBase, *,\n            title: str = \"\",\n            filetype: BootResourceFileType = BootResourceFileType.TGZ,\n            chunk_size=(1 << 22), progress_callback=None):\n        \n        if  not in name:\n            raise ValueError(\n                \"name must be in format os/release; missing \")\n        if  not in architecture:\n            raise ValueError(\n                \"architecture must be in format arch/subarch; missing \")\n        if not content.readable():\n            raise ValueError(\"content must be readable\")\n        elif not content.seekable():\n            raise ValueError(\"content must be seekable\")\n        if chunk_size <= 0:\n            raise ValueError(\n                \"chunk_size must be greater than 0, not %d\" % chunk_size)\n\n        size, sha256 = calc_size_and_sha265(content, chunk_size)\n        resource = cls._object(await cls._handler.create(\n            name=name, architecture=architecture, title=title,\n            filetype=filetype.value, size=str(size), sha256=sha256))\n        newest_set = max(resource.sets, default=None)\n        assert newest_set is not None\n        resource_set = resource.sets[newest_set]\n        assert len(resource_set.files) == 1\n        rfile = list(resource_set.files.values())[0]\n        if rfile.complete:\n            \n            return resource\n        else:\n            \n            await cls._upload_chunks(\n                rfile, content, chunk_size, progress_callback)\n            return cls._object.read(resource.id)",
        "hard_negative_ids": [
            232,
            171,
            364,
            273,
            466,
            62,
            386,
            275,
            414,
            470,
            291,
            360,
            382,
            455,
            81,
            73,
            424,
            76,
            197,
            264,
            23,
            170,
            349,
            429,
            222,
            179,
            213,
            201,
            69,
            404,
            295,
            325,
            300,
            391,
            109,
            163,
            206,
            149,
            345,
            239,
            91,
            453,
            182,
            217,
            204,
            498,
            269,
            68,
            168,
            157
        ]
    },
    {
        "query": "Apply normalizations over all files in the given directory.\n\n        Iterate over all files in a given directory. Normalizations\n        will be applied to each file, storing the result in a new file.\n        The extension for the new file will be the one defined in\n        BATCH_EXTENSION.\n\n        Args:\n            path: Path to the directory.\n            recursive: Whether to find files recursively or not.",
        "positive_code": "def process_files(self, path, recursive=False):\n        \n        self._logger.info(, path)\n\n        for (path, file) in files_generator(path, recursive):\n            if not file.endswith(BATCH_EXTENSION):\n                self.process_file(os.path.join(path, file))",
        "hard_negative_ids": [
            363,
            287,
            82,
            171,
            360,
            414,
            73,
            38,
            264,
            23,
            295,
            232,
            44,
            405,
            291,
            144,
            269,
            275,
            197,
            402,
            466,
            99,
            223,
            76,
            170,
            376,
            452,
            456,
            169,
            151,
            27,
            136,
            246,
            470,
            106,
            178,
            488,
            201,
            462,
            382,
            85,
            189,
            112,
            41,
            391,
            304,
            254,
            311,
            25,
            226
        ]
    },
    {
        "query": "Invoke the visitors before and after decending down the tree. \n        The walker will also try to invoke a method matching the pattern \n        *accept_<type name>*, where <type name> is the name of the accepted\n        *node*.",
        "positive_code": "def accept(self, node, **kwargs):\n        \n        if node is None:\n            return\n        \n        for v in self.visitors:\n            v.enter(node)\n        \n        name =  + node.__class__.__name__\n        fn = getattr(self, name, self.default_accept)\n        r = fn(node, **kwargs)\n        \n        for v in self.visitors:\n            v.leave(node)\n        \n        return r",
        "hard_negative_ids": [
            429,
            500,
            159,
            197,
            388,
            466,
            360,
            498,
            232,
            314,
            323,
            487,
            41,
            377,
            412,
            414,
            366,
            437,
            17,
            139,
            176,
            376,
            305,
            485,
            291,
            70,
            73,
            174,
            237,
            76,
            379,
            324,
            126,
            391,
            226,
            475,
            15,
            44,
            272,
            256,
            258,
            18,
            66,
            215,
            311,
            349,
            23,
            353,
            144,
            411
        ]
    },
    {
        "query": "yaw angle angular_speed angle_mode",
        "positive_code": "def cmd_condition_yaw(self, args):\n        \n        if ( len(args) != 3):\n            print(\"Usage: yaw ANGLE ANGULAR_SPEED MODE:[0 absolute / 1 relative]\")\n            return\n\n        if (len(args) == 3):\n            angle = float(args[0])\n            angular_speed = float(args[1])\n            angle_mode = float(args[2])\n            print(\"ANGLE %s\" % (str(angle)))\n\n            self.master.mav.command_long_send(\n                self.settings.target_system,  \n                mavutil.mavlink.MAV_COMP_ID_SYSTEM_CONTROL, \n                mavutil.mavlink.MAV_CMD_CONDITION_YAW, \n                0, \n                angle, \n                angular_speed, \n                0, \n                angle_mode, \n                0, \n                0, \n                0)",
        "hard_negative_ids": [
            500,
            499,
            498,
            497,
            496,
            495,
            494,
            493,
            492,
            491,
            490,
            489,
            488,
            487,
            486,
            485,
            484,
            483,
            482,
            481,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469,
            468,
            467,
            466,
            465,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457,
            456,
            455,
            454,
            453,
            452,
            451
        ]
    },
    {
        "query": "Runs the optimization of the given TimeSeries.\n\n        :param TimeSeries timeSeries:    TimeSeries instance that requires an optimized forecast.\n        :param list forecastingMethods:    List of forecastingMethods that will be used for optimization.\n        :param float startingPercentage: Defines the start of the interval. This has to be a value in [0.0, 100.0].\n            It represents the value, where the error calculation should be started.\n            25.0 for example means that the first 25% of all calculated errors will be ignored.\n        :param float endPercentage:    Defines the end of the interval. This has to be a value in [0.0, 100.0].\n            It represents the value, after which all error values will be ignored. 90.0 for example means that\n            the last 10% of all local errors will be ignored.\n\n        :return:    Returns the optimized forecasting method, the corresponding error measure and the forecasting methods\n            parameters.\n        :rtype:     [BaseForecastingMethod, BaseErrorMeasure, Dictionary]\n\n        :raise:    Raises a :py:exc:`ValueError` ValueError if no forecastingMethods is empty.",
        "positive_code": "def optimize(self, timeSeries, forecastingMethods=None, startingPercentage=0.0, endPercentage=100.0):\n        \n\n        if forecastingMethods is None or len(forecastingMethods) == 0:\n            raise ValueError(\"forecastingMethods cannot be empty.\")\n\n        self._startingPercentage = startingPercentage\n        self._endPercentage      = endPercentage\n\n        results = []\n        for forecastingMethod in forecastingMethods:\n            results.append([forecastingMethod] + self.optimize_forecasting_method(timeSeries, forecastingMethod))\n\n        \n        bestForecastingMethod = min(results, key=lambda item: item[1].get_error(self._startingPercentage, self._endPercentage))\n\n        for parameter in bestForecastingMethod[2]:\n            bestForecastingMethod[0].set_parameter(parameter, bestForecastingMethod[2][parameter])\n\n        return bestForecastingMethod",
        "hard_negative_ids": [
            360,
            232,
            349,
            268,
            44,
            197,
            386,
            382,
            56,
            332,
            414,
            81,
            73,
            291,
            466,
            23,
            470,
            269,
            142,
            182,
            192,
            493,
            267,
            237,
            462,
            90,
            69,
            278,
            201,
            47,
            429,
            76,
            424,
            323,
            15,
            178,
            272,
            344,
            25,
            366,
            109,
            80,
            189,
            375,
            487,
            485,
            82,
            41,
            87,
            99
        ]
    },
    {
        "query": "All names in the package directory that matches the given glob, without\n  their extension. Repeated names should appear only once.",
        "positive_code": "def get_module_names(package_path, pattern=\"lazy_*.py*\"):\n  \n  package_contents = glob(os.path.join(package_path[0], pattern))\n  relative_path_names = (os.path.split(name)[1] for name in package_contents)\n  no_ext_names = (os.path.splitext(name)[0] for name in relative_path_names)\n  return sorted(set(no_ext_names))",
        "hard_negative_ids": [
            445,
            73,
            388,
            360,
            36,
            429,
            295,
            291,
            264,
            498,
            274,
            38,
            466,
            258,
            215,
            176,
            414,
            197,
            76,
            85,
            99,
            344,
            69,
            25,
            116,
            65,
            136,
            142,
            201,
            496,
            182,
            66,
            23,
            319,
            150,
            44,
            412,
            462,
            192,
            454,
            366,
            109,
            321,
            88,
            239,
            237,
            185,
            386,
            233,
            47
        ]
    },
    {
        "query": "Install a DISM capability\n\n    Args:\n        name (str): The capability to install\n        source (str): The optional source of the capability\n        limit_access (bool): Prevent DISM from contacting Windows Update for\n            online images\n        image (Optional[str]): The path to the root directory of an offline\n            Windows image. If `None` is passed, the running operating system is\n            targeted. Default is None.\n        restart (Optional[bool]): Reboot the machine if required by the install\n\n    Example:\n        Run ``dism.available_capabilities`` to get a list of available\n        capabilities. This will help you get the proper name to use.\n\n        .. code-block:: yaml\n\n            install_dotnet35:\n              dism.capability_installed:\n                - name: NetFX3~~~~",
        "positive_code": "def capability_installed(name,\n                         source=None,\n                         limit_access=False,\n                         image=None,\n                         restart=False):\n    \n    ret = {: name,\n           : True,\n           : ,\n           : {}}\n\n    old = __salt__[]()\n\n    if name in old:\n        ret[] = .format(name)\n        return ret\n\n    if __opts__[]:\n        ret[][] = .format(name)\n        ret[] = None\n        return ret\n\n    \n    status = __salt__[](\n        name, source, limit_access, image, restart)\n\n    if status[] not in [0, 1641, 3010]:\n        ret[] = \\\n            .format(name, status[])\n        ret[] = False\n\n    new = __salt__[]()\n    changes = salt.utils.data.compare_lists(old, new)\n\n    if changes:\n        ret[] = .format(name)\n        ret[] = status\n        ret[][] = changes\n\n    return ret",
        "hard_negative_ids": [
            168,
            466,
            435,
            360,
            414,
            73,
            69,
            429,
            498,
            460,
            264,
            12,
            424,
            327,
            189,
            269,
            363,
            291,
            76,
            136,
            197,
            178,
            38,
            412,
            25,
            186,
            201,
            293,
            47,
            339,
            181,
            322,
            405,
            84,
            295,
            349,
            23,
            391,
            393,
            179,
            171,
            98,
            331,
            117,
            276,
            324,
            5,
            286,
            131,
            260
        ]
    },
    {
        "query": "Reset internal state",
        "positive_code": "def reset(self):\n        \n        self.overall = {\n            : 0.0,\n            : 0.0,\n            : 0.0\n        }\n\n        self.scene_wise = {}\n        for label in self.scene_label_list:\n            self.scene_wise[label] = {\n                : 0.0,\n                : 0.0,\n                : 0.0\n            }",
        "hard_negative_ids": [
            325,
            217,
            202,
            410,
            465,
            360,
            185,
            97,
            9,
            336,
            352,
            179,
            472,
            285,
            30,
            29,
            28,
            27,
            26,
            25,
            24,
            23,
            22,
            21,
            20,
            19,
            18,
            1,
            480,
            479,
            478,
            477,
            476,
            475,
            474,
            473,
            471,
            470,
            469,
            468,
            467,
            466,
            464,
            463,
            462,
            461,
            460,
            459,
            458,
            457
        ]
    },
    {
        "query": "Scrap the number of organizations from a GitHub profile.\n\n        :param web: parsed web.\n        :type web: BeautifulSoup node.",
        "positive_code": "def __getOrganizations(self, web):\n        \n        orgsElements = web.find_all(\"a\", {\"class\": \"avatar-group-item\"})\n        self.organizations = len(orgsElements)",
        "hard_negative_ids": [
            158,
            178,
            232,
            305,
            142,
            174,
            124,
            126,
            81,
            466,
            215,
            360,
            18,
            197,
            311,
            379,
            470,
            272,
            349,
            204,
            252,
            366,
            429,
            106,
            344,
            304,
            391,
            73,
            300,
            414,
            280,
            31,
            395,
            279,
            193,
            291,
            453,
            105,
            133,
            7,
            115,
            26,
            20,
            317,
            425,
            76,
            23,
            367,
            222,
            131
        ]
    },
    {
        "query": "Simple helper function that finds the test data in the directory tree\n    and loads it using :func:`gzip.open` and :func:`numpy.loadtxt`.\n\n    :param gzfile: Filename\n    :type gzfile: str\n    :returns: data\n    :rtype: numpy.ndarray",
        "positive_code": "def _load_mtdata(gzfile):\n    \n    path = os.path.join(os.path.dirname(__file__), , , gzfile)\n    return np.loadtxt(gzip.open(path))",
        "hard_negative_ids": [
            42,
            38,
            217,
            337,
            360,
            112,
            500,
            166,
            421,
            29,
            377,
            99,
            271,
            297,
            119,
            453,
            373,
            478,
            291,
            393,
            263,
            223,
            364,
            81,
            424,
            117,
            204,
            23,
            425,
            402,
            235,
            498,
            283,
            169,
            197,
            195,
            22,
            109,
            33,
            232,
            85,
            357,
            148,
            466,
            154,
            440,
            345,
            163,
            324,
            228
        ]
    },
    {
        "query": "Enqueue the download of the given foreign resource.\n\n        Deprecated: Use async version instead",
        "positive_code": "def enqueue_download(self, resource):\n        \n        worker = self.pick_sticky(resource.url_string)\n        coro = worker.enqueue(enums.Task.DOWNLOAD, (resource,))\n        asyncio.ensure_future(coro)",
        "hard_negative_ids": [
            73,
            171,
            466,
            153,
            244,
            434,
            197,
            414,
            122,
            136,
            178,
            370,
            360,
            47,
            429,
            291,
            38,
            407,
            374,
            50,
            386,
            147,
            349,
            395,
            137,
            470,
            232,
            157,
            264,
            44,
            1,
            23,
            99,
            25,
            34,
            243,
            318,
            426,
            109,
            272,
            180,
            476,
            475,
            474,
            473,
            472,
            471,
            469,
            468,
            467
        ]
    },
    {
        "query": "Runs local prediction on the prediction graph.\n\n  Runs local prediction and returns the result in a Pandas DataFrame. For\n  running prediction on a large dataset or saving the results, run\n  local_batch_prediction or batch_prediction. Input data should fully match\n  the schema that was used at training, except the target column should not\n  exist.\n\n  Args:\n    training_dir: local path to the trained output folder.\n    data: List of csv strings or a Pandas DataFrame that match the model schema.\n\n  Raises:\n    ValueError: if training_dir does not contain the folder 'model'.\n    FileNotFoundError: if the prediction data is not found.",
        "positive_code": "def local_predict(training_dir, data):\n  \n  \n  from .prediction import predict as predict_module\n\n  \n  tmp_dir = tempfile.mkdtemp()\n  _, input_file_path = tempfile.mkstemp(dir=tmp_dir, suffix=,\n                                        prefix=)\n\n  try:\n    if isinstance(data, pd.DataFrame):\n      data.to_csv(input_file_path, header=False, index=False)\n    else:\n      with open(input_file_path, ) as f:\n        for line in data:\n          f.write(line + )\n\n    model_dir = os.path.join(training_dir, )\n    if not file_io.file_exists(model_dir):\n      raise ValueError()\n\n    cmd = [,\n            % input_file_path,\n            % model_dir,\n            % tmp_dir,\n           ,\n           ,\n           ,\n           ]\n\n    \n    runner_results = predict_module.main(cmd)\n    runner_results.wait_until_finish()\n\n    \n    schema_file = os.path.join(tmp_dir, )\n    with open(schema_file, ) as f:\n      schema = json.loads(f.read())\n\n    \n    errors_file = glob.glob(os.path.join(tmp_dir, ))\n    if errors_file and os.path.getsize(errors_file[0]) > 0:\n      print()\n      with open(errors_file[0], ) as f:\n        text = f.read()\n        print(text)\n\n    \n    prediction_file = glob.glob(os.path.join(tmp_dir, ))\n    if not prediction_file:\n      raise FileNotFoundError()\n    predictions = pd.read_csv(prediction_file[0],\n                              header=None,\n                              names=[col[] for col in schema])\n    return predictions\n  finally:\n    shutil.rmtree(tmp_dir)",
        "hard_negative_ids": [
            363,
            360,
            424,
            33,
            429,
            136,
            484,
            466,
            144,
            223,
            349,
            73,
            44,
            291,
            201,
            333,
            477,
            134,
            89,
            496,
            421,
            23,
            324,
            414,
            489,
            198,
            462,
            197,
            269,
            109,
            499,
            266,
            329,
            142,
            9,
            452,
            151,
            295,
            252,
            318,
            2,
            51,
            232,
            41,
            283,
            226,
            438,
            179,
            171,
            239
        ]
    },
    {
        "query": "Call `func` on each element in the collection.\n\n        If multiple functions are provided, each item\n        in the output will be a tuple of each\n        func(item) in self.\n\n        Returns a new Collection.\n\n        Example:\n\n            >>> col = Collection([Scalar(1), Scalar(2)])\n            >>> col.each(Q * 10)\n            Collection([Scalar(10), Scalar(20)])\n            >>> col.each(Q * 10, Q - 1)\n            Collection([Scalar((10, 0)), Scalar((20, 1))])",
        "positive_code": "def each(self, *funcs):\n        \n\n        funcs = list(map(_make_callable, funcs))\n\n        if len(funcs) == 1:\n            return Collection(map(funcs[0], self._items))\n\n        tupler = lambda item: Scalar(\n            tuple(_unwrap(func(item)) for func in funcs))\n        return Collection(map(tupler, self._items))",
        "hard_negative_ids": [
            287,
            78,
            160,
            217,
            107,
            85,
            42,
            453,
            443,
            112,
            82,
            16,
            183,
            337,
            156,
            136,
            425,
            466,
            429,
            360,
            97,
            23,
            39,
            29,
            297,
            227,
            433,
            291,
            461,
            222,
            472,
            414,
            90,
            77,
            272,
            119,
            348,
            58,
            232,
            197,
            470,
            240,
            235,
            499,
            185,
            252,
            245,
            350,
            182,
            256
        ]
    },
    {
        "query": "You can choose whether to use lock method when running threads.",
        "positive_code": "def run(self, *args):\n        \n        if self.running:\n            return self\n\n        self._mut_finished(False)  \n        self._mut_running(True)\n\n        stream = self.target(*args)\n\n        \n        def subr():\n            self._mut_running(True)\n            try:\n                for each in stream:\n                    self._product = each\n                    desc = self.descriptor_mapping(each)\n                    event = self.events.get(desc)\n                    if event:\n                        event(self, each, globals)\n                self._mut_finished(True)\n            except ThreadExit:\n                pass\n            finally:\n                self._mut_running(False)\n\n        self._thread = thread = threading.Thread(target=subr, args=())\n        thread.start()\n        return self",
        "hard_negative_ids": [
            323,
            255,
            229,
            466,
            136,
            269,
            41,
            122,
            189,
            128,
            70,
            139,
            360,
            73,
            47,
            402,
            254,
            414,
            315,
            237,
            201,
            97,
            171,
            25,
            44,
            434,
            131,
            368,
            376,
            295,
            87,
            264,
            275,
            426,
            76,
            266,
            157,
            329,
            99,
            109,
            478,
            477,
            476,
            475,
            474,
            473,
            472,
            471,
            470,
            469
        ]
    },
    {
        "query": "Set the properties of a single cell.\n\n    .. note::\n        This function is slow.\n    .. deprecated:: 4.5\n        Use :any:`tcod.map.Map.transparent` and :any:`tcod.map.Map.walkable`\n        arrays to set these properties.",
        "positive_code": "def map_set_properties(\n    m: tcod.map.Map, x: int, y: int, isTrans: bool, isWalk: bool\n) -> None:\n    \n    lib.TCOD_map_set_properties(m.map_c, x, y, isTrans, isWalk)",
        "hard_negative_ids": [
            414,
            199,
            359,
            42,
            404,
            269,
            235,
            244,
            152,
            47,
            360,
            466,
            343,
            90,
            197,
            186,
            392,
            192,
            58,
            25,
            122,
            349,
            174,
            171,
            201,
            189,
            113,
            470,
            48,
            109,
            73,
            239,
            429,
            198,
            304,
            23,
            272,
            12,
            97,
            184,
            142,
            88,
            106,
            182,
            175,
            275,
            291,
            391,
            11,
            232
        ]
    }
]